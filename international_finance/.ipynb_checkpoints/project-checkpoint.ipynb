{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "253f7c06-4efe-4614-86f2-0966cc597924",
   "metadata": {},
   "source": [
    "# **International Finance**\n",
    "Thomas de Portzamparc - 7/12/2025 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0b41fd-0d3e-4125-adc4-3759f17f35d9",
   "metadata": {},
   "source": [
    "# **Module Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1b7726f-4db2-4c38-b3a0-7e54886591f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from scipy.stats import skew, kurtosis\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b697a20a-a0dc-4080-9622-30d199883918",
   "metadata": {},
   "source": [
    "# **Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "644824d3-d461-4b62-89a4-7325a04b05de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/openpyxl/worksheet/_read_only.py:85: UserWarning: Unknown extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n"
     ]
    }
   ],
   "source": [
    "dict_forward = pd.read_excel(\"fwd_rates.xlsx\", header = 0, skiprows = [2], sheet_name = None, index_col = 0)\n",
    "df_forward = pd.concat(dict_forward.values(), axis = 1)\n",
    "df_forward = df_forward[1:]\n",
    "dict_spot = pd.read_excel(\"spot_rates.xls\", header = [0, 1], sheet_name = None, index_col = 0)\n",
    "df_spot = pd.concat(dict_spot.values(), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4b63a02-18db-4582-8ee7-bcc79ed3c046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we will get the dollar exchange rate and remove the other unused columns to manipulate the dataframe quicker\n",
    "usd_columns_spot = [col for col in df_spot if \" US\" in col[0] or \"US \" in col [0]] \n",
    "usd_columns_fwd = [col for col in df_forward if \" US\" in col or \"US \" in col]\n",
    "# A lot of XUSD spot columns are missing, we may need to retreive them buy using other currency pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2218989-ccbb-465b-8bef-ee760442425a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['US $ TO AUSTRALIAN $ 1W FWD (TR) - BID SPOT',\n",
       " 'US $ TO AUSTRALIAN $ 1W FWD (TR) - EXCHANGE RATE',\n",
       " 'US $ TO AUSTRALIAN $ 1W FWD (TR) - SPOT OFFERED',\n",
       " 'US $ TO AUSTRALIAN $ 1M FWD (TR) - BID SPOT',\n",
       " 'US $ TO AUSTRALIAN $ 1M FWD (TR) - EXCHANGE RATE',\n",
       " 'US $ TO AUSTRALIAN $ 1M FWD (TR) - SPOT OFFERED',\n",
       " 'BRAZILIAN REAL TO US $ 1M FWD OFF TR - BID SPOT',\n",
       " 'BRAZILIAN REAL TO US $ 1M FWD OFF TR - EXCHANGE RATE',\n",
       " 'BRAZILIAN REAL TO US $ 1M FWD OFF TR - SPOT OFFERED',\n",
       " 'BRAZILIAN REAL TO US $ 1W NDF (WMR) - BID SPOT',\n",
       " 'BRAZILIAN REAL TO US $ 1W NDF (WMR) - EXCHANGE RATE',\n",
       " 'BRAZILIAN REAL TO US $ 1W NDF (WMR) - SPOT OFFERED',\n",
       " 'CANADIAN $ TO US $ 1M FWD (BBI) - BID SPOT',\n",
       " 'CANADIAN $ TO US $ 1M FWD (BBI) - EXCHANGE RATE',\n",
       " 'CANADIAN $ TO US $ 1M FWD (BBI) - SPOT OFFERED',\n",
       " 'CANADIAN $ TO US $ 1W FWD (TR) - BID SPOT',\n",
       " 'CANADIAN $ TO US $ 1W FWD (TR) - EXCHANGE RATE',\n",
       " 'CANADIAN $ TO US $ 1W FWD (TR) - SPOT OFFERED',\n",
       " 'CROATIAN KUNA TO US $ 1M FWD (WMR) - BID SPOT',\n",
       " 'CROATIAN KUNA TO US $ 1M FWD (WMR) - EXCHANGE RATE',\n",
       " 'CROATIAN KUNA TO US $ 1M FWD (WMR) - SPOT OFFERED',\n",
       " 'CROATIAN KUNA TO US $ 1W FWD (WMR) - BID SPOT',\n",
       " 'CROATIAN KUNA TO US $ 1W FWD (WMR) - EXCHANGE RATE',\n",
       " 'CROATIAN KUNA TO US $ 1W FWD (WMR) - SPOT OFFERED',\n",
       " 'CZECH KORUNA TO US $ 1M FWD (TR) - BID SPOT',\n",
       " 'CZECH KORUNA TO US $ 1M FWD (TR) - EXCHANGE RATE',\n",
       " 'CZECH KORUNA TO US $ 1M FWD (TR) - SPOT OFFERED',\n",
       " 'CZECH KORUNA TO US $ 1W FWD (TR) - BID SPOT',\n",
       " 'CZECH KORUNA TO US $ 1W FWD (TR) - EXCHANGE RATE',\n",
       " 'CZECH KORUNA TO US $ 1W FWD (TR) - SPOT OFFERED',\n",
       " 'US $ TO EURO 1M FWD (TR) - BID SPOT',\n",
       " 'US $ TO EURO 1M FWD (TR) - EXCHANGE RATE',\n",
       " 'US $ TO EURO 1M FWD (TR) - SPOT OFFERED',\n",
       " 'US $ TO EURO 1W (TR) - BID SPOT',\n",
       " 'US $ TO EURO 1W (TR) - EXCHANGE RATE',\n",
       " 'US $ TO EURO 1W (TR) - SPOT OFFERED',\n",
       " 'HUNGARIAN HUF TO US $ 1M FWD (WMR) - BID SPOT',\n",
       " 'HUNGARIAN HUF TO US $ 1M FWD (WMR) - EXCHANGE RATE',\n",
       " 'HUNGARIAN HUF TO US $ 1M FWD (WMR) - SPOT OFFERED',\n",
       " 'HUNGARIAN FORINT TO US$ 1W FWD (WMR) - BID SPOT',\n",
       " 'HUNGARIAN FORINT TO US$ 1W FWD (WMR) - EXCHANGE RATE',\n",
       " 'HUNGARIAN FORINT TO US$ 1W FWD (WMR) - SPOT OFFERED',\n",
       " 'INDIAN RUPEE TO US $ 1M FWD (WMR) - BID SPOT',\n",
       " 'INDIAN RUPEE TO US $ 1M FWD (WMR) - EXCHANGE RATE',\n",
       " 'INDIAN RUPEE TO US $ 1M FWD (WMR) - SPOT OFFERED',\n",
       " 'INDIAN RUPEE TO US $ 1W FWD (WMR) - BID SPOT',\n",
       " 'INDIAN RUPEE TO US $ 1W FWD (WMR) - EXCHANGE RATE',\n",
       " 'INDIAN RUPEE TO US $ 1W FWD (WMR) - SPOT OFFERED',\n",
       " 'INDONESIAN RUPIAH TO US $ 1M FWD - BID SPOT',\n",
       " 'INDONESIAN RUPIAH TO US $ 1M FWD - EXCHANGE RATE',\n",
       " 'INDONESIAN RUPIAH TO US $ 1M FWD - SPOT OFFERED',\n",
       " 'INDONESIAN RUPIAH TO US $ 1W FWD - BID SPOT',\n",
       " 'INDONESIAN RUPIAH TO US $ 1W FWD - EXCHANGE RATE',\n",
       " 'INDONESIAN RUPIAH TO US $ 1W FWD - SPOT OFFERED',\n",
       " 'ISRAELI SHEKEL TO US $ 1M FWD (WMR) - BID SPOT',\n",
       " 'ISRAELI SHEKEL TO US $ 1M FWD (WMR) - EXCHANGE RATE',\n",
       " 'ISRAELI SHEKEL TO US $ 1M FWD (WMR) - SPOT OFFERED',\n",
       " 'ISRAELI SHEKEL TO US $ 1W FWD (WMR) - BID SPOT',\n",
       " 'ISRAELI SHEKEL TO US $ 1W FWD (WMR) - EXCHANGE RATE',\n",
       " 'ISRAELI SHEKEL TO US $ 1W FWD (WMR) - SPOT OFFERED',\n",
       " 'JAPANESE YEN TO US $ 1M FWD (TR) - BID SPOT',\n",
       " 'JAPANESE YEN TO US $ 1M FWD (TR) - EXCHANGE RATE',\n",
       " 'JAPANESE YEN TO US $ 1M FWD (TR) - SPOT OFFERED',\n",
       " 'JAPANESE YEN TO US $ 1W FWD (TR) - BID SPOT',\n",
       " 'JAPANESE YEN TO US $ 1W FWD (TR) - EXCHANGE RATE',\n",
       " 'JAPANESE YEN TO US $ 1W FWD (TR) - SPOT OFFERED',\n",
       " 'MEXICAN PESO TO US $ 1M FWD (WMR) - BID SPOT',\n",
       " 'MEXICAN PESO TO US $ 1M FWD (WMR) - EXCHANGE RATE',\n",
       " 'MEXICAN PESO TO US $ 1M FWD (WMR) - SPOT OFFERED',\n",
       " 'MEXICAN PESO TO US $ 1W FWD (WMR) - BID SPOT',\n",
       " 'MEXICAN PESO TO US $ 1W FWD (WMR) - EXCHANGE RATE',\n",
       " 'MEXICAN PESO TO US $ 1W FWD (WMR) - SPOT OFFERED',\n",
       " 'US $ TO NEW ZEALAND $ 1M FWD (TR) - BID SPOT',\n",
       " 'US $ TO NEW ZEALAND $ 1M FWD (TR) - EXCHANGE RATE',\n",
       " 'US $ TO NEW ZEALAND $ 1M FWD (TR) - SPOT OFFERED',\n",
       " 'US $ TO NEW ZEALAND $ 1W FWD (WMR) - BID SPOT',\n",
       " 'US $ TO NEW ZEALAND $ 1W FWD (WMR) - EXCHANGE RATE',\n",
       " 'US $ TO NEW ZEALAND $ 1W FWD (WMR) - SPOT OFFERED',\n",
       " 'NORWEGIAN KRONE TO US $ 1M FWD (TR) - BID SPOT',\n",
       " 'NORWEGIAN KRONE TO US $ 1M FWD (TR) - EXCHANGE RATE',\n",
       " 'NORWEGIAN KRONE TO US $ 1M FWD (TR) - SPOT OFFERED',\n",
       " 'NORWEGIAN KRONE TO US $ 1W FWD (TR) - BID SPOT',\n",
       " 'NORWEGIAN KRONE TO US $ 1W FWD (TR) - EXCHANGE RATE',\n",
       " 'NORWEGIAN KRONE TO US $ 1W FWD (TR) - SPOT OFFERED',\n",
       " 'PHILIPPINE PESO TO US $ 1M FWD(WMR) - BID SPOT',\n",
       " 'PHILIPPINE PESO TO US $ 1M FWD(WMR) - EXCHANGE RATE',\n",
       " 'PHILIPPINE PESO TO US $ 1M FWD(WMR) - SPOT OFFERED',\n",
       " 'POLISH ZLOTY TO US $ 1M FWD (TR) - BID SPOT',\n",
       " 'POLISH ZLOTY TO US $ 1M FWD (TR) - EXCHANGE RATE',\n",
       " 'POLISH ZLOTY TO US $ 1M FWD (TR) - SPOT OFFERED',\n",
       " 'POLISH ZLOTY TO US $ 1W FWD (TR) - BID SPOT',\n",
       " 'POLISH ZLOTY TO US $ 1W FWD (TR) - EXCHANGE RATE',\n",
       " 'POLISH ZLOTY TO US $ 1W FWD (TR) - SPOT OFFERED',\n",
       " 'RUSSIAN ROUBLE TO US $ 1M FWD (WMR) - BID SPOT',\n",
       " 'RUSSIAN ROUBLE TO US $ 1M FWD (WMR) - EXCHANGE RATE',\n",
       " 'RUSSIAN ROUBLE TO US $ 1M FWD (WMR) - SPOT OFFERED',\n",
       " 'RUSSIAN ROUBLE TO US $ 1W FWD (WMR) - BID SPOT',\n",
       " 'RUSSIAN ROUBLE TO US $ 1W FWD (WMR) - EXCHANGE RATE',\n",
       " 'RUSSIAN ROUBLE TO US $ 1W FWD (WMR) - SPOT OFFERED',\n",
       " 'SINGAPORE $ TO US $ 1M FWD (BBI) - BID SPOT',\n",
       " 'SINGAPORE $ TO US $ 1M FWD (BBI) - EXCHANGE RATE',\n",
       " 'SINGAPORE $ TO US $ 1M FWD (BBI) - SPOT OFFERED',\n",
       " 'SINGAPORE $ TO US $ 1W FWD (TR) - BID SPOT',\n",
       " 'SINGAPORE $ TO US $ 1W FWD (TR) - EXCHANGE RATE',\n",
       " 'SINGAPORE $ TO US $ 1W FWD (TR) - SPOT OFFERED',\n",
       " 'SOUTH AFRICA RAND TO US $ 1M FWD (TR) - BID SPOT',\n",
       " 'SOUTH AFRICA RAND TO US $ 1M FWD (TR) - EXCHANGE RATE',\n",
       " 'SOUTH AFRICA RAND TO US $ 1M FWD (TR) - SPOT OFFERED',\n",
       " 'SOUTH AFRICA RAND TO US $ 1W FWD (TR) - BID SPOT',\n",
       " 'SOUTH AFRICA RAND TO US $ 1W FWD (TR) - EXCHANGE RATE',\n",
       " 'SOUTH AFRICA RAND TO US $ 1W FWD (TR) - SPOT OFFERED',\n",
       " 'SWEDISH KRONA TO US $ 1M FWD (TR) - BID SPOT',\n",
       " 'SWEDISH KRONA TO US $ 1M FWD (TR) - EXCHANGE RATE',\n",
       " 'SWEDISH KRONA TO US $ 1M FWD (TR) - SPOT OFFERED',\n",
       " 'SWEDISH KRONA TO US $ 1W FWD (TR) - BID SPOT',\n",
       " 'SWEDISH KRONA TO US $ 1W FWD (TR) - EXCHANGE RATE',\n",
       " 'SWEDISH KRONA TO US $ 1W FWD (TR) - SPOT OFFERED',\n",
       " 'SWISS FRANC TO US $ 1M FWD (TR) - BID SPOT',\n",
       " 'SWISS FRANC TO US $ 1M FWD (TR) - EXCHANGE RATE',\n",
       " 'SWISS FRANC TO US $ 1M FWD (TR) - SPOT OFFERED',\n",
       " 'SWISS FRANC TO US $ 1W FWD (TR) - BID SPOT',\n",
       " 'SWISS FRANC TO US $ 1W FWD (TR) - EXCHANGE RATE',\n",
       " 'SWISS FRANC TO US $ 1W FWD (TR) - SPOT OFFERED',\n",
       " 'THAI BAHT TO US $ 1M FWD (WMR) - BID SPOT',\n",
       " 'THAI BAHT TO US $ 1M FWD (WMR) - EXCHANGE RATE',\n",
       " 'THAI BAHT TO US $ 1M FWD (WMR) - SPOT OFFERED',\n",
       " 'US $ TO GBP 1M FWD (TR) - BID SPOT',\n",
       " 'US $ TO GBP 1M FWD (TR) - EXCHANGE RATE',\n",
       " 'US $ TO GBP 1M FWD (TR) - SPOT OFFERED',\n",
       " 'US $ TO GBP 1W FWD (TR) - BID SPOT',\n",
       " 'US $ TO GBP 1W FWD (TR) - EXCHANGE RATE',\n",
       " 'US $ TO GBP 1W FWD (TR) - SPOT OFFERED',\n",
       " 'US $ TO AUD 1W FWD (LSEG DS) - BID SPOT',\n",
       " 'US $ TO AUD 1W FWD (LSEG DS) - EXCHANGE RATE',\n",
       " 'US $ TO AUD 1W FWD (LSEG DS) - SPOT OFFERED',\n",
       " 'US $ TO AUD 1M FWD (LSEG DS) - BID SPOT',\n",
       " 'US $ TO AUD 1M FWD (LSEG DS) - EXCHANGE RATE',\n",
       " 'US $ TO AUD 1M FWD (LSEG DS) - SPOT OFFERED',\n",
       " 'BRL TO USD 1M FWD OFF (LSEG DS) - BID SPOT',\n",
       " 'BRL TO USD 1M FWD OFF (LSEG DS) - EXCHANGE RATE',\n",
       " 'BRL TO USD 1M FWD OFF (LSEG DS) - SPOT OFFERED',\n",
       " 'BRL TO USD SW FWD OR (WMR) - BID SPOT',\n",
       " 'BRL TO USD SW FWD OR (WMR) - EXCHANGE RATE',\n",
       " 'BRL TO USD SW FWD OR (WMR) - SPOT OFFERED',\n",
       " 'CANADIAN $ TO US $ 1M FWD (BBI) - BID SPOT',\n",
       " 'CANADIAN $ TO US $ 1M FWD (BBI) - EXCHANGE RATE',\n",
       " 'CANADIAN $ TO US $ 1M FWD (BBI) - SPOT OFFERED',\n",
       " 'CAD TO USD 1W FWD (LSEG DS) - BID SPOT',\n",
       " 'CAD TO USD 1W FWD (LSEG DS) - EXCHANGE RATE',\n",
       " 'CAD TO USD 1W FWD (LSEG DS) - SPOT OFFERED',\n",
       " 'HRK TO USD 1M FWD OR (WMR) - BID SPOT',\n",
       " 'HRK TO USD 1M FWD OR (WMR) - EXCHANGE RATE',\n",
       " 'HRK TO USD 1M FWD OR (WMR) - SPOT OFFERED',\n",
       " 'HRK TO USD SW FWD OR (WMR) - BID SPOT',\n",
       " 'HRK TO USD SW FWD OR (WMR) - EXCHANGE RATE',\n",
       " 'HRK TO USD SW FWD OR (WMR) - SPOT OFFERED',\n",
       " 'CZK TO US $ 1M FWD (LSEG DS) - BID SPOT',\n",
       " 'CZK TO US $ 1M FWD (LSEG DS) - EXCHANGE RATE',\n",
       " 'CZK TO US $ 1M FWD (LSEG DS) - SPOT OFFERED',\n",
       " 'CZK TO US $ 1W FWD (LSEG DS) - BID SPOT',\n",
       " 'CZK TO US $ 1W FWD (LSEG DS) - EXCHANGE RATE',\n",
       " 'CZK TO US $ 1W FWD (LSEG DS) - SPOT OFFERED',\n",
       " 'US $ TO EURO 1M FWD (LSEG DS) - BID SPOT',\n",
       " 'US $ TO EURO 1M FWD (LSEG DS) - EXCHANGE RATE',\n",
       " 'US $ TO EURO 1M FWD (LSEG DS) - SPOT OFFERED',\n",
       " 'US $ TO EURO 1W (LSEG DS) - BID SPOT',\n",
       " 'US $ TO EURO 1W (LSEG DS) - EXCHANGE RATE',\n",
       " 'US $ TO EURO 1W (LSEG DS) - SPOT OFFERED',\n",
       " 'HUF TO USD 1M FWD OR (WMR) - BID SPOT',\n",
       " 'HUF TO USD 1M FWD OR (WMR) - EXCHANGE RATE',\n",
       " 'HUF TO USD 1M FWD OR (WMR) - SPOT OFFERED',\n",
       " 'HUF TO USD SW FWD OR (WMR) - BID SPOT',\n",
       " 'HUF TO USD SW FWD OR (WMR) - EXCHANGE RATE',\n",
       " 'HUF TO USD SW FWD OR (WMR) - SPOT OFFERED',\n",
       " 'INR TO USD 1M FWD OR (WMR) - BID SPOT',\n",
       " 'INR TO USD 1M FWD OR (WMR) - EXCHANGE RATE',\n",
       " 'INR TO USD 1M FWD OR (WMR) - SPOT OFFERED',\n",
       " 'INR TO USD SW FWD OR (WMR) - BID SPOT',\n",
       " 'INR TO USD SW FWD OR (WMR) - EXCHANGE RATE',\n",
       " 'INR TO USD SW FWD OR (WMR) - SPOT OFFERED',\n",
       " 'IDR TO USD 1M FWD OR (WMR) - BID SPOT',\n",
       " 'IDR TO USD 1M FWD OR (WMR) - EXCHANGE RATE',\n",
       " 'IDR TO USD 1M FWD OR (WMR) - SPOT OFFERED',\n",
       " 'IDR TO USD SW FWD OR (WMR) - BID SPOT',\n",
       " 'IDR TO USD SW FWD OR (WMR) - EXCHANGE RATE',\n",
       " 'IDR TO USD SW FWD OR (WMR) - SPOT OFFERED',\n",
       " 'ILS TO USD 1M FWD OR (WMR) - BID SPOT',\n",
       " 'ILS TO USD 1M FWD OR (WMR) - EXCHANGE RATE',\n",
       " 'ILS TO USD 1M FWD OR (WMR) - SPOT OFFERED',\n",
       " 'ILS TO USD SW FWD OR (WMR) - BID SPOT',\n",
       " 'ILS TO USD SW FWD OR (WMR) - EXCHANGE RATE',\n",
       " 'ILS TO USD SW FWD OR (WMR) - SPOT OFFERED',\n",
       " 'JPY TO US $ 1M FWD (LSEG DS) - BID SPOT',\n",
       " 'JPY TO US $ 1M FWD (LSEG DS) - EXCHANGE RATE',\n",
       " 'JPY TO US $ 1M FWD (LSEG DS) - SPOT OFFERED',\n",
       " 'JPY TO US $ 1W FWD (LSEG DS) - BID SPOT',\n",
       " 'JPY TO US $ 1W FWD (LSEG DS) - EXCHANGE RATE',\n",
       " 'JPY TO US $ 1W FWD (LSEG DS) - SPOT OFFERED',\n",
       " 'MXN TO USD 1M FWD OR (WMR) - BID SPOT',\n",
       " 'MXN TO USD 1M FWD OR (WMR) - EXCHANGE RATE',\n",
       " 'MXN TO USD 1M FWD OR (WMR) - SPOT OFFERED',\n",
       " 'MXN TO USD SW FWD OR (WMR) - BID SPOT',\n",
       " 'MXN TO USD SW FWD OR (WMR) - EXCHANGE RATE',\n",
       " 'MXN TO USD SW FWD OR (WMR) - SPOT OFFERED',\n",
       " 'US $ TO NZD 1M FWD (LSEG DS) - BID SPOT',\n",
       " 'US $ TO NZD 1M FWD (LSEG DS) - EXCHANGE RATE',\n",
       " 'US $ TO NZD 1M FWD (LSEG DS) - SPOT OFFERED',\n",
       " 'NOK TO US $ 1M FWD (LSEG DS) - BID SPOT',\n",
       " 'NOK TO US $ 1M FWD (LSEG DS) - BID SPOT',\n",
       " 'NOK TO US $ 1M FWD (LSEG DS) - EXCHANGE RATE',\n",
       " 'NOK TO US $ 1M FWD (LSEG DS) - SPOT OFFERED',\n",
       " 'NOK TO US $ 1W FWD (LSEG DS) - BID SPOT',\n",
       " 'NOK TO US $ 1W FWD (LSEG DS) - EXCHANGE RATE',\n",
       " 'NOK TO US $ 1W FWD (LSEG DS) - SPOT OFFERED',\n",
       " 'PHP TO USD 1M FWD OR (WMR) - BID SPOT',\n",
       " 'PHP TO USD 1M FWD OR (WMR) - EXCHANGE RATE',\n",
       " 'PHP TO USD 1M FWD OR (WMR) - SPOT OFFERED',\n",
       " 'PLN TO US $ 1M FWD (LSEG DS) - BID SPOT',\n",
       " 'PLN TO US $ 1M FWD (LSEG DS) - EXCHANGE RATE',\n",
       " 'PLN TO US $ 1M FWD (LSEG DS) - SPOT OFFERED',\n",
       " 'PLN TO US $ 1W FWD (LSEG DS) - BID SPOT',\n",
       " 'PLN TO US $ 1W FWD (LSEG DS) - EXCHANGE RATE',\n",
       " 'PLN TO US $ 1W FWD (LSEG DS) - SPOT OFFERED',\n",
       " 'RUB TO USD 1M FWD OR (WMR) - BID SPOT',\n",
       " 'RUB TO USD 1M FWD OR (WMR) - EXCHANGE RATE',\n",
       " 'RUB TO USD 1M FWD OR (WMR) - SPOT OFFERED',\n",
       " 'RUB TO USD SW FWD OR (WMR) - BID SPOT',\n",
       " 'RUB TO USD SW FWD OR (WMR) - EXCHANGE RATE',\n",
       " 'RUB TO USD SW FWD OR (WMR) - SPOT OFFERED',\n",
       " 'SINGAPORE $ TO US $ 1M FWD (BBI) - BID SPOT',\n",
       " 'SINGAPORE $ TO US $ 1M FWD (BBI) - EXCHANGE RATE',\n",
       " 'SINGAPORE $ TO US $ 1M FWD (BBI) - SPOT OFFERED',\n",
       " 'SINGAPORE $ TO US $ 1W FWD (LSEG DS) - BID SPOT',\n",
       " 'SINGAPORE $ TO US $ 1W FWD (LSEG DS) - EXCHANGE RATE',\n",
       " 'SINGAPORE $ TO US $ 1W FWD (LSEG DS) - SPOT OFFERED',\n",
       " 'ZAR TO USD 1M FWD (LSEG DS) - BID SPOT',\n",
       " 'ZAR TO USD 1M FWD (LSEG DS) - EXCHANGE RATE',\n",
       " 'ZAR TO USD 1M FWD (LSEG DS) - SPOT OFFERED',\n",
       " 'ZAR TO USD 1W FWD (LSEG DS) - BID SPOT',\n",
       " 'ZAR TO USD 1W FWD (LSEG DS) - EXCHANGE RATE',\n",
       " 'ZAR TO USD 1W FWD (LSEG DS) - SPOT OFFERED',\n",
       " 'SEK TO US $ 1M FWD (LSEG DS) - BID SPOT',\n",
       " 'SEK TO US $ 1M FWD (LSEG DS) - EXCHANGE RATE',\n",
       " 'SEK TO US $ 1M FWD (LSEG DS) - SPOT OFFERED',\n",
       " 'SEK TO US $ 1W FWD (LSEG DS) - BID SPOT',\n",
       " 'SEK TO US $ 1W FWD (LSEG DS) - EXCHANGE RATE',\n",
       " 'SEK TO US $ 1W FWD (LSEG DS) - SPOT OFFERED',\n",
       " 'SWISS FRANC TO US $ 1M FWD (LSEG DS) - BID SPOT',\n",
       " 'SWISS FRANC TO US $ 1M FWD (LSEG DS) - EXCHANGE RATE',\n",
       " 'SWISS FRANC TO US $ 1M FWD (LSEG DS) - SPOT OFFERED',\n",
       " 'SWISS FRANC TO US $ 1W FWD (LSEG DS) - BID SPOT',\n",
       " 'SWISS FRANC TO US $ 1W FWD (LSEG DS) - EXCHANGE RATE',\n",
       " 'SWISS FRANC TO US $ 1W FWD (LSEG DS) - SPOT OFFERED',\n",
       " 'THB TO USD 1M FWD OR (WMR) - BID SPOT',\n",
       " 'THB TO USD 1M FWD OR (WMR) - EXCHANGE RATE',\n",
       " 'THB TO USD 1M FWD OR (WMR) - SPOT OFFERED',\n",
       " 'US $ TO GBP 1M FWD (LSEG DS) - BID SPOT',\n",
       " 'US $ TO GBP 1M FWD (LSEG DS) - EXCHANGE RATE',\n",
       " 'US $ TO GBP 1M FWD (LSEG DS) - SPOT OFFERED',\n",
       " 'US $ TO GBP 1W FWD (LSEG DS) - BID SPOT',\n",
       " 'US $ TO GBP 1W FWD (LSEG DS) - EXCHANGE RATE',\n",
       " 'US $ TO GBP 1W FWD (LSEG DS) - SPOT OFFERED']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uk_col = [col for col in df_forward if 'EURO' in col]\n",
    "usd_columns_fwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15761fe0-427f-4f87-a749-a301b8b91b29",
   "metadata": {},
   "source": [
    "# **Data Pre - Processing**\n",
    "Here we will run some pre - treatment prior to executing strategies for both spot and forward dataframes\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a67d5e-bda0-4884-a4f6-a959afcdeb3f",
   "metadata": {},
   "source": [
    "## Spot dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a43d05b-5e8c-426d-9d1e-b87674d7eb1e",
   "metadata": {},
   "source": [
    "### Computing of the XUSD spot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba562d9c-9cd6-4f06-8ac5-3dc6f7d78da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUSTRALIAN_BID</th>\n",
       "      <th>AUSTRALIAN_ER</th>\n",
       "      <th>AUSTRALIAN_OFFER</th>\n",
       "      <th>BRAZILIAN_BID</th>\n",
       "      <th>BRAZILIAN_ER</th>\n",
       "      <th>BRAZILIAN_OFFER</th>\n",
       "      <th>BULGARIAN_BID</th>\n",
       "      <th>BULGARIAN_ER</th>\n",
       "      <th>BULGARIAN_OFFER</th>\n",
       "      <th>CANADIAN_BID</th>\n",
       "      <th>...</th>\n",
       "      <th>SWEDISH_OFFER</th>\n",
       "      <th>SWISS_BID</th>\n",
       "      <th>SWISS_ER</th>\n",
       "      <th>SWISS_OFFER</th>\n",
       "      <th>THAI_BID</th>\n",
       "      <th>THAI_ER</th>\n",
       "      <th>THAI_OFFER</th>\n",
       "      <th>UK_BID</th>\n",
       "      <th>UK_ER</th>\n",
       "      <th>UK_OFFER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1998-01-01</th>\n",
       "      <td>0.651112</td>\n",
       "      <td>0.651546</td>\n",
       "      <td>0.652007</td>\n",
       "      <td>0.895682</td>\n",
       "      <td>0.896014</td>\n",
       "      <td>0.896345</td>\n",
       "      <td>0.560139</td>\n",
       "      <td>0.560224</td>\n",
       "      <td>0.560309</td>\n",
       "      <td>0.698467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126108</td>\n",
       "      <td>0.685144</td>\n",
       "      <td>0.685591</td>\n",
       "      <td>0.686038</td>\n",
       "      <td>0.020655</td>\n",
       "      <td>0.020768</td>\n",
       "      <td>0.020883</td>\n",
       "      <td>1.6451</td>\n",
       "      <td>1.64535</td>\n",
       "      <td>1.6456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-01-02</th>\n",
       "      <td>0.649301</td>\n",
       "      <td>0.649949</td>\n",
       "      <td>0.650599</td>\n",
       "      <td>0.895208</td>\n",
       "      <td>0.896068</td>\n",
       "      <td>0.896929</td>\n",
       "      <td>0.560053</td>\n",
       "      <td>0.560224</td>\n",
       "      <td>0.560395</td>\n",
       "      <td>0.700880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125620</td>\n",
       "      <td>0.680920</td>\n",
       "      <td>0.681495</td>\n",
       "      <td>0.682071</td>\n",
       "      <td>0.020649</td>\n",
       "      <td>0.020768</td>\n",
       "      <td>0.020890</td>\n",
       "      <td>1.6402</td>\n",
       "      <td>1.64070</td>\n",
       "      <td>1.6412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-01-05</th>\n",
       "      <td>0.642280</td>\n",
       "      <td>0.642941</td>\n",
       "      <td>0.643603</td>\n",
       "      <td>0.895534</td>\n",
       "      <td>0.895997</td>\n",
       "      <td>0.896510</td>\n",
       "      <td>0.551438</td>\n",
       "      <td>0.551572</td>\n",
       "      <td>0.551707</td>\n",
       "      <td>0.701555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125008</td>\n",
       "      <td>0.676355</td>\n",
       "      <td>0.676954</td>\n",
       "      <td>0.677553</td>\n",
       "      <td>0.019990</td>\n",
       "      <td>0.020040</td>\n",
       "      <td>0.020090</td>\n",
       "      <td>1.6382</td>\n",
       "      <td>1.63860</td>\n",
       "      <td>1.6390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-01-06</th>\n",
       "      <td>0.632139</td>\n",
       "      <td>0.632667</td>\n",
       "      <td>0.633171</td>\n",
       "      <td>0.895600</td>\n",
       "      <td>0.895989</td>\n",
       "      <td>0.896427</td>\n",
       "      <td>0.550087</td>\n",
       "      <td>0.550205</td>\n",
       "      <td>0.550323</td>\n",
       "      <td>0.698306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124224</td>\n",
       "      <td>0.676488</td>\n",
       "      <td>0.677025</td>\n",
       "      <td>0.677536</td>\n",
       "      <td>0.019094</td>\n",
       "      <td>0.019157</td>\n",
       "      <td>0.019221</td>\n",
       "      <td>1.6325</td>\n",
       "      <td>1.63285</td>\n",
       "      <td>1.6332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-01-07</th>\n",
       "      <td>0.639301</td>\n",
       "      <td>0.639802</td>\n",
       "      <td>0.640304</td>\n",
       "      <td>0.894986</td>\n",
       "      <td>0.895272</td>\n",
       "      <td>0.895607</td>\n",
       "      <td>0.548763</td>\n",
       "      <td>0.548848</td>\n",
       "      <td>0.548932</td>\n",
       "      <td>0.697437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124250</td>\n",
       "      <td>0.676157</td>\n",
       "      <td>0.676599</td>\n",
       "      <td>0.677013</td>\n",
       "      <td>0.018809</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.018927</td>\n",
       "      <td>1.6244</td>\n",
       "      <td>1.62465</td>\n",
       "      <td>1.6249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            AUSTRALIAN_BID  AUSTRALIAN_ER  AUSTRALIAN_OFFER  BRAZILIAN_BID  \\\n",
       "1998-01-01        0.651112       0.651546          0.652007       0.895682   \n",
       "1998-01-02        0.649301       0.649949          0.650599       0.895208   \n",
       "1998-01-05        0.642280       0.642941          0.643603       0.895534   \n",
       "1998-01-06        0.632139       0.632667          0.633171       0.895600   \n",
       "1998-01-07        0.639301       0.639802          0.640304       0.894986   \n",
       "\n",
       "            BRAZILIAN_ER  BRAZILIAN_OFFER  BULGARIAN_BID  BULGARIAN_ER  \\\n",
       "1998-01-01      0.896014         0.896345       0.560139      0.560224   \n",
       "1998-01-02      0.896068         0.896929       0.560053      0.560224   \n",
       "1998-01-05      0.895997         0.896510       0.551438      0.551572   \n",
       "1998-01-06      0.895989         0.896427       0.550087      0.550205   \n",
       "1998-01-07      0.895272         0.895607       0.548763      0.548848   \n",
       "\n",
       "            BULGARIAN_OFFER  CANADIAN_BID  ...  SWEDISH_OFFER  SWISS_BID  \\\n",
       "1998-01-01         0.560309      0.698467  ...       0.126108   0.685144   \n",
       "1998-01-02         0.560395      0.700880  ...       0.125620   0.680920   \n",
       "1998-01-05         0.551707      0.701555  ...       0.125008   0.676355   \n",
       "1998-01-06         0.550323      0.698306  ...       0.124224   0.676488   \n",
       "1998-01-07         0.548932      0.697437  ...       0.124250   0.676157   \n",
       "\n",
       "            SWISS_ER  SWISS_OFFER  THAI_BID   THAI_ER  THAI_OFFER  UK_BID  \\\n",
       "1998-01-01  0.685591     0.686038  0.020655  0.020768    0.020883  1.6451   \n",
       "1998-01-02  0.681495     0.682071  0.020649  0.020768    0.020890  1.6402   \n",
       "1998-01-05  0.676954     0.677553  0.019990  0.020040    0.020090  1.6382   \n",
       "1998-01-06  0.677025     0.677536  0.019094  0.019157    0.019221  1.6325   \n",
       "1998-01-07  0.676599     0.677013  0.018809  0.018868    0.018927  1.6244   \n",
       "\n",
       "              UK_ER  UK_OFFER  \n",
       "1998-01-01  1.64535    1.6456  \n",
       "1998-01-02  1.64070    1.6412  \n",
       "1998-01-05  1.63860    1.6390  \n",
       "1998-01-06  1.63285    1.6332  \n",
       "1998-01-07  1.62465    1.6249  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================================================\n",
    "# Build metadata (Cur1 / Cur2 / Type)\n",
    "# =========================================================\n",
    "# Extract the currency structure and associated quote type for each column.\n",
    "# Titles follow the pattern: \"<CUR1> TO <CUR2> - <QUOTE TYPE>\".\n",
    "# We standardize the quote nature into BID, OFFER, or ER (exchange rate mid).\n",
    "\n",
    "records = []\n",
    "\n",
    "for (title, code) in df_spot.columns:\n",
    "    # Identify base and quote currencies from the \"CUR1 TO CUR2\" portion\n",
    "    left, right = title.split(\"TO\")\n",
    "    cur1 = left.strip().split()[0].upper()\n",
    "    cur2 = right.strip().split()[0].upper()\n",
    "    \n",
    "    # Extract the descriptive quote label from the suffix (e.g. \"BID SPOT\")\n",
    "    raw_nature = title.split(\"-\")[-1].strip().upper()\n",
    "\n",
    "    # Convert the descriptive label to a standardized quote type\n",
    "    if \"BID\" in raw_nature:\n",
    "        price_type = \"BID\"\n",
    "    elif \"OFFER\" in raw_nature:\n",
    "        price_type = \"OFFER\"\n",
    "    elif \"EXCHANGE\" in raw_nature:\n",
    "        price_type = \"ER\"\n",
    "    else:\n",
    "        price_type = \"OTHER\"\n",
    "\n",
    "    records.append({\n",
    "        \"Title\": title,\n",
    "        \"Code\": code,\n",
    "        \"Cur1\": cur1,\n",
    "        \"Cur2\": cur2,\n",
    "        \"RawNature\": raw_nature,\n",
    "        \"Type\": price_type\n",
    "    })\n",
    "\n",
    "meta = pd.DataFrame(records, index=df_spot.columns)\n",
    "\n",
    "# Ensure consistent MultiIndex formatting across df_spot and metadata\n",
    "df_spot.columns = pd.MultiIndex.from_tuples([(str(a), str(b)) for a, b in df_spot.columns])\n",
    "meta.index       = pd.MultiIndex.from_tuples([(str(a), str(b)) for a, b in meta.index])\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Helpers\n",
    "# =========================================================\n",
    "\n",
    "def get_leg(cur1, cur2, typ):\n",
    "    \"\"\"\n",
    "    Select the time series corresponding to a specific currency pair (cur1 → cur2)\n",
    "    and quote type (BID, OFFER, ER). Returns None if the requested leg is missing.\n",
    "    \"\"\"\n",
    "    mask = (meta[\"Cur1\"] == cur1) & (meta[\"Cur2\"] == cur2) & (meta[\"Type\"] == typ)\n",
    "    idx = meta.index[mask]\n",
    "    if len(idx) == 0:\n",
    "        return None\n",
    "    return df_spot[idx[0]]\n",
    "\n",
    "\n",
    "def invert_bid_ask(bid, ask):\n",
    "    \"\"\"\n",
    "    Convert an X/USD bid-ask pair into the corresponding USD/X pair.\n",
    "    The inverted bid equals 1/ask and the inverted ask equals 1/bid.\n",
    "    \"\"\"\n",
    "    return 1/ask, 1/bid\n",
    "\n",
    "# Some quotes are missing we will thus input the missing values using the quote present in the dataframe \n",
    "\n",
    "\n",
    "def complete_quotes(bid, offer, mid):\n",
    "    if bid is None and offer is None and mid is None:\n",
    "        return None, None, None\n",
    "\n",
    "    # Convert to series\n",
    "    b = bid.copy() if bid is not None else None\n",
    "    o = offer.copy() if offer is not None else None\n",
    "    m = mid.copy() if mid is not None else None\n",
    "\n",
    "    # Ensure all exist\n",
    "    if b is None:\n",
    "        b = pd.Series(index=o.index if o is not None else m.index, dtype=float)\n",
    "    if o is None:\n",
    "        o = pd.Series(index=b.index if b is not None else m.index, dtype=float)\n",
    "    if m is None:\n",
    "        m = pd.Series(index=b.index if b is not None else o.index, dtype=float)\n",
    "\n",
    "    # 1. Fill mid when possible\n",
    "    mask_mid = m.isna() & b.notna() & o.notna()\n",
    "    m.loc[mask_mid] = (b.loc[mask_mid] + o.loc[mask_mid]) / 2\n",
    "\n",
    "    # 2. Fill bid when possible\n",
    "    mask_bid = b.isna() & m.notna() & o.notna()\n",
    "    b.loc[mask_bid] = 2 * m.loc[mask_bid] - o.loc[mask_bid]\n",
    "\n",
    "    # 3. Fill offer when possible\n",
    "    mask_offer = o.isna() & m.notna() & b.notna()\n",
    "    o.loc[mask_offer] = 2 * m.loc[mask_offer] - b.loc[mask_offer]\n",
    "\n",
    "    # 4. Last resort: if both bid & offer missing but mid exists\n",
    "    mask_both = b.isna() & o.isna() & m.notna()\n",
    "    b.loc[mask_both] = m.loc[mask_both]\n",
    "    o.loc[mask_both] = m.loc[mask_both]\n",
    "\n",
    "    return b, o, m\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Build USDX = X per USD\n",
    "# =========================================================\n",
    "# Construct quotes expressing the value of 1 USD in each foreign currency.\n",
    "# Direct USD→X quotes are used when available; otherwise, cross rates are\n",
    "# reconstructed using pivot currencies.\n",
    "\n",
    "usdx = pd.DataFrame(index=df_spot.index)\n",
    "\n",
    "# List all currencies appearing in Cur1 or Cur2, excluding USD\n",
    "currencies = set(meta[\"Cur1\"].unique()) | set(meta[\"Cur2\"].unique())\n",
    "currencies.discard(\"US\")\n",
    "\n",
    "# Start with direct USD→UK and USD→EURO pairs\n",
    "for tgt in [\"UK\", \"EURO\"]:\n",
    "    bid_X_USD   = get_leg(\"US\", tgt, \"BID\")\n",
    "    offer_X_USD = get_leg(\"US\", tgt, \"OFFER\")\n",
    "    mid_X_USD   = get_leg(\"US\", tgt, \"ER\")\n",
    "\n",
    "    # Fill missing values if necessary\n",
    "    bid_X_USD, offer_X_USD, mid_X_USD = complete_quotes(bid_X_USD, offer_X_USD, mid_X_USD)\n",
    "\n",
    "    if bid_X_USD is not None and offer_X_USD is not None:\n",
    "        # Convert X/USD quotes into USD→X using bid/ask inversion\n",
    "        bid_USD_X, offer_USD_X = invert_bid_ask(bid_X_USD, offer_X_USD)\n",
    "        mid_USD_X = 1/mid_X_USD\n",
    "\n",
    "        usdx[f\"{tgt}_BID\"]   = bid_USD_X\n",
    "        usdx[f\"{tgt}_OFFER\"] = offer_USD_X\n",
    "        usdx[f\"{tgt}_ER\"]    = mid_USD_X\n",
    "\n",
    "\n",
    "# Compute cross USD→X rates via pivot currencies when no direct quote exists\n",
    "pivots = [\"UK\", \"EURO\"]\n",
    "\n",
    "for cur in sorted(currencies):\n",
    "    if cur in [\"UK\", \"EURO\"]:\n",
    "        continue\n",
    "\n",
    "    for pivot in pivots:\n",
    "\n",
    "        # Retrieve X→pivot legs\n",
    "        bid_X_P   = get_leg(cur,  pivot, \"BID\")\n",
    "        offer_X_P = get_leg(cur,  pivot, \"OFFER\")\n",
    "        mid_X_P   = get_leg(cur,  pivot, \"ER\")\n",
    "\n",
    "        # Retrieve USD→pivot legs\n",
    "        bid_US_P   = get_leg(\"US\", pivot, \"BID\")\n",
    "        offer_US_P = get_leg(\"US\", pivot, \"OFFER\")\n",
    "        mid_US_P   = get_leg(\"US\", pivot, \"ER\")\n",
    "\n",
    "        # Complete missing values before using them\n",
    "        bid_X_P, offer_X_P, mid_X_P = complete_quotes(bid_X_P, offer_X_P, mid_X_P)\n",
    "        bid_US_P, offer_US_P, mid_US_P = complete_quotes(bid_US_P, offer_US_P, mid_US_P)\n",
    "        # Skip if still incomplete (very unlikely after correction)\n",
    "        if bid_X_P is None or offer_X_P is None or bid_US_P is None or offer_US_P is None:\n",
    "            continue\n",
    "\n",
    "        # Compute X per USD via the pivot:\n",
    "        # Sequence: USD→pivot (using ask), then pivot→X (using bid)\n",
    "        bid_USD_X   = bid_X_P   / offer_US_P\n",
    "        offer_USD_X = offer_X_P / bid_US_P\n",
    "        mid_USD_X   = mid_X_P / mid_US_P\n",
    "\n",
    "        usdx[f\"{cur}_BID\"]   = bid_USD_X\n",
    "        usdx[f\"{cur}_OFFER\"] = offer_USD_X\n",
    "        usdx[f\"{cur}_ER\"]    = mid_USD_X\n",
    "\n",
    "        break\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Convert USDX → XUSD (final quoting convention)\n",
    "# =========================================================\n",
    "# Invert each USD→X quote to obtain the final XUSD convention (USD per unit of X).\n",
    "# Bid and ask are swapped upon inversion.\n",
    "\n",
    "xusd_df = pd.DataFrame(index=usdx.index)\n",
    "\n",
    "for col in usdx.columns:\n",
    "    cur, typ = col.split(\"_\")\n",
    "\n",
    "    if typ == \"BID\":\n",
    "        xusd_df[f\"{cur}_OFFER\"] = 1 / usdx[col]\n",
    "\n",
    "    elif typ == \"OFFER\":\n",
    "        xusd_df[f\"{cur}_BID\"]   = 1 / usdx[col]\n",
    "\n",
    "    else:  # ER (mid)\n",
    "        xusd_df[f\"{cur}_ER\"]    = 1 / usdx[col]\n",
    "\n",
    "xusd_df = xusd_df.sort_index(axis=1)\n",
    "xusd_df.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa7c0d4-5e2e-444a-ae49-85812d48ba61",
   "metadata": {},
   "source": [
    "### Coherence of the spot obtained \n",
    "The first thing to do here is to verify the coherence of our computing, to do this we have several ressources, chatgpt and other AI tool may help us quickly review our code but to check the coherence of our data we can look at some spots on Yfinance or do it empirically as we've done below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c25078-25f1-4509-a107-e95840644fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnary containing the index of the comparison dataframe and the yfinance ticker to extract market data\n",
    "fx_map = {\n",
    "    \"UK\": \"GBPUSD=X\",\n",
    "    \"EURO\": \"EURUSD=X\",\n",
    "    \"PHILIPPINE\": \"PHPUSD=X\",\n",
    "    \"CANADIAN\": \"CADUSD=X\",\n",
    "    \"NORWEGIAN\": \"NOKUSD=X\",\n",
    "    \"NEW\": \"NZDUSD=X\",\n",
    "    \"CZECH\": \"CZKUSD=X\",\n",
    "    \"HUNGARIAN\": \"HUFUSD=X\",\n",
    "    \"POLISH\": \"PLNUSD=X\",\n",
    "    \"SINGAPORE\": \"SGDUSD=X\",\n",
    "    \"RUSSIAN\": \"RUBUSD=X\",\n",
    "    \"INDIAN\": \"INRUSD=X\",\n",
    "    \"SOUTH\": \"ZARUSD=X\",\n",
    "    \"INDONESIAN\": \"IDRUSD=X\",\n",
    "    \"BULGARIAN\": \"BGNUSD=X\",\n",
    "    \"ISRAELI\": \"ILSUSD=X\",\n",
    "    \"JAPANESE\": \"JPYUSD=X\",\n",
    "    \"BRAZILIAN\": \"BRLUSD=X\",\n",
    "    \"SWEDISH\": \"SEKUSD=X\",\n",
    "    \"THAI\": \"THBUSD=X\",\n",
    "    \"AUSTRALIAN\": \"AUDUSD=X\",\n",
    "    \"SWISS\": \"CHFUSD=X\",\n",
    "    \"MEXICAN\": \"MXNUSD=X\",\n",
    "    \"CHILEAN\": \"CLPUSD=X\",\n",
    "}\n",
    "\n",
    "target_date = \"2024-10-23\"\n",
    "results = {}\n",
    "\n",
    "for name, ticker in fx_map.items():\n",
    "    try:\n",
    "        data = yf.download(\n",
    "            ticker,\n",
    "            start=\"2024-10-23\",\n",
    "            end=\"2024-10-24\",\n",
    "            progress=False,\n",
    "            auto_adjust=False\n",
    "        )\n",
    "        \n",
    "        # If no data → record NaN\n",
    "        if data.empty:\n",
    "            results[name+\"_ER\"] = float(\"nan\")\n",
    "            continue\n",
    "        \n",
    "        # Look for the exact date\n",
    "        date_match = data.loc[data.index.strftime(\"%Y-%m-%d\") == target_date]\n",
    "        \n",
    "        if len(date_match) == 0:\n",
    "            results[name+\"_ER\"] = float(\"nan\")\n",
    "        else:\n",
    "            results[name+\"_ER\"] = date_match[\"Close\"].iloc[0]\n",
    "    \n",
    "    except Exception:\n",
    "        results[name] = float(\"nan\")\n",
    "\n",
    "clean_results = {k: float(v.iloc[0])for k, v in results.items()}\n",
    "df_check = pd.DataFrame.from_dict(clean_results,orient=\"index\", columns=[\"USD per X\"]) # dataframe \n",
    "\n",
    "\n",
    "# DATA comparison \n",
    "row_model = xusd_df.loc[target_date]\n",
    "row_model.name = \"USD_per_X_professor_data\"\n",
    "df_model = row_model.to_frame(name=\"USD_per_X_model\")\n",
    "comparison = df_model.join(df_check, how=\"inner\")\n",
    "comparison[\"abs_diff\"] = comparison[\"USD_per_X_model\"] - comparison[\"USD per X\"]\n",
    "comparison[\"rel_diff(%)\"] = comparison[\"abs_diff\"] / comparison[\"USD per X\"] * 100\n",
    "\n",
    "print(comparison.sort_values(\"rel_diff(%)\").head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6564f1-2dbf-485f-9e40-97e8d5cfee94",
   "metadata": {},
   "source": [
    "Once the verification is done, we can pursue our calculus without worrying about wether our currency pairs are quoted in the wrong direction. First and foremost we will thus start by computing some log returns -> we pick this because it has the nice property that the returns are additive and because the subject encourage us to go this way "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50205344-4ea8-4595-b20d-008d41158e4a",
   "metadata": {},
   "source": [
    "## Forward dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2059a659-8251-4dd3-86bb-9aa5c4a38845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# Ensure all columns are 1D numeric arrays\n",
    "# =========================================================\n",
    "\n",
    "def force_1d(df):\n",
    "    df2 = df.copy()\n",
    "    for c in df2.columns:\n",
    "        col = df2[c]\n",
    "\n",
    "        if any(isinstance(x, np.ndarray) for x in col):\n",
    "            df2[c] = col.apply(lambda x: x.flatten()[0] if isinstance(x, np.ndarray) else x)\n",
    "\n",
    "        arr = df2[c].to_numpy()\n",
    "        if isinstance(arr, np.ndarray) and arr.ndim == 2:\n",
    "            df2[c] = arr[:, 0]\n",
    "\n",
    "        try:\n",
    "            df2[c] = pd.to_numeric(df2[c], errors=\"coerce\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return df2\n",
    "\n",
    "\n",
    "df_forward = force_1d(df_forward)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Extract source tag from column title\n",
    "# =========================================================\n",
    "\n",
    "def extract_source(title):\n",
    "    parts = re.findall(r\"\\((.*?)\\)\", title.upper())\n",
    "    return parts[-1].strip() if parts else \"UNK\"\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Currency normalization\n",
    "# =========================================================\n",
    "\n",
    "CURRENCY_MAP = {\n",
    "    \"AUD\": \"AUSTRALIAN\",\"AUSTRALIAN\": \"AUSTRALIAN\",\n",
    "    \"EUR\": \"EURO\", \"EURO\": \"EURO\",\n",
    "    \"GBP\": \"UK\",\"UK\": \"UK\",\n",
    "    \"NZD\": \"NEW\", \"NEW\": \"NEW\",\n",
    "    \"BRL\": \"BRAZILIAN\",   \"BRAZILIAN\": \"BRAZILIAN\",\n",
    "    \"CAD\": \"CANADIAN\",    \"CANADIAN\": \"CANADIAN\",\n",
    "    \"HRK\": \"CROATIAN\",    \"CROATIAN\": \"CROATIAN\",\n",
    "    \"CZK\": \"CZECH\",       \"CZECH\": \"CZECH\",\n",
    "    \"HUF\": \"HUNGARIAN\",   \"HUNGARIAN\": \"HUNGARIAN\",\n",
    "    \"INR\": \"INDIAN\",      \"INDIAN\": \"INDIAN\",\n",
    "    \"IDR\": \"INDONESIAN\",  \"INDONESIAN\": \"INDONESIAN\",\n",
    "    \"ILS\": \"ISRAELI\",     \"ISRAELI\": \"ISRAELI\",\n",
    "    \"JPY\": \"JAPANESE\",    \"JAPANESE\": \"JAPANESE\",\n",
    "    \"MXN\": \"MEXICAN\",     \"MEXICAN\": \"MEXICAN\",\n",
    "    \"NOK\": \"NORWEGIAN\",   \"NORWEGIAN\": \"NORWEGIAN\",\n",
    "    \"PHP\": \"PHILIPPINE\",  \"PHILIPPINE\": \"PHILIPPINE\",\n",
    "    \"PLN\": \"POLISH\",      \"POLISH\": \"POLISH\",\n",
    "    \"RUB\": \"RUSSIAN\",     \"RUSSIAN\": \"RUSSIAN\",\n",
    "    \"SGD\": \"SINGAPORE\",   \"SINGAPORE\": \"SINGAPORE\",\n",
    "    \"ZAR\": \"SOUTH\",       \"SOUTH\": \"SOUTH\",\n",
    "    \"SEK\": \"SWEDISH\",     \"SWEDISH\": \"SWEDISH\",\n",
    "    \"CHF\": \"SWISS\",       \"SWISS\": \"SWISS\",\n",
    "    \"THB\": \"THAI\",        \"THAI\": \"THAI\",\n",
    "}\n",
    "\n",
    "\n",
    "def clean_cur(raw):\n",
    "    raw = re.sub(r\"[^A-Z]\", \"\", raw.upper())\n",
    "    return CURRENCY_MAP.get(raw, raw)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Resolve duplicate column names (same currency/type)\n",
    "# =========================================================\n",
    "\n",
    "def unique_name(base, container):\n",
    "    if base not in container:\n",
    "        return base\n",
    "    i = 2\n",
    "    while f\"{base}_{i}\" in container:\n",
    "        i += 1\n",
    "    return f\"{base}_{i}\"\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Build cleaned forward datasets: 1M and 1W\n",
    "# =========================================================\n",
    "\n",
    "def build_forward_clean(df):\n",
    "    usd_cols = [c for c in df.columns if \" US\" in c or \"US \" in c]\n",
    "    df = df.sort_index()\n",
    "    df.index = pd.to_datetime(df.index).normalize()\n",
    "    data_1M = {}\n",
    "    data_1W = {}\n",
    "\n",
    "    for col in usd_cols:\n",
    "        t = col.upper()\n",
    "        if \"TO\" not in t:\n",
    "            continue\n",
    "        left = t.split(\"TO\", 1)[0].strip()\n",
    "        right = t.split(\"TO\", 1)[1].strip()\n",
    "        cur_left = clean_cur(left.split()[0])\n",
    "        cur_right = clean_cur(right.split()[0])\n",
    "                   \n",
    "        if \"1M\" in t:\n",
    "            tenor = \"1M\"\n",
    "        elif (\"1W\" in t) or (\"SW\" in t):\n",
    "            tenor = \"1W\"\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        if \"BID\" in t:\n",
    "            typ = \"BID\"\n",
    "        elif \"OFFER\" in t:\n",
    "            typ = \"OFFER\"\n",
    "        elif \"EXCHANGE RATE\" in t:\n",
    "            typ = \"ER\"\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        src = extract_source(col)\n",
    "        \n",
    "        arr = df[col].to_numpy()\n",
    "        if arr.ndim > 1:\n",
    "            arr = arr[:, 0]\n",
    "            \n",
    "        if cur_left in (\"US\", \"USD\") and cur_right not in (\"US\", \"USD\"): \n",
    "            base = f\"{cur_right}_{typ}_{src}\"\n",
    "            if tenor == \"1M\":\n",
    "                name = unique_name(base, data_1M)\n",
    "                data_1M[name] = arr\n",
    "            else:\n",
    "                name = unique_name(base, data_1W)\n",
    "                data_1W[name] = arr\n",
    "                \n",
    "        elif cur_left not in (\"US\", \"USD\") and cur_right in (\"US\", \"USD\"): \n",
    "            base = f\"{cur_left}_{typ}_{src}\"\n",
    "            if tenor == \"1M\":\n",
    "                name = unique_name(base, data_1M)\n",
    "                data_1M[name] = 1/arr\n",
    "            else:\n",
    "                name = unique_name(base, data_1W)\n",
    "                data_1W[name] = 1/arr\n",
    "\n",
    "\n",
    "       \n",
    "\n",
    "        \n",
    "    fwd_1M = pd.DataFrame(data_1M, index=df.index).sort_index(axis=1)\n",
    "    fwd_1W = pd.DataFrame(data_1W, index=df.index).sort_index(axis=1)\n",
    "\n",
    "    return fwd_1M, fwd_1W\n",
    "\n",
    "\n",
    "forward_1M, forward_1W = build_forward_clean(df_forward)\n",
    "forward_1W.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbbc2fd-9876-4af0-83a9-772b4ccee948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# Source priority for forward merging\n",
    "# =========================================================\n",
    "\n",
    "SOURCE_PRIORITY = [\"LSEG DS\", \"LSEG\", \"BBI\", \"TR\", \"WMR\", \"UNK\"]\n",
    "\n",
    "def source_rank(src):\n",
    "    src = src.upper()\n",
    "    for i, s in enumerate(SOURCE_PRIORITY):\n",
    "        if s.upper() in src:\n",
    "            return i\n",
    "    return len(SOURCE_PRIORITY)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Merge duplicated forward columns (same CUR + TYPE)\n",
    "# =========================================================\n",
    "\n",
    "def fuse_duplicates(df):\n",
    "    \"\"\"\n",
    "    Fusionne les forwards par devise et reconstruit un triplet BID/OFFER/ER complet.\n",
    "    \"\"\"\n",
    "    final = {}\n",
    "\n",
    "    # construit un mapping {currency: {BID: [cols...], OFFER: [...], ER: [...]}}\n",
    "    groups = {}\n",
    "    for col in df.columns:\n",
    "        parts = col.split(\"_\")\n",
    "        if len(parts) < 3:\n",
    "            continue\n",
    "        cur, typ = parts[0], parts[1]\n",
    "        src = \"_\".join(parts[2:])\n",
    "        groups.setdefault(cur, {}).setdefault(typ, []).append((col, src))\n",
    "\n",
    "    # fusion par devise\n",
    "    for cur, type_dict in groups.items():\n",
    "\n",
    "        # fonctions utilitaires\n",
    "        def merge_type(type_name):\n",
    "            if type_name not in type_dict:\n",
    "                return None\n",
    "            cols = type_dict[type_name]\n",
    "            cols_sorted = sorted(cols, key=lambda x: source_rank(x[1]))\n",
    "            merged = df[cols_sorted[0][0]].copy()\n",
    "            for col_name, _ in cols_sorted[1:]:\n",
    "                merged = merged.fillna(df[col_name])\n",
    "            return merged\n",
    "\n",
    "        b = merge_type(\"BID\")\n",
    "        o = merge_type(\"OFFER\")\n",
    "        m = merge_type(\"ER\")\n",
    "\n",
    "        # reconstruction complète ici (et seulement ici)\n",
    "        b2, o2, m2 = complete_quotes(b, o, m)\n",
    "\n",
    "        final[f\"{cur}_BID\"]   = b2\n",
    "        final[f\"{cur}_OFFER\"] = o2\n",
    "        final[f\"{cur}_ER\"]    = m2\n",
    "\n",
    "    out = pd.DataFrame(final, index=df.index)\n",
    "    return out.sort_index(axis=1)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Usage\n",
    "# =========================================================\n",
    "\n",
    "forward_1M = fuse_duplicates(forward_1M)\n",
    "forward_1W = fuse_duplicates(forward_1W)\n",
    "forward_1M.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e10699-3d57-4174-b512-03d43af8b1dd",
   "metadata": {},
   "source": [
    "### Coherence of the forward obtained \n",
    "The first thing to do here is to verify the coherence of our computing, to do this we have several ressources, chatgpt and other AI tool may help us quickly review our code but to check the coherence of our data we can look at some spots on Yfinance or do it empirically as we've done below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8591786c-25fd-4fab-8f83-063728643f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnary containing the index of the comparison dataframe and the yfinance ticker to extract market data\n",
    "fx_map = {\n",
    "    \"UK\": \"GBPUSD=X\",\n",
    "    \"EURO\": \"EURUSD=X\",\n",
    "    \"PHILIPPINE\": \"PHPUSD=X\",\n",
    "    \"CANADIAN\": \"CADUSD=X\",\n",
    "    \"NORWEGIAN\": \"NOKUSD=X\",\n",
    "    \"NEW\": \"NZDUSD=X\",\n",
    "    \"CZECH\": \"CZKUSD=X\",\n",
    "    \"HUNGARIAN\": \"HUFUSD=X\",\n",
    "    \"POLISH\": \"PLNUSD=X\",\n",
    "    \"SINGAPORE\": \"SGDUSD=X\",\n",
    "    \"RUSSIAN\": \"RUBUSD=X\",\n",
    "    \"INDIAN\": \"INRUSD=X\",\n",
    "    \"SOUTH\": \"ZARUSD=X\",\n",
    "    \"INDONESIAN\": \"IDRUSD=X\",\n",
    "    \"BULGARIAN\": \"BGNUSD=X\",\n",
    "    \"ISRAELI\": \"ILSUSD=X\",\n",
    "    \"JAPANESE\": \"JPYUSD=X\",\n",
    "    \"BRAZILIAN\": \"BRLUSD=X\",\n",
    "    \"SWEDISH\": \"SEKUSD=X\",\n",
    "    \"THAI\": \"THBUSD=X\",\n",
    "    \"AUSTRALIAN\": \"AUDUSD=X\",\n",
    "    \"SWISS\": \"CHFUSD=X\",\n",
    "    \"MEXICAN\": \"MXNUSD=X\",\n",
    "    \"CHILEAN\": \"CLPUSD=X\",\n",
    "}\n",
    "\n",
    "target_date = \"2024-10-01\"\n",
    "results = {}\n",
    "\n",
    "for name, ticker in fx_map.items():\n",
    "    try:\n",
    "        data = yf.download(\n",
    "            ticker,\n",
    "            start=\"2024-10-01\",\n",
    "            end=\"2024-10-02\",\n",
    "            progress=False,\n",
    "            auto_adjust=False\n",
    "        )\n",
    "        \n",
    "        # If no data → record NaN\n",
    "        if data.empty:\n",
    "            results[name+\"_ER\"] = float(\"nan\")\n",
    "            continue\n",
    "        \n",
    "        # Look for the exact date\n",
    "        date_match = data.loc[data.index.strftime(\"%Y-%m-%d\") == target_date]\n",
    "        \n",
    "        if len(date_match) == 0:\n",
    "            results[name+\"_ER\"] = float(\"nan\")\n",
    "        else:\n",
    "            results[name+\"_ER\"] = date_match[\"Close\"].iloc[0]\n",
    "    \n",
    "    except Exception:\n",
    "        results[name] = float(\"nan\")\n",
    "\n",
    "clean_results = {k: float(v.iloc[0])for k, v in results.items()}\n",
    "df_check = pd.DataFrame.from_dict(clean_results,orient=\"index\", columns=[\"USD per X\"]) # dataframe \n",
    "\n",
    "\n",
    "# DATA comparison \n",
    "row_model = forward_1M.loc[target_date]\n",
    "row_model.name = \"USD_per_X_professor_data\"\n",
    "df_model = row_model.to_frame(name=\"USD_per_X_model\")\n",
    "comparison = df_model.join(df_check, how=\"inner\")\n",
    "comparison[\"abs_diff\"] = comparison[\"USD_per_X_model\"] - comparison[\"USD per X\"]\n",
    "comparison[\"rel_diff(%)\"] = comparison[\"abs_diff\"] / comparison[\"USD per X\"] * 100\n",
    "\n",
    "print(comparison.sort_values(\"rel_diff(%)\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dc04ea-bc00-49a0-bb35-2bc833b2baff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we plot the missing values to check the coherence of the results \n",
    "forward_1M[[\"SINGAPORE_ER\", \"CANADIAN_ER\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f05149-88ba-4615-ac2f-683e0efed73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_columns(df):\n",
    "    names = sorted({col.split(\"_\")[0] for col in df.columns})\n",
    "    for name in names:\n",
    "        bid = df[name + \"_BID\"]\n",
    "        er = df[name + \"_ER\"]\n",
    "        offer = df[name + \"_OFFER\"]\n",
    "        \n",
    "        same_bid_er = bid.isna().equals(er.isna())\n",
    "        same_bid_offer = bid.isna().equals(offer.isna())\n",
    "        same_offer_er = offer.isna().equals(er.isna())\n",
    "        num_not_nan = bid.notna().sum()\n",
    "        if same_bid_er and same_bid_offer and same_offer_er: \n",
    "            continue \n",
    "        else: \n",
    "            print(f\"=== {name} ===\")\n",
    "            print(\"BID vs ER NaN pattern identical :\", same_bid_er)\n",
    "            print(\"BID vs OFFER NaN pattern identical :\", same_bid_offer)\n",
    "            print(\"ER vs OFFER NaN pattern identical :\", same_offer_er)\n",
    "            return None \n",
    "        if  num_not_nan == 0: \n",
    "            print(f\"=== {name} ===\")\n",
    "            print(\"0 not Nan values there is maybe an issue\") \n",
    "            break \n",
    "            return None \n",
    "    print(\"dataframe OK\") \n",
    "            \n",
    "test_columns(xusd_df)        \n",
    "test_columns(forward_1W)\n",
    "test_columns(forward_1M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b330893d-0316-4469-b6d4-6decb6841346",
   "metadata": {},
   "source": [
    "# **Economic Rationale Behind the Fixed Portfolio Construction**\n",
    "\n",
    "To obtain meaningful and interpretable results, currencies were not assigned randomly to portfolios. Instead, we grouped them according to **economic similarity, geographical proximity, market development, and common macro-financial drivers**. This approach is widely used in the empirical FX literature, as currencies tend to exhibit strong co-movements when they share similar economic fundamentals, exposure to global risk factors, or monetary and trade linkages.\n",
    "\n",
    "The five portfolios therefore reflect **coherent currency blocs**:\n",
    "\n",
    "1. **Developed Europe (EUR, GBP, CHF, SEK, NOK)**\n",
    "   These currencies belong to highly integrated and liquid markets with similar monetary regimes and strong cross-correlations. They typically behave as low-volatility safe-haven or funding currencies, making them a natural benchmark group in FX momentum tests.\n",
    "\n",
    "2. **Commodity-Linked Majors (AUD, NZD, CAD, ZAR, CLP)**\n",
    "   These currencies are strongly exposed to global commodity cycles and international trade dynamics. Their returns tend to co-move with risk sentiment and global demand, which makes momentum effects more pronounced or more volatile within this group.\n",
    "\n",
    "3. **Emerging Europe (CZK, PLN, HUF, HRK, BGN)**\n",
    "   Central and Eastern European currencies share similar macroeconomic structures, EU economic linkages, and exposure to regional capital flows. Treating them as a unified block allows us to analyse momentum in a medium-volatility, partially integrated market segment.\n",
    "\n",
    "4. **Emerging Asia (INR, IDR, PHP, THB, SGD)**\n",
    "   Asian currencies are influenced by regional trade patterns, high growth rates, and varying degrees of managed exchange rate regimes. Grouping them together highlights how momentum behaves in markets where monetary authorities often intervene.\n",
    "\n",
    "5. **Americas & High-Risk EM (BRL, MXN, RUB, ILS, JPY)**\n",
    "   This portfolio includes currencies with higher idiosyncratic volatility, geopolitical risk, or structural risk premia. They often display strong directional moves and are useful for isolating momentum performance in high-risk environments.\n",
    "\n",
    "This fixed allocation provides **three key benefits**:\n",
    "\n",
    "* It generates **economically interpretable differences** across portfolios, allowing us to analyse whether momentum behaves differently in developed vs. emerging markets, commodity-linked vs. safe-haven currencies, or high-risk vs. low-risk regimes.\n",
    "* It ensures **stable composition over time**, avoiding confusion between the effects of portfolio rebalancing and actual strategy performance.\n",
    "* It aligns with **empirical FX research**, where currencies are often grouped by region or market characteristics to isolate structural return patterns.\n",
    "\n",
    "Overall, structuring the portfolios economically rather than randomly creates a more robust and meaningful framework for analysing momentum strategies in the FX market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4842628d-3700-4fe3-9b84-3b59679e975a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_economic_portfolios(df):\n",
    "    \"\"\"\n",
    "    Build fixed economic FX portfolios.\n",
    "    Input:\n",
    "        df = any FX dataframe where columns follow the pattern CURRENCY or CURRENCY_xxx\n",
    "             (ex: EURO, EURO_ER, EURO_BID ...)\n",
    "    Output:\n",
    "        A dictionary { \"P1\": df_subset, ..., \"P5\": df_subset }\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the 5 economic portfolios\n",
    "    portfolios = {\n",
    "        \"P1\": [\"UK\", \"EURO\", \"SWISS\", \"SWEDISH\", \"NORWEGIAN\"],             # Developed Europe\n",
    "        \"P2\": [\"AUSTRALIAN\", \"NEW\", \"CANADIAN\", \"SOUTH\", \"CHILEAN\"],      # Commodity-linked majors\n",
    "        \"P3\": [\"CZECH\", \"POLISH\", \"HUNGARIAN\", \"CROATIAN\", \"BULGARIAN\"],  # Emerging Europe\n",
    "        \"P4\": [\"INDIAN\", \"INDONESIAN\", \"PHILIPPINE\", \"THAI\", \"SINGAPORE\"],# Emerging Asia\n",
    "        \"P5\": [\"BRAZILIAN\", \"MEXICAN\", \"RUSSIAN\", \"ISRAELI\", \"JAPANESE\"]  # Americas + High-risk EM\n",
    "    }\n",
    "\n",
    "    out = {}\n",
    "    for pname, currency_list in portfolios.items():\n",
    "        name = pname +' : '\n",
    "        # Select all columns in df that start with the currency name\n",
    "        cols = []\n",
    "        \n",
    "        for cur in currency_list:\n",
    "            matching = [c for c in df.columns if c.startswith(cur)]\n",
    "            cols.extend(matching)\n",
    "        \n",
    "        name += \"|\".join(currency_list)\n",
    "        # Build the portfolio dataframe (only relevant columns)\n",
    "        out[pname] = df[cols].copy()\n",
    "\n",
    "    return out\n",
    "\n",
    "portfolios = get_economic_portfolios(xusd_df)\n",
    "portfolios_forward_1W = get_economic_portfolios(forward_1W)\n",
    "portfolios_forward_1M = get_economic_portfolios(forward_1M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d81400-ac47-46c4-a838-95ac519dc129",
   "metadata": {},
   "source": [
    "# **Trading strategies** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e783f96f-3ea4-457f-9eb9-ae8ae54db207",
   "metadata": {},
   "source": [
    "## Momentum strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde70aad-1e7e-4642-a01f-287e14310507",
   "metadata": {},
   "source": [
    "The momentum strategy implemented here is a direct translation of the assignment instructions into a systematic trading framework. It adheres to the classical structure of cross-sectional momentum in currency markets: a short lookback window used to generate directional signals, combined with a fixed monthly holding period to capture persistent trends. Its design is intentionally simple, yet it preserves market realism through the use of bid–ask spreads in execution and the separation of bid, mid, and offer data.\n",
    "\n",
    "The signal relies on four-day cumulative log returns computed from mid-market spot prices, which provides a very short-term measure of relative performance across currencies. At each monthly rebalancing date, currencies are sorted by recent momentum, and the top and bottom quantiles form the long and short portfolios, respectively. The position is then held for twenty-two trading days. This structure enforces disciplined, calendar-based rebalancing and reflects the literature on short-horizon momentum in FX markets.\n",
    "\n",
    "A key strength of the implementation is the explicit modelling of transaction costs through bid–ask spreads: long positions enter and exit via offer-to-bid pricing, whereas shorts transact via bid-to-offer. This prevents the strategy from overstating profitability and brings the backtest closer to executable returns. The code also ensures that signals are lagged by one day to avoid look-ahead bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf33f353-95af-4e7c-b3c1-14c85573e234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 1. Split BID / ER / OFFER\n",
    "# =====================================================\n",
    "\n",
    "def split_bid_offer(df):\n",
    "    bid_cols   = [c for c in df.columns if c.endswith(\"_BID\")]\n",
    "    er_cols    = [c for c in df.columns if c.endswith(\"_ER\")]\n",
    "    offer_cols = [c for c in df.columns if c.endswith(\"_OFFER\")]\n",
    "\n",
    "    BID   = df[bid_cols].copy()\n",
    "    ER    = df[er_cols].copy()\n",
    "    OFFER = df[offer_cols].copy()\n",
    "\n",
    "    BID.columns   = [c.replace(\"_BID\", \"\") for c in bid_cols]\n",
    "    ER.columns    = [c.replace(\"_ER\", \"\") for c in er_cols]\n",
    "    OFFER.columns = [c.replace(\"_OFFER\", \"\") for c in offer_cols]\n",
    "\n",
    "    return BID, ER, OFFER\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 2. Momentum signal + signals (common for both versions)\n",
    "#    4-day lookback, 1-month holding (approx 22 jours)\n",
    "# =====================================================\n",
    "\n",
    "def compute_signals(ER, lookback=4, hold_period=22, pct=0.3):\n",
    "\n",
    "    log_ret_spot = np.log(ER).diff()\n",
    "    mom_signal = log_ret_spot.rolling(lookback).sum()\n",
    "\n",
    "    dates = ER.index\n",
    "    assets = ER.columns\n",
    "    signals = pd.DataFrame(0, index=dates, columns=assets)\n",
    "\n",
    "    # rebal tous les hold_period jours, après lookback\n",
    "    rebalance_dates = dates[lookback::hold_period]\n",
    "\n",
    "    for t in rebalance_dates:\n",
    "        today = mom_signal.loc[t].dropna()\n",
    "        if len(today) == 0:\n",
    "            continue\n",
    "\n",
    "        n = len(today)\n",
    "        k = int(np.floor(n * pct))\n",
    "\n",
    "        winners = today.nlargest(k).index\n",
    "        losers  = today.nsmallest(k).index\n",
    "\n",
    "        signals.loc[t, winners] = 1\n",
    "        signals.loc[t, losers]  = -1\n",
    "\n",
    "    # on tient les positions entre deux rebalancings\n",
    "    signals = signals.replace(0, np.nan).ffill().fillna(0)\n",
    "\n",
    "    return signals, mom_signal, log_ret_spot\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 3. Momentum using only mid (ER)\n",
    "#    Mark-to-market au mid, pas de coûts de transaction\n",
    "# =====================================================\n",
    "\n",
    "def momentum_ER_only(ER, signals):\n",
    "\n",
    "    log_ret = np.log(ER).diff()\n",
    "    # daily portfolio return = moyenne des positions (décalées) * log-returns\n",
    "    r = (signals.shift(1) * log_ret).mean(axis=1)\n",
    "    return r.fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 4. Momentum using BID/OFFER execution rules\n",
    "#    Mark-to-market au mid + coûts seulement aux changements de position\n",
    "# =====================================================\n",
    "\n",
    "def momentum_bidask(BID, OFFER, signals):\n",
    "\n",
    "    # mid-prices and daily mid log-returns\n",
    "    MID = (BID + OFFER) / 2\n",
    "    log_mid = np.log(MID)\n",
    "    daily_mid_ret = log_mid.diff()\n",
    "\n",
    "    # base daily PnL: comme la version mid-only, mais avec MID\n",
    "    base_ret = (signals.shift(1) * daily_mid_ret).mean(axis=1)\n",
    "\n",
    "    # positions today vs yesterday\n",
    "    pos_prev = signals.shift(1).fillna(0)\n",
    "    pos_curr = signals\n",
    "\n",
    "    log_bid   = np.log(BID)\n",
    "    log_offer = np.log(OFFER)\n",
    "\n",
    "    # transaction cost per asset / day selon type de trade\n",
    "    # long open  : mid - offer  (on paie le spread en entrant long)\n",
    "    # long close : bid - mid\n",
    "    # short open : bid - mid\n",
    "    # short close: mid - offer\n",
    "\n",
    "    tc_long_open  = log_mid - log_offer\n",
    "    tc_long_close = log_bid - log_mid\n",
    "    tc_short_open = log_bid - log_mid\n",
    "    tc_short_close= log_mid - log_offer\n",
    "\n",
    "    # masks de changement de position\n",
    "    long_open_mask   = (pos_prev == 0) & (pos_curr == 1)\n",
    "    long_close_mask  = (pos_prev == 1) & (pos_curr == 0)\n",
    "    short_open_mask  = (pos_prev == 0) & (pos_curr == -1)\n",
    "    short_close_mask = (pos_prev == -1) & (pos_curr == 0)\n",
    "\n",
    "    # flips: 1 -> -1 (close long + open short) et -1 -> 1 (close short + open long)\n",
    "    flip_long_to_short = (pos_prev == 1) & (pos_curr == -1)\n",
    "    flip_short_to_long = (pos_prev == -1) & (pos_curr == 1)\n",
    "\n",
    "    long_close_mask  = long_close_mask  | flip_long_to_short\n",
    "    short_open_mask  = short_open_mask  | flip_long_to_short\n",
    "    short_close_mask = short_close_mask | flip_short_to_long\n",
    "    long_open_mask   = long_open_mask   | flip_short_to_long\n",
    "\n",
    "    # transaction cost matrix\n",
    "    tc_matrix = (\n",
    "        long_open_mask   * tc_long_open  +\n",
    "        long_close_mask  * tc_long_close +\n",
    "        short_open_mask  * tc_short_open +\n",
    "        short_close_mask * tc_short_close\n",
    "    )\n",
    "\n",
    "    # nombre d'actifs tradés par jour\n",
    "    traded_mask  = long_open_mask | long_close_mask | short_open_mask | short_close_mask\n",
    "    traded_count = traded_mask.sum(axis=1).replace(0, np.nan)\n",
    "\n",
    "    # coût de transaction au niveau portefeuille = moyenne sur les actifs tradés\n",
    "    tc_port = tc_matrix.sum(axis=1) / traded_count\n",
    "    tc_port = tc_port.fillna(0)\n",
    "\n",
    "    # total daily return = mid-based MTM + transaction cost adjustments\n",
    "    r = base_ret + tc_port\n",
    "\n",
    "    return r.fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 5. Evaluation\n",
    "# =====================================================\n",
    "\n",
    "def evaluate_strategy(r):\n",
    "\n",
    "    r = r.fillna(0)\n",
    "\n",
    "    perf = (1 + r).cumprod()\n",
    "\n",
    "    ann_ret = (1 + r.mean())**252 - 1\n",
    "    ann_vol = r.std() * np.sqrt(252)\n",
    "    sharpe  = ann_ret / ann_vol if ann_vol != 0 else np.nan\n",
    "\n",
    "    running_max = perf.cummax()\n",
    "    max_dd = ((perf - running_max) / running_max).min()\n",
    "\n",
    "    return pd.Series({\n",
    "        \"Annualized Return\": ann_ret,\n",
    "        \"Annualized Volatility\": ann_vol,\n",
    "        \"Sharpe Ratio\": sharpe,\n",
    "        \"Max Drawdown\": max_dd,\n",
    "        \"Skewness (daily)\": skew(r.dropna()),\n",
    "        \"Kurtosis (daily)\": kurtosis(r.dropna(), fisher=False)\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 6. WRAPPER : run BOTH versions for each portfolio\n",
    "# =====================================================\n",
    "\n",
    "def run_portfolio_strategies(portfolios, lookback=4, hold_period=22, pct=0.3, print_data = True):\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for name, df_port in portfolios.items():\n",
    "\n",
    "        BID, ER, OFFER = split_bid_offer(df_port)\n",
    "\n",
    "        signals, momentum, log_ret_spot = compute_signals(\n",
    "            ER, lookback=lookback, hold_period=hold_period, pct=pct\n",
    "        )\n",
    "\n",
    "        # Strategy A: mid-only\n",
    "        ret_mid   = momentum_ER_only(ER, signals)\n",
    "        stats_mid = evaluate_strategy(ret_mid)\n",
    "\n",
    "        # Strategy B: real execution using bid/offer with TC at rebal only\n",
    "        ret_ba   = momentum_bidask(BID, OFFER, signals)\n",
    "        stats_ba = evaluate_strategy(ret_ba)\n",
    "        \n",
    "        results[name] = {\n",
    "            \"ER_only\": {\n",
    "                \"returns\": ret_mid,\n",
    "                \"stats\": stats_mid\n",
    "            },\n",
    "            \"BidAsk\": {\n",
    "                \"returns\": ret_ba,\n",
    "                \"stats\": stats_ba\n",
    "            },\n",
    "            \"signals\": signals,\n",
    "            \"momentum\": momentum,\n",
    "            \"log_returns\": log_ret_spot\n",
    "        }\n",
    "        if print_data :\n",
    "            print(\"\\n==============================\")\n",
    "            print(f\"Portfolio: {name}\")\n",
    "            print(\"=== ER-only ===\")\n",
    "            print(stats_mid)\n",
    "            print(\"=== Bid/Ask ===\")\n",
    "            print(stats_ba)\n",
    "\n",
    "    return results\n",
    "\n",
    "results=run_portfolio_strategies(portfolios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5b2874-70e1-41e2-a2e8-23c3c4cb0414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1) Visualiser TOUTES les transactions d’un portefeuille\n",
    "# ============================================================\n",
    "\n",
    "def plot_portfolio_transactions(portfolio_data, portfolios, portfolio_name):\n",
    "\n",
    "    df = portfolios[portfolio_name]\n",
    "    BID, ER, OFFER = split_bid_offer(df)\n",
    "\n",
    "    signals = portfolio_data[portfolio_name][\"signals\"]\n",
    "\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.suptitle(f\"Transactions – {portfolio_name}\", fontsize=14)\n",
    "\n",
    "    for i, cur in enumerate(ER.columns):\n",
    "        price = ER[cur]\n",
    "        s = signals[cur]\n",
    "\n",
    "        # raw buy/sell\n",
    "        buy_idx  = s[s == 1].index\n",
    "        sell_idx = s[s == -1].index\n",
    "\n",
    "        # === CRUCIAL FIX ===\n",
    "        # keep only dates present in price.index\n",
    "        buy_idx  = buy_idx.intersection(price.index)\n",
    "        sell_idx = sell_idx.intersection(price.index)\n",
    "\n",
    "        plt.subplot(len(ER.columns), 1, i + 1)\n",
    "\n",
    "        plt.plot(price.index, price, color=\"black\", linewidth=1.2)\n",
    "        plt.scatter(buy_idx,  price.loc[buy_idx],  color=\"green\", marker=\"^\", s=40)\n",
    "        plt.scatter(sell_idx, price.loc[sell_idx], color=\"red\", marker=\"v\", s=40)\n",
    "\n",
    "        plt.title(cur, fontsize=10)\n",
    "        plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2) Comparer les PnL de TOUTES les sorties (ER-only vs Bid/Ask)\n",
    "# ============================================================\n",
    "\n",
    "def plot_portfolio_pnl_comparison(portfolio_data, portfolio_name):\n",
    "    \"\"\"\n",
    "    Trace les PnL cumulés ER-only et Bid/Ask pour un portefeuille.\n",
    "    \"\"\"\n",
    "    ret_mid = portfolio_data[portfolio_name][\"ER_only\"][\"returns\"].fillna(0)\n",
    "    ret_ba  = portfolio_data[portfolio_name][\"BidAsk\"][\"returns\"].fillna(0)\n",
    "\n",
    "    pnl_mid = (1 + ret_mid).cumprod()\n",
    "    pnl_ba  = (1 + ret_ba).cumprod()\n",
    "\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.plot(pnl_mid, linewidth=2, label=\"Mid-price strategy (ER-only)\")\n",
    "    plt.plot(pnl_ba, linewidth=2, label=\"Executed strategy (Bid/Ask)\")\n",
    "\n",
    "    plt.title(f\"Cumulative Performance – {portfolio_name}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Cumulative Return\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3) Inspecter une devise spécifique d’un portefeuille\n",
    "# ============================================================\n",
    "\n",
    "def plot_currency_details(portfolio_data, portfolios, portfolio_name, currency):\n",
    "    \"\"\"\n",
    "    Trace :\n",
    "      • le prix ER\n",
    "      • les signaux Buy/Sell\n",
    "      • le PnL transactionnel exécuté (Bid/Ask)\n",
    "    \"\"\"\n",
    "\n",
    "    df = portfolios[portfolio_name]\n",
    "    BID, ER, OFFER = split_bid_offer(df)\n",
    "\n",
    "    if currency not in ER.columns:\n",
    "        print(f\"{currency} not found in {portfolio_name}.\")\n",
    "        return\n",
    "\n",
    "    price = ER[currency]\n",
    "    sig   = portfolio_data[portfolio_name][\"signals\"][currency]\n",
    "\n",
    "    # Transaction returns\n",
    "    long_ret  = np.log(BID[currency])   - np.log(OFFER[currency].shift(1))\n",
    "    short_ret = np.log(OFFER[currency]) - np.log(BID[currency].shift(1))\n",
    "    exec_ret  = ((sig.shift(1) == 1) * long_ret +\n",
    "                 (sig.shift(1) == -1) * short_ret).fillna(0)\n",
    "\n",
    "    pnl_exec = (1 + exec_ret).cumprod()\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(16, 8))\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(price, color=\"black\", linewidth=1.5, label=\"ER price\")\n",
    "\n",
    "    buy_idx  = sig[sig == 1].index\n",
    "    sell_idx = sig[sig == -1].index\n",
    "\n",
    "    plt.scatter(buy_idx, price.loc[buy_idx], color=\"green\", marker=\"^\", s=60, label=\"Buy\")\n",
    "    plt.scatter(sell_idx, price.loc[sell_idx], color=\"red\", marker=\"v\", s=60, label=\"Sell\")\n",
    "\n",
    "    plt.title(f\"{portfolio_name} – Price & Signals ({currency})\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"ER\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(pnl_exec, linewidth=2, color=\"blue\")\n",
    "    plt.title(f\"Executed Transaction PnL – {currency}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Cumulative Return\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4) Résumé complet d’un portefeuille (table + plots)\n",
    "# ============================================================\n",
    "\n",
    "def summarize_portfolio(portfolio_data, portfolios, portfolio_name):\n",
    "    \"\"\"\n",
    "    Affiche :\n",
    "      • composition du portefeuille\n",
    "      • tableau stats ER-only vs Bid/Ask\n",
    "      • PnL comparé\n",
    "      • transactions détaillées\n",
    "    \"\"\"\n",
    "    print(f\"\\n====== Portfolio {portfolio_name} – Composition ======\")\n",
    "    print(portfolios[portfolio_name].columns.tolist())\n",
    "\n",
    "    print(f\"\\n====== Performance Statistics – {portfolio_name} ======\")\n",
    "    stats_mid   = portfolio_data[portfolio_name][\"ER_only\"][\"stats\"]\n",
    "    stats_bidask = portfolio_data[portfolio_name][\"BidAsk\"][\"stats\"]\n",
    "\n",
    "    display(pd.DataFrame({\n",
    "        \"ER-only\": stats_mid,\n",
    "        \"Bid/Ask Executed\": stats_bidask\n",
    "    }))\n",
    "\n",
    "    plot_portfolio_pnl_comparison(portfolio_data, portfolio_name)\n",
    "    plot_portfolio_transactions(portfolio_data, portfolios, portfolio_name)\n",
    "\n",
    "def plot_all_portfolios_pnl(portfolio_data, portfolios_keys=None):\n",
    "    \"\"\"\n",
    "    Compare the cumulative PnL of all portfolios (ER-only and Bid/Ask)\n",
    "    on one figure.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    portfolio_data : dict\n",
    "        Output of run_portfolio_strategies()\n",
    "    portfolios_keys : list or None\n",
    "        List of portfolio names to plot (e.g. [\"P1\", \"P2\", ...]).\n",
    "        If None, all keys contained in portfolio_data are plotted.\n",
    "    \"\"\"\n",
    "\n",
    "    if portfolios_keys is None:\n",
    "        portfolios_keys = sorted(list(portfolio_data.keys()))\n",
    "\n",
    "    plt.figure(figsize=(16, 8))\n",
    "\n",
    "    colors = [\"blue\", \"green\", \"red\", \"purple\", \"orange\"]\n",
    "    linestyles = [\"-\", \"--\"]  # ER-only solid, Bid/Ask dashed\n",
    "\n",
    "    for i, p in enumerate(portfolios_keys):\n",
    "        data = portfolio_data[p]\n",
    "\n",
    "        # retrieve returns\n",
    "        ret_mid = data[\"ER_only\"][\"returns\"].fillna(0)\n",
    "        ret_ba  = data[\"BidAsk\"][\"returns\"].fillna(0)\n",
    "\n",
    "        pnl_mid = (1 + ret_mid).cumprod()\n",
    "        pnl_ba  = (1 + ret_ba).cumprod()\n",
    "\n",
    "        # plot mid-only PnL\n",
    "        plt.plot(pnl_mid, color=colors[i % len(colors)], \n",
    "                 linestyle=linestyles[0], linewidth=1.8,\n",
    "                 label=f\"{p} – Mid\")\n",
    "\n",
    "        # plot bid/ask PnL\n",
    "        plt.plot(pnl_ba, color=colors[i % len(colors)], \n",
    "                 linestyle=linestyles[1], linewidth=1.8,\n",
    "                 label=f\"{p} – Bid/Ask\")\n",
    "\n",
    "    plt.title(\"Portfolio PnL Comparison (ER-only vs Bid/Ask Execution)\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Cumulative Return\")\n",
    "    plt.grid(True)\n",
    "    plt.legend(ncol=2)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "portfolio_data = run_portfolio_strategies(portfolios, print_data = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9053ec7-43ba-4327-9a5d-23beafaafac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_portfolio(portfolio_data, portfolios, \"P5\")\n",
    "plot_all_portfolios_pnl(portfolio_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e861a09d-b01a-41c4-b09a-32c6995926ee",
   "metadata": {},
   "source": [
    "The baseline full-sample results show modest negative performance, with an annualized return of about –1.7% and a Sharpe ratio of –0.25. The drawdown profile is substantial, and the return distribution is marked by mild negative skewness and pronounced excess kurtosis, consistent with the fat-tailed behaviour characteristic of currency markets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95309f39-d3f9-4857-a1df-8b611214c12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\"lookback\": 4, \"hold\": 22, \"pct\": 0.2},\n",
    "    {\"lookback\": 10, \"hold\": 22, \"pct\": 0.4},\n",
    "]\n",
    "# allow to test other setup -> we can maybe tune some values using optuna for bayesian optimisation of those parameters\n",
    "\n",
    "subsamples = {\n",
    "    \"1999-2007\": (\"1999-01-01\", \"2007-12-31\"), # (pre-crisis)\n",
    "    \"2008-2012\": (\"2008-01-01\", \"2012-12-31\"), # (Financial Crisis + Euro Crisis)\n",
    "    \"2013-2019\": (\"2013-01-01\", \"2019-12-31\"), # (QE, Low Volatility)\n",
    "    \"2020-2024\": (\"2020-01-01\", \"2024-12-31\"), # (COVID, Inflation, QT)\n",
    "}\n",
    "\n",
    "\n",
    "results_sub = {}\n",
    "\n",
    "for sub_name, (start, end) in subsamples.items():\n",
    "    print(sub_name) \n",
    "    df_sub = xusd_df.loc[start:end]\n",
    "    portfolios_sub = get_economic_portfolios(df_sub)\n",
    "    if len(df_sub) < 200:\n",
    "        continue\n",
    "\n",
    "    for p in param_grid:\n",
    "        lb = p[\"lookback\"]\n",
    "        hd = p[\"hold\"]\n",
    "        pct = p[\"pct\"]\n",
    "        portfolio_data = run_portfolio_strategies(portfolios,lookback=lb, hold_period=hd, pct=pct, print_data = False)\n",
    "        summarize_portfolio(portfolio_data, portfolios, \"P1\") #change the key to visualize the portfolio you wish to comment on \n",
    "        plot_all_portfolios_pnl(portfolio_data)\n",
    "\n",
    "        key = f\"{sub_name} | LB={lb}, HP={hd}, PCT={pct}\"\n",
    "        results_sub[key] = portfolio_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707b6b43-17d6-42b7-bfd1-8092a8a901e9",
   "metadata": {},
   "source": [
    "The subsample analysis reveals a pattern consistent with empirical findings in the literature. Momentum performs relatively well in the pre-crisis period (1999–2007), delivering positive returns with reasonable risk-adjusted performance. However, the strategy deteriorates markedly during and after the 2008 financial crisis, with negative performance persisting through the low-volatility, policy-driven environment of the 2013–2019 period. This degradation aligns with well-documented observations that carry and momentum strategies suffered structural breaks post-2008, partly due to deleveraging, increased funding constraints, and reduced dispersion in macroeconomic fundamentals.\n",
    "\n",
    "Interestingly, the post-2020 sample shows mixed behaviour. Short-horizon momentum remains weak for the four-day lookback, yet a longer lookback (20 days) improves performance modestly, suggesting that trend-following signals may have experienced a partial recovery in the higher-volatility environment associated with COVID-19, inflation shocks, and monetary tightening.\n",
    "\n",
    "Overall, the implemented framework captures the essential mechanics of FX momentum and provides a transparent basis for evaluating its behaviour across regimes. The results underline a central theme in empirical international finance: the profitability of cross-sectional FX factors is highly sensitive to macroeconomic conditions, market structure, and periods of stress, and has not been stable over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dc5fed-ece2-4c09-b5a4-60d8f91efa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 1. Split BID / ER / OFFER (spot)\n",
    "# =====================================================\n",
    "\n",
    "def split_bid_offer(df):\n",
    "    bid_cols   = [c for c in df.columns if c.endswith(\"_BID\")]\n",
    "    er_cols    = [c for c in df.columns if c.endswith(\"_ER\")]\n",
    "    offer_cols = [c for c in df.columns if c.endswith(\"_OFFER\")]\n",
    "\n",
    "    BID   = df[bid_cols].copy()\n",
    "    ER    = df[er_cols].copy()\n",
    "    OFFER = df[offer_cols].copy()\n",
    "\n",
    "    BID.columns   = [c.replace(\"_BID\", \"\") for c in bid_cols]\n",
    "    ER.columns    = [c.replace(\"_ER\", \"\") for c in er_cols]\n",
    "    OFFER.columns = [c.replace(\"_OFFER\", \"\") for c in offer_cols]\n",
    "\n",
    "    return BID, ER, OFFER\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 2. Forward harmonisation\n",
    "# =====================================================\n",
    "\n",
    "def harmonize_forward(df_forward):\n",
    "\n",
    "    currencies = sorted(set(c.split(\"_\")[0] for c in df_forward.columns))\n",
    "\n",
    "    F_bid   = pd.DataFrame(index=df_forward.index)\n",
    "    F_mid   = pd.DataFrame(index=df_forward.index)\n",
    "    F_offer = pd.DataFrame(index=df_forward.index)\n",
    "\n",
    "    for cur in currencies:\n",
    "        if f\"{cur}_BID\" in df_forward.columns:\n",
    "            F_bid[cur] = df_forward[f\"{cur}_BID\"]\n",
    "        if f\"{cur}_ER\" in df_forward.columns:\n",
    "            F_mid[cur] = df_forward[f\"{cur}_ER\"]\n",
    "        if f\"{cur}_OFFER\" in df_forward.columns:\n",
    "            F_offer[cur] = df_forward[f\"{cur}_OFFER\"]\n",
    "\n",
    "    return F_bid, F_mid, F_offer\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 3. PPP STRATEGY (Correct & aligned with momentum logic)\n",
    "# =====================================================\n",
    "\n",
    "def ppp_strategy(df_spot, df_forward, hold_period=22, pct=0.3):\n",
    "\n",
    "    BID, ER, OFFER = split_bid_offer(df_spot)\n",
    "    F_bid, F_mid, F_offer = harmonize_forward(df_forward)\n",
    "\n",
    "    # Align spot data to forward dates\n",
    "    BID   = BID.reindex(df_forward.index)\n",
    "    ER    = ER.reindex(df_forward.index)\n",
    "    OFFER = OFFER.reindex(df_forward.index)\n",
    "\n",
    "    spot_currencies = set(ER.columns)\n",
    "    fwd_currencies = set(F_mid.columns) & set(F_bid.columns) & set(F_offer.columns)\n",
    "\n",
    "    # Missing forward currencies\n",
    "    missing = sorted(list(spot_currencies - fwd_currencies))\n",
    "    if len(missing) > 0:\n",
    "        print(\"\\n[PPP WARNING] Missing forward quotes for:\", missing)\n",
    "\n",
    "    common = sorted(list(spot_currencies & fwd_currencies))\n",
    "    if len(common) == 0:\n",
    "        empty = pd.Series(0, index=df_forward.index)\n",
    "        return empty, empty, pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    # Restrict to tradable universe\n",
    "    BID   = BID[common]\n",
    "    ER    = ER[common]\n",
    "    OFFER = OFFER[common]\n",
    "    F_mid = F_mid[common]\n",
    "\n",
    "    # ===== PPP mispricing =====\n",
    "    value_signal = F_mid / ER - 1\n",
    "\n",
    "    dates = value_signal.index\n",
    "    assets = value_signal.columns\n",
    "    signals = pd.DataFrame(0, index=dates, columns=assets)\n",
    "\n",
    "    # Monthly rebalance\n",
    "    rebalance_dates = dates[::hold_period]\n",
    "\n",
    "    for t in rebalance_dates:\n",
    "        today = value_signal.loc[t].dropna()\n",
    "        if today.empty:\n",
    "            continue\n",
    "\n",
    "        n = len(today)\n",
    "        k = int(np.floor(n * pct))\n",
    "\n",
    "        underval = today.nsmallest(k).index   # go long undervalued\n",
    "        overval  = today.nlargest(k).index    # short overvalued\n",
    "\n",
    "        signals.loc[t, underval] = 1\n",
    "        signals.loc[t, overval]  = -1\n",
    "\n",
    "    signals = signals.replace(0, np.nan).ffill().fillna(0)\n",
    "\n",
    "    # ========== MID-ONLY PPP RETURN ==========\n",
    "    logret = np.log(ER).diff()\n",
    "    ret_mid = (signals.shift(1) * logret).mean(axis=1).fillna(0)\n",
    "\n",
    "\n",
    "    # =====================================================\n",
    "    # ========== BID/ASK Version with Correct Execution ===\n",
    "    # =====================================================\n",
    "\n",
    "    MID = (BID + OFFER) / 2\n",
    "    log_mid = np.log(MID)\n",
    "    daily_mid_ret = log_mid.diff()\n",
    "\n",
    "    # Base PnL = MTM at mid\n",
    "    base_ret = (signals.shift(1) * daily_mid_ret).mean(axis=1)\n",
    "\n",
    "    pos_prev = signals.shift(1).fillna(0)\n",
    "    pos_curr = signals\n",
    "\n",
    "    log_bid   = np.log(BID)\n",
    "    log_offer = np.log(OFFER)\n",
    "\n",
    "    # Transaction costs (same logic as corrected momentum)\n",
    "    tc_long_open  = log_mid - log_offer\n",
    "    tc_long_close = log_bid - log_mid\n",
    "    tc_short_open = log_bid - log_mid\n",
    "    tc_short_close= log_mid - log_offer\n",
    "\n",
    "    long_open_mask   = (pos_prev == 0) & (pos_curr == 1)\n",
    "    long_close_mask  = (pos_prev == 1) & (pos_curr == 0)\n",
    "    short_open_mask  = (pos_prev == 0) & (pos_curr == -1)\n",
    "    short_close_mask = (pos_prev == -1) & (pos_curr == 0)\n",
    "\n",
    "    flip_long_to_short = (pos_prev == 1) & (pos_curr == -1)\n",
    "    flip_short_to_long = (pos_prev == -1) & (pos_curr == 1)\n",
    "\n",
    "    long_close_mask  |= flip_long_to_short\n",
    "    short_open_mask  |= flip_long_to_short\n",
    "    short_close_mask |= flip_short_to_long\n",
    "    long_open_mask   |= flip_short_to_long\n",
    "\n",
    "    tc_matrix = (\n",
    "        long_open_mask   * tc_long_open  +\n",
    "        long_close_mask  * tc_long_close +\n",
    "        short_open_mask  * tc_short_open +\n",
    "        short_close_mask * tc_short_close\n",
    "    )\n",
    "\n",
    "    traded_mask = long_open_mask | long_close_mask | short_open_mask | short_close_mask\n",
    "    traded_count = traded_mask.sum(axis=1).replace(0, np.nan)\n",
    "\n",
    "    tc_port = (tc_matrix.sum(axis=1) / traded_count).fillna(0)\n",
    "\n",
    "    ret_ba = (base_ret + tc_port).fillna(0)\n",
    "\n",
    "    return ret_mid, ret_ba, signals, value_signal, logret\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 4. Wrapper matching Momentum outputs\n",
    "# =====================================================\n",
    "\n",
    "def run_ppp_portfolio_strategies(portfolios_spot, portfolios_forward, hold_period=1, pct=0.3, print_data=True): # hold period is one because monthly obs \n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for name in portfolios_spot.keys():\n",
    "\n",
    "        df_spot    = portfolios_spot[name]\n",
    "        df_forward = portfolios_forward[name]\n",
    "\n",
    "        ret_mid, ret_ba, signals_ppp, value_ppp, logret_ppp = ppp_strategy(\n",
    "            df_spot,\n",
    "            df_forward,\n",
    "            hold_period=hold_period,\n",
    "            pct=pct\n",
    "        )\n",
    "\n",
    "        stats_mid = evaluate_strategy(ret_mid)\n",
    "        stats_ba  = evaluate_strategy(ret_ba)\n",
    "\n",
    "        results[name] = {\n",
    "            \"ER_only\": {\n",
    "                \"returns\": ret_mid,\n",
    "                \"stats\": stats_mid\n",
    "            },\n",
    "            \"BidAsk\": {\n",
    "                \"returns\": ret_ba,\n",
    "                \"stats\": stats_ba\n",
    "            },\n",
    "            \"signals\": signals_ppp,\n",
    "            \"value_signal\": value_ppp,\n",
    "            \"log_returns\": logret_ppp\n",
    "        }\n",
    "\n",
    "        if print_data:\n",
    "            print(\"\\n==============================\")\n",
    "            print(f\"PPP Portfolio: {name}\")\n",
    "            print(\"=== PPP Mid-only ===\")\n",
    "            print(stats_mid)\n",
    "            print(\"=== PPP Bid/Ask Execution ===\")\n",
    "            print(stats_ba)\n",
    "\n",
    "    return results\n",
    "\n",
    "results_ppp_1M = run_ppp_portfolio_strategies(\n",
    "    portfolios_spot=portfolios,\n",
    "    portfolios_forward=portfolios_forward_1M\n",
    ")\n",
    "\n",
    "results_ppp_1W = run_ppp_portfolio_strategies(\n",
    "    portfolios_spot=portfolios,\n",
    "    portfolios_forward=portfolios_forward_1W\n",
    ")\n",
    "\n",
    "summarize_portfolio(results_ppp_1M, portfolios, \"P5\")\n",
    "plot_all_portfolios_pnl(results_ppp_1M)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd30007-8728-441d-824d-7a379f758fd7",
   "metadata": {},
   "source": [
    "The performance of the PPP-based trading rule at both the 1-month and 1-week horizons is modest and provides little evidence that short-maturity forward rates contain exploitable deviations from purchasing power parity. Annualized returns remain close to zero in both cases, while volatility is meaningfully higher. As a result, Sharpe ratios hover around 0.1, indicating that the strategy fails to generate meaningful risk-adjusted returns.\n",
    "\n",
    "This weakness is largely structural. The forward–spot differential, which serves as the PPP signal, is extremely small at short maturities and dominated by microstructure noise rather than genuine misalignments. Small fluctuations in short-term interest rates, liquidity conditions, or funding costs overwhelm any underlying PPP relationship. The resulting signal is therefore unstable and provides no reliable directional information.\n",
    "\n",
    "Distributional properties reinforce this conclusion. Daily returns exhibit near-zero skewness but very elevated kurtosis, reflecting fat-tailed behaviour with occasional abrupt losses. The strategy tends to hover near breakeven most of the time but suffers sudden drawdowns, typical of signals with little predictive value and significant execution frictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3ec20b-105c-40da-aac2-c7c4bb58e93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_ppp_execution_calendar(results_ppp, portfolios_forward, portfolio_name):\n",
    "    \"\"\"\n",
    "    Visualise:\n",
    "    - PPP rebalance dates\n",
    "    - Trade execution dates (where bid/offer execution was possible)\n",
    "    - Forward portfolio content\n",
    "    \"\"\"\n",
    "\n",
    "    data = results_ppp[portfolio_name]\n",
    "    ret_ba = data[\"BidAsk\"][\"returns\"]\n",
    "    signals = data[\"signals\"]\n",
    "\n",
    "    # Rebalance dates = where signals change (first differences)\n",
    "    rebalance_dates = signals.diff().abs().sum(axis=1)\n",
    "    rebalance_dates = rebalance_dates[rebalance_dates > 0].index\n",
    "\n",
    "    # Execution dates = where ret_ba != 0\n",
    "    pos_prev = signals.shift(1).fillna(0)\n",
    "    pos_curr = signals\n",
    "    \n",
    "    trade_mask = (pos_prev != pos_curr).any(axis=1)\n",
    "    exec_dates = trade_mask[trade_mask].index\n",
    "    \n",
    "\n",
    "    # Forward portfolio composition\n",
    "    fwd_cols = portfolios_forward[portfolio_name].columns\n",
    "    forward_assets = sorted(set(c.split(\"_\")[0] for c in fwd_cols))\n",
    "\n",
    "    plt.figure(figsize=(15, 4))\n",
    "\n",
    "    plt.scatter(rebalance_dates, [1]*len(rebalance_dates),\n",
    "                color=\"blue\", s=50, label=\"PPP Rebalance dates\")\n",
    "\n",
    "    plt.scatter(exec_dates, [0]*len(exec_dates),\n",
    "                color=\"red\", s=30, label=\"Executed trades (Bid/Offer)\")\n",
    "\n",
    "    plt.yticks([0,1], [\"Executed trades\", \"Rebalance trigger\"])\n",
    "    plt.grid(True, alpha=0.4)\n",
    "    plt.title(f\"PPP Execution Calendar – Portfolio {portfolio_name}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.legend(loc=\"upper left\")\n",
    "\n",
    "    print(\"\\nForward currencies used in this portfolio:\")\n",
    "    print(forward_assets)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_ppp_execution_calendar(results_ppp_1W, portfolios_forward_1W, \"P5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a29177-a48b-4c30-8a5c-b06fdb4ca406",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\"hold\": 1, \"pct\": 0.2},\n",
    "]\n",
    "subsamples = {\n",
    "    \"1999-2007\": (\"1999-01-01\", \"2007-12-31\"), # (pre-crisis)\n",
    "    \"2008-2012\": (\"2008-01-01\", \"2012-12-31\"), # (Financial Crisis + Euro Crisis)\n",
    "    \"2013-2019\": (\"2013-01-01\", \"2019-12-31\"), # (QE, Low Volatility)\n",
    "    \"2020-2024\": (\"2020-01-01\", \"2024-12-31\"), # (COVID, Inflation, QT)\n",
    "}\n",
    "\n",
    "\n",
    "results_sub1W = {}\n",
    "results_sub1M = {}\n",
    "for sub_name, (start, end) in subsamples.items():\n",
    "    xusd_df_sub = xusd_df.loc[start:end]\n",
    "    forward_1M_sub = forward_1M.loc[start:end]\n",
    "    forward_1W_sub = forward_1W.loc[start:end]\n",
    "\n",
    "\n",
    "    portfolios_sub = get_economic_portfolios(xusd_df_sub)\n",
    "    portfolios_forward_1W_sub = get_economic_portfolios(forward_1W_sub)\n",
    "    portfolios_forward_1M_sub = get_economic_portfolios(forward_1M_sub)\n",
    "    if len(df_sub) < 200:\n",
    "        continue\n",
    "\n",
    "    for p in param_grid:\n",
    "        hd = p[\"hold\"]\n",
    "        pct = p[\"pct\"]\n",
    "\n",
    "        results_ppp_1M = run_ppp_portfolio_strategies(\n",
    "            portfolios_spot=portfolios_sub,\n",
    "            portfolios_forward=portfolios_forward_1M_sub\n",
    "        )\n",
    "        \n",
    "        results_ppp_1W = run_ppp_portfolio_strategies(\n",
    "            portfolios_spot=portfolios_sub,\n",
    "            portfolios_forward=portfolios_forward_1W_sub\n",
    "        )\n",
    "        summarize_portfolio(results_ppp_1W, portfolios_sub, \"P5\")\n",
    "        summarize_portfolio(results_ppp_1M, portfolios_sub, \"P5\")\n",
    "        plot_all_portfolios_pnl(results_ppp_1M)\n",
    "\n",
    "\n",
    "        key = f\"{sub_name} | HP={hd}, PCT={pct}\"\n",
    "        results_sub1M[key] = results_ppp_1W\n",
    "        results_sub1W[key] = results_ppp_1M\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e9b434-d100-4a54-a06d-1548ba9ed33e",
   "metadata": {},
   "source": [
    "Regime-Based Analysis\n",
    "\n",
    "To better understand the behaviour of the strategy, performance was evaluated over four distinct macro-financial regimes.\n",
    "\n",
    "1. 1999–2007 — Pre-crisis, relatively stable markets\n",
    "\n",
    "Performance is strongest in this subsample.\n",
    "Both the 1W and 1M variants produce positive returns with Sharpe ratios around 0.5–0.6 for portfolio sizes of 20–30%.\n",
    "This is the only period where PPP deviations appear marginally informative.\n",
    "Interest rate differentials were relatively stable, FX volatility moderate, and microstructure distortions less dominant—conditions under which PPP-related signals can occasionally manifest.\n",
    "\n",
    "2. 2008–2012 — Global Financial Crisis and Eurozone crisis\n",
    "\n",
    "Results become more mixed.\n",
    "The strategy remains positive but with higher volatility and roughly half the Sharpe ratio observed in the pre-crisis years.\n",
    "Dislocations in funding markets, heightened risk aversion, and rapid swings in interest rates reduce the informational content of forward discounts.\n",
    "PPP-based signals become increasingly noisy in this regime.\n",
    "\n",
    "3. 2013–2019 — QE era, compressed yields and low volatility\n",
    "\n",
    "The strategy deteriorates sharply.\n",
    "Returns turn negative and Sharpe ratios remain consistently below zero.\n",
    "This period features historically low interest rate differentials and extremely muted FX volatility.\n",
    "Under these conditions, PPP deviations at short maturities all but vanish, and the model ends up selecting currencies on the basis of noise rather than persistent structure.\n",
    "\n",
    "4. 2020–2024 — COVID, inflation shock, and monetary tightening\n",
    "\n",
    "The results remain negative across both horizons.\n",
    "Sharpe ratios fall into the –0.35 to –0.50 range.\n",
    "Market dynamics during this period are dominated by abrupt monetary adjustments, liquidity dislocations, and risk-on/risk-off flows unrelated to PPP.\n",
    "Short-term forward prices reflect these forces far more than they do any convergence toward long-run parity.\n",
    "\n",
    "**Overall Assessment**\n",
    "\n",
    "Across the full sample and within each regime, the evidence points to the same conclusion:\n",
    "\n",
    "Short-horizon PPP-based trading signals are not economically or statistically reliable.\n",
    "\n",
    "Specifically:\n",
    "\n",
    "- Returns are weak and unstable across maturities and regimes.\n",
    "- Sharpe ratios remain close to zero or negative.\n",
    "- High kurtosis reveals frequent tail events despite low average volatility.\n",
    "- The forward–spot differential at short horizons is dominated by noise.\n",
    "- Monthly rebalancing does not improve the robustness of the signal.\n",
    "- Performance collapses whenever monetary or macroeconomic conditions deviate from historical norms.\n",
    "\n",
    "PPP remains a useful long-term equilibrium concept, but it does not translate into actionable predictive power at horizons relevant for tactical currency trading. The empirical evidence suggests that the strategy, in its current form, is not viable for practical implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d10a8f7-353f-4665-9103-f0582ad0ee3a",
   "metadata": {},
   "source": [
    "# Enhanced Momentum Strategy for FX Markets (Literature-Based)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96079f9b-37a2-4535-9371-a6cf337b4ae6",
   "metadata": {},
   "source": [
    "Momentum strategies, originally documented by Jegadeesh & Titman (1993, 2001), have proven persistent across equities (Fama & French, 2012), global asset classes (Asness et al., 2013), and foreign exchange markets (Menkhoff et al., 2012).\n",
    "However, research after the Global Financial Crisis showed that momentum is **fragile**, especially during market rebounds, and that naïve implementations can experience severe drawdowns (Daniel & Moskowitz, 2016).\n",
    "\n",
    "To adapt the classical FX momentum strategy without over-engineering the model, we implement **three simple improvements** directly motivated by the academic literature.q\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Volatility Scaling (Barroso & Santa-Clara, 2015)**\n",
    "\n",
    "Momentum behaves poorly when its volatility spikes, particularly during crisis periods.\n",
    "A straightforward improvement is to **reduce exposure when recent strategy volatility is high**.\n",
    "\n",
    "**Implementation (very simple):**\n",
    "\n",
    "```\n",
    "vol_t   = rolling 60-day volatility of the strategy\n",
    "scale_t = target_vol / vol_t\n",
    "signal  = scale_t * raw_signal\n",
    "```\n",
    "\n",
    "**Why this matters:**\n",
    "FX markets exhibit volatility clustering. This adjustment prevents the strategy from taking large positions in unstable periods (e.g., 2008, 2020), thereby reducing drawdowns and improving Sharpe ratios.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Market-Condition Filter (Daniel & Moskowitz, 2016)**\n",
    "\n",
    "Momentum tends to crash in **sharp market reversals**. A full crash-robust model would be heavy, but a simple filter works well:\n",
    "\n",
    "```\n",
    "market_momentum = average 1-month return across all currencies\n",
    "\n",
    "if market_momentum < 0:\n",
    "    signals are reduced (for example by 50%)\n",
    "else:\n",
    "    full exposure\n",
    "```\n",
    "\n",
    "**Intuition:**\n",
    "When FX markets collectively reverse after stress, momentum spreads compress violently.\n",
    "This lightweight filter avoids trading aggressively in these regimes without requiring complex modelling.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Combine Cross-Sectional and Time-Series Momentum (Moskowitz, Ooi & Pedersen, 2012)**\n",
    "\n",
    "Cross-sectional momentum (ranking currencies against each other) can be noisy.\n",
    "Adding a **simple time-series component** stabilises signals and improves persistence.\n",
    "\n",
    "**Implementation:**\n",
    "\n",
    "```\n",
    "ts_signal     = sign(50-day cumulative return of each currency)\n",
    "final_signal  = 0.5 * cross_sectional + 0.5 * ts_signal\n",
    "```\n",
    "\n",
    "**Benefit:**\n",
    "If a currency is a “relative winner” but not trending upward, the signal is moderated.\n",
    "If both components agree, the position is reinforced.\n",
    "This reduces false positive trades and improves robustness across regimes.\n",
    "\n",
    "---\n",
    "\n",
    "# **Summary**\n",
    "\n",
    "With only three compact enhancements, the FX momentum strategy becomes:\n",
    "\n",
    "* **More stable** (volatility scaling)\n",
    "* **Less exposed to crashes** (market-condition filter)\n",
    "* **More robust and persistent** (hybrid momentum signal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c662e648-9324-4f83-af97-9c921de34c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 1. Split BID / ER / OFFER\n",
    "# =====================================================\n",
    "\n",
    "def split_bid_offer(df):\n",
    "    bid_cols   = [c for c in df.columns if c.endswith(\"_BID\")]\n",
    "    er_cols    = [c for c in df.columns if c.endswith(\"_ER\")]\n",
    "    offer_cols = [c for c in df.columns if c.endswith(\"_OFFER\")]\n",
    "\n",
    "    BID   = df[bid_cols].copy()\n",
    "    ER    = df[er_cols].copy()\n",
    "    OFFER = df[offer_cols].copy()\n",
    "\n",
    "    BID.columns   = [c.replace(\"_BID\", \"\") for c in bid_cols]\n",
    "    ER.columns    = [c.replace(\"_ER\", \"\") for c in er_cols]\n",
    "    OFFER.columns = [c.replace(\"_OFFER\", \"\") for c in offer_cols]\n",
    "\n",
    "    return BID, ER, OFFER\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 2. Basic momentum building blocks\n",
    "# =====================================================\n",
    "\n",
    "def compute_log_returns(ER):\n",
    "    return np.log(ER).diff()\n",
    "\n",
    "def compute_cross_sectional_momentum(log_ret, lookback):\n",
    "    return log_ret.rolling(lookback).sum()\n",
    "\n",
    "def compute_time_series_momentum(ER, ts_window):\n",
    "    return np.sign(ER.pct_change(ts_window))\n",
    "\n",
    "def combine_momentum(cs, ts):\n",
    "    return 0.5 * cs + 0.5 * ts\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 3. Market filter\n",
    "# =====================================================\n",
    "\n",
    "def compute_market_momentum(momentum):\n",
    "    return momentum.mean(axis=1)\n",
    "\n",
    "def market_regime_multiplier(market_mom, threshold):\n",
    "    return 1 - 0.5 * (market_mom < threshold).astype(float)\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 4. Signal construction\n",
    "# =====================================================\n",
    "\n",
    "def select_assets(momentum_vector, pct):\n",
    "    momentum_vector = momentum_vector.dropna()\n",
    "    if momentum_vector.empty:\n",
    "        return [], []\n",
    "\n",
    "    n = len(momentum_vector)\n",
    "    k = int(np.floor(n * pct))\n",
    "\n",
    "    winners = list(momentum_vector.nlargest(k).index)\n",
    "    losers  = list(momentum_vector.nsmallest(k).index)\n",
    "\n",
    "    return winners, losers\n",
    "\n",
    "\n",
    "def build_signal_matrix(momentum, dates, assets, hold_period, pct):\n",
    "    signals = pd.DataFrame(0, index=dates, columns=assets)\n",
    "    rebalance_dates = dates[::hold_period]\n",
    "\n",
    "    for t in rebalance_dates:\n",
    "        winners, losers = select_assets(momentum.loc[t], pct)\n",
    "        signals.loc[t, winners] = 1\n",
    "        signals.loc[t, losers]  = -1\n",
    "\n",
    "    return signals.replace(0, np.nan).ffill().fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 5. Volatility scaling\n",
    "# =====================================================\n",
    "\n",
    "def compute_volatility_scaler(r, window=60, target_vol=0.10):\n",
    "    vol = r.rolling(window).std()\n",
    "    scale = (target_vol / vol).clip(upper=3)\n",
    "    return scale\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 6A. Mid-only execution (MTM daily)\n",
    "# =====================================================\n",
    "\n",
    "def compute_mid_execution(ER, signals):\n",
    "    log_ret = np.log(ER).diff()\n",
    "    return (signals.shift(1) * log_ret).mean(axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 6B. Correct bid/ask execution with monthly holding\n",
    "# =====================================================\n",
    "\n",
    "def compute_bidask_execution(BID, OFFER, ER, signals, hold_period=22):\n",
    "\n",
    "    dates = ER.index\n",
    "    assets = ER.columns\n",
    "\n",
    "    daily_mid_ret = np.log(ER).diff()\n",
    "    portfolio_ret = pd.Series(0.0, index=dates)\n",
    "\n",
    "    # Detect true rebalance dates (signal changes)\n",
    "    rebal_dates = signals.diff().abs().sum(axis=1)\n",
    "    rebal_dates = rebal_dates[rebal_dates > 0].index\n",
    "    rebal_dates = rebal_dates.sort_values()\n",
    "\n",
    "    for i in range(len(rebal_dates)-1):\n",
    "\n",
    "        t_entry = rebal_dates[i]\n",
    "        t_exit  = rebal_dates[i+1]\n",
    "\n",
    "        pos = signals.loc[t_entry]\n",
    "        active = pos[pos != 0].index\n",
    "\n",
    "        if len(active) == 0:\n",
    "            continue\n",
    "\n",
    "        # --- 1. Daily MTM using mid ---------------------\n",
    "        mtm = (signals.loc[t_entry] * daily_mid_ret)[active]\n",
    "\n",
    "        # Convert timestamps to index positions\n",
    "        entry_idx = daily_mid_ret.index.get_loc(t_entry) + 1\n",
    "        exit_idx  = daily_mid_ret.index.get_loc(t_exit)\n",
    "\n",
    "        if entry_idx <= exit_idx:\n",
    "            mtm_period = mtm.iloc[entry_idx : exit_idx + 1]\n",
    "            portfolio_ret.iloc[entry_idx : exit_idx + 1] = mtm_period.mean(axis=1)\n",
    "\n",
    "        # --- 2. Entry transaction cost -------------------\n",
    "        entry_cost = 0\n",
    "        for cur in active:\n",
    "            if pos[cur] == 1:   # long\n",
    "                entry_cost += np.log(OFFER.loc[t_entry, cur]) - np.log(ER.loc[t_entry, cur])\n",
    "            else:               # short\n",
    "                entry_cost += np.log(ER.loc[t_entry, cur]) - np.log(BID.loc[t_entry, cur])\n",
    "\n",
    "        # --- 3. Exit transaction cost --------------------\n",
    "        exit_cost = 0\n",
    "        for cur in active:\n",
    "            if pos[cur] == 1:\n",
    "                exit_cost += np.log(ER.loc[t_exit, cur]) - np.log(BID.loc[t_exit, cur])\n",
    "            else:\n",
    "                exit_cost += np.log(OFFER.loc[t_exit, cur]) - np.log(ER.loc[t_exit, cur])\n",
    "\n",
    "        # Record total period PnL on exit date\n",
    "        portfolio_ret.loc[t_exit] += (-entry_cost - exit_cost)\n",
    "\n",
    "    return portfolio_ret\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 7. Compute hybrid momentum signals\n",
    "# =====================================================\n",
    "\n",
    "def compute_signals(ER, lookback=4, hold_period=22, pct=0.3,\n",
    "                    ts_window=50, market_threshold=0):\n",
    "\n",
    "    log_ret = compute_log_returns(ER)\n",
    "    cs = compute_cross_sectional_momentum(log_ret, lookback)\n",
    "    ts = compute_time_series_momentum(ER, ts_window)\n",
    "\n",
    "    hybrid = combine_momentum(cs, ts)\n",
    "\n",
    "    market_mom = compute_market_momentum(hybrid)\n",
    "    regime = market_regime_multiplier(market_mom, market_threshold)\n",
    "\n",
    "    hybrid_filtered = hybrid.mul(regime, axis=0)\n",
    "\n",
    "    signals = build_signal_matrix(\n",
    "        hybrid_filtered,\n",
    "        ER.index,\n",
    "        ER.columns,\n",
    "        hold_period,\n",
    "        pct\n",
    "    )\n",
    "\n",
    "    return signals, hybrid_filtered, log_ret\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 8. Momentum using mid-only\n",
    "# =====================================================\n",
    "\n",
    "def momentum_ER_only(ER, signals, vol_window=60, target_vol=0.10):\n",
    "    raw = compute_mid_execution(ER, signals)\n",
    "    scale = compute_volatility_scaler(raw, vol_window, target_vol)\n",
    "    return raw * scale\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 9. Momentum using corrected bid/offer execution\n",
    "# =====================================================\n",
    "\n",
    "def momentum_bidask(BID, OFFER, ER, signals, hold_period=22,\n",
    "                    vol_window=60, target_vol=0.10):\n",
    "\n",
    "    raw = compute_bidask_execution(BID, OFFER, ER, signals, hold_period)\n",
    "    scale = compute_volatility_scaler(raw, vol_window, target_vol)\n",
    "    return raw * scale\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 10. Evaluation\n",
    "# =====================================================\n",
    "\n",
    "def evaluate_strategy(r):\n",
    "\n",
    "    perf = (1 + r).cumprod()\n",
    "\n",
    "    ann_ret = (1 + r.mean())**252 - 1\n",
    "    ann_vol = r.std() * np.sqrt(252)\n",
    "    sharpe  = ann_ret / ann_vol if ann_vol != 0 else np.nan\n",
    "\n",
    "    running_max = perf.cummax()\n",
    "    max_dd = ((perf - running_max) / running_max).min()\n",
    "\n",
    "    return pd.Series({\n",
    "        \"Annualized Return\": ann_ret,\n",
    "        \"Annualized Volatility\": ann_vol,\n",
    "        \"Sharpe Ratio\": sharpe,\n",
    "        \"Max Drawdown\": max_dd,\n",
    "        \"Skewness (daily)\": skew(r.dropna()),\n",
    "        \"Kurtosis (daily)\": kurtosis(r.dropna(), fisher=False)\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 11. Wrapper\n",
    "# =====================================================\n",
    "\n",
    "def run_portfolio_strategies_improved(portfolios, lookback=4, hold_period=22, pct=0.3, print_data = True):\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for name, df_port in portfolios.items():\n",
    "\n",
    "        BID, ER, OFFER = split_bid_offer(df_port)\n",
    "\n",
    "        signals, momentum, log_ret_spot = compute_signals(\n",
    "            ER,\n",
    "            lookback=lookback,\n",
    "            hold_period=hold_period,\n",
    "            pct=pct\n",
    "        )\n",
    "\n",
    "        ret_mid = momentum_ER_only(ER, signals)\n",
    "        stats_mid = evaluate_strategy(ret_mid)\n",
    "\n",
    "        ret_ba = momentum_bidask(BID, OFFER, ER, signals, hold_period)\n",
    "        stats_ba = evaluate_strategy(ret_ba)\n",
    "\n",
    "        results[name] = {\n",
    "            \"ER_only\": {\n",
    "                \"returns\": ret_mid,\n",
    "                \"stats\": stats_mid\n",
    "            },\n",
    "            \"BidAsk\": {\n",
    "                \"returns\": ret_ba,\n",
    "                \"stats\": stats_ba\n",
    "            },\n",
    "            \"signals\": signals,\n",
    "            \"momentum\": momentum,\n",
    "            \"log_returns\": log_ret_spot\n",
    "        }\n",
    "        if print_data: \n",
    "            print(\"\\n==============================\")\n",
    "            print(f\"Portfolio: {name}\")\n",
    "            print(\"=== ER-only ===\")\n",
    "            print(stats_mid)\n",
    "            print(\"=== Bid/Ask ===\")\n",
    "            print(stats_ba)\n",
    "\n",
    "    return results\n",
    "\n",
    "portfolio_run_momentum_strat_biblio= run_portfolio_strategies_improved(portfolios)\n",
    "\n",
    "summarize_portfolio(portfolio_run_momentum_strat_biblio, portfolios, \"P1\")\n",
    "plot_all_portfolios_pnl(portfolio_run_momentum_strat_biblio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1f283f-3bee-4cc8-8796-64cbab7bba81",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\"lookback\": 4, \"hold\": 22, \"pct\": 0.2},\n",
    "    {\"lookback\": 10, \"hold\": 22, \"pct\": 0.4},\n",
    "]\n",
    "# allow to test other setup -> we can maybe tune some values using optuna for bayesian optimisation of those parameters\n",
    "\n",
    "subsamples = {\n",
    "    \"1999-2007\": (\"1999-01-01\", \"2007-12-31\"), # (pre-crisis)\n",
    "    \"2008-2012\": (\"2008-01-01\", \"2012-12-31\"), # (Financial Crisis + Euro Crisis)\n",
    "    \"2013-2019\": (\"2013-01-01\", \"2019-12-31\"), # (QE, Low Volatility)\n",
    "    \"2020-2024\": (\"2020-01-01\", \"2024-12-31\"), # (COVID, Inflation, QT)\n",
    "}\n",
    "\n",
    "\n",
    "results_sub = {}\n",
    "\n",
    "for sub_name, (start, end) in subsamples.items():\n",
    "    print(sub_name) \n",
    "    df_sub = xusd_df.loc[start:end]\n",
    "    portfolios_sub = get_economic_portfolios(df_sub)\n",
    "    if len(df_sub) < 200:\n",
    "        continue\n",
    "\n",
    "    for p in param_grid:\n",
    "        lb = p[\"lookback\"]\n",
    "        hd = p[\"hold\"]\n",
    "        pct = p[\"pct\"]\n",
    "        portfolio_data = run_portfolio_strategies_improved(portfolios,lookback=lb, hold_period=hd, pct=pct, print_data = False)\n",
    "        summarize_portfolio(portfolio_data, portfolios, \"P1\") #change the key to visualize the portfolio you wish to comment on \n",
    "        plot_all_portfolios_pnl(portfolio_data)\n",
    "\n",
    "        key = f\"{sub_name} | LB={lb}, HP={hd}, PCT={pct}\"\n",
    "        results_sub[key] = portfolio_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3d31e5-ec57-4114-98ba-423ce54686cc",
   "metadata": {},
   "source": [
    "Despite integrating state-of-the-art enhancements such as volatility scaling (Barroso & Santa-Clara, 2015), crash-robust conditioning (Daniel & Moskowitz, 2016) and hybrid trend specifications (Moskowitz et al., 2012), the FX momentum strategy does not exhibit any economically meaningful improvement. This is fully consistent with the empirical literature, which shows that momentum is structurally weak in FX spot markets, highly regime-dependent, and largely dominated by bid–ask frictions and global volatility conditions. In short, the strategy fails not because of implementation errors, but because FX momentum is not a robust standalone factor over long horizons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425ea79a-5644-48cf-b958-5f173283a574",
   "metadata": {},
   "source": [
    "# Opening on other momentum based strategy boosted by some TCN \n",
    "\n",
    "# **TCN-Enhanced Momentum Strategy**\n",
    "\n",
    "This section presents an improved version of the classical FX momentum strategy by integrating a Temporal Convolutional Network (TCN) as a regime-conditioning and signal-refinement module. The objective is not to replace the economic logic of momentum, but rather to strengthen its predictive content and avoid allocating risk in unfavourable market conditions.\n",
    "\n",
    "## 1. Motivation\n",
    "\n",
    "Traditional cross-sectional momentum ranks currencies based on their recent cumulative return and goes long the top performers while shorting the weakest ones. While simple and empirically validated (Jegadeesh & Titman, 1993; Moskowitz et al., 2012), this approach suffers from:\n",
    "\n",
    "* sensitivity to noisy short-term returns\n",
    "* vulnerability during reversal periods (Daniel & Moskowitz, 2016)\n",
    "* unstable performance across macro-financial regimes\n",
    "\n",
    "To address these issues, we augment the raw momentum signal with a data-driven component extracted by a **Temporal Convolutional Network**, a deep learning architecture specifically designed for sequential modelling.\n",
    "\n",
    "## 2. Why a TCN?\n",
    "\n",
    "A TCN is a causal convolutional neural network that:\n",
    "\n",
    "* processes time series without leakage (only past data is used)\n",
    "* captures multi-scale temporal dependencies\n",
    "* is more stable, faster to train, and less prone to overfitting than LSTMs\n",
    "* is well suited to regime identification and denoising\n",
    "\n",
    "Instead of asking the network to \"predict prices\", we train it on the **future sign of the average FX basket momentum**, i.e. whether the market environment in the next few weeks is favourable or unfavourable for momentum.\n",
    "\n",
    "## 3. Construction of the learning target\n",
    "\n",
    "For each time (t), we define:\n",
    "\n",
    "\n",
    "$$ y_t = \\text{sign}\\big( r^{\\text{avg}}_{t \\to t+H} \\big) $$ \n",
    "\n",
    "where $r^{\\text{avg}}_{t \\to t+H}$ is the average FX return over a 20-day horizon.\n",
    "This target reflects whether momentum returns are likely to be positive or negative.\n",
    "\n",
    "A neutral zone is introduced to avoid labelling noise:\n",
    "\n",
    "* $ y_t = +1 $ if future return > +0.2%\n",
    "* $ y_t = -1 $ if future return < −0.2%\n",
    "* otherwise label is removed from training\n",
    "\n",
    "This ensures the TCN learns from meaningful directional episodes.\n",
    "\n",
    "## 4. TCN as a momentum filter\n",
    "\n",
    "Once trained, the TCN outputs a probability $p_t\\in[0,1]$ that the next regime is favourable for momentum. This probability acts as a **smooth regime filter** applied to the classical ranking signal:\n",
    "\n",
    "$$ enhanced\\_signal_{t,i} = momentum\\_signal_{t,i} \\times f(p_t) $$\n",
    "\n",
    "with:\n",
    "\n",
    "$$ f(p) = 0.5 + p $$\n",
    "\n",
    "so the filter always remains between 0.5 and 1.5\n",
    "→ never fully shutting down trades,\n",
    "→ but reducing exposure during adverse regimes,\n",
    "→ and increasing it during momentum-friendly regimes.\n",
    "\n",
    "## 5. Portfolio construction\n",
    "\n",
    "The final steps remain identical to your original methodology:\n",
    "\n",
    "1. rank currencies based on the enhanced momentum signal\n",
    "2. take long positions on the top quantile, short positions on the bottom\n",
    "3. hold for 22 days\n",
    "4. compute P&L using bid/ask execution prices\n",
    "\n",
    "This preserves the economics of momentum while benefiting from machine-learned regime identification.\n",
    "\n",
    "## 6. Expected impact\n",
    "\n",
    "The TCN enhancement aims to:\n",
    "\n",
    "* stabilise performance across subsamples\n",
    "* mitigate losses during unfavorable market regimes\n",
    "* improve Sharpe ratio by reducing exposure in noisy environments\n",
    "* strengthen trend-following periods through selective leverage\n",
    "\n",
    "It does **not** create a black-box strategy.\n",
    "It is an **economically grounded momentum strategy** with an **ML-based risk overlay**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119503e0-734c-4b07-8def-bbdc98739e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from scipy.stats import skew, kurtosis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22430d1-9d15-47a4-9778-187512fa7e4e",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50171006-8b28-4033-a26c-558adf0a918f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 1. Build FEATURE SET for the TCN\n",
    "# =====================================================\n",
    "\n",
    "def build_features(ER):\n",
    "    \n",
    "    log_ret = np.log(ER).diff()\n",
    "\n",
    "    feats = pd.DataFrame(index=ER.index)\n",
    "\n",
    "    # Multi-horizon returns (each produces a DF with one column per currency)\n",
    "    feats_ret2  = log_ret.rolling(2).sum().add_prefix(\"ret2_\")\n",
    "    feats_ret4  = log_ret.rolling(4).sum().add_prefix(\"ret4_\")\n",
    "    feats_ret10 = log_ret.rolling(10).sum().add_prefix(\"ret10_\")\n",
    "    feats_ret22 = log_ret.rolling(22).sum().add_prefix(\"ret22_\")\n",
    "\n",
    "    # Volatility\n",
    "    feats_vol10 = log_ret.rolling(10).std().add_prefix(\"vol10_\")\n",
    "    feats_vol22 = log_ret.rolling(22).std().add_prefix(\"vol22_\")\n",
    "\n",
    "    # Skew / kurtosis → apply per column\n",
    "    feats_skew22 = log_ret.rolling(22).apply(lambda x: skew(x), raw=False).add_prefix(\"skew22_\")\n",
    "    feats_kurt22 = log_ret.rolling(22).apply(lambda x: kurtosis(x), raw=False).add_prefix(\"kurt22_\")\n",
    "\n",
    "    # Cross-sectional rank (momentum flavour)\n",
    "    cs_rank = ER.rank(axis=1, pct=True).add_prefix(\"rank_\")\n",
    "\n",
    "    # Carry proxy\n",
    "    carry = (ER.shift(-22) / ER - 1).add_prefix(\"carry_\")\n",
    "\n",
    "    # Merge all features horizontally\n",
    "    feats = pd.concat([\n",
    "        feats_ret2, feats_ret4, feats_ret10, feats_ret22,\n",
    "        feats_vol10, feats_vol22,\n",
    "        feats_skew22, feats_kurt22,\n",
    "        cs_rank,\n",
    "        carry\n",
    "    ], axis=1)\n",
    "\n",
    "    return feats\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 3. Labels = future 22-day return (per currency)\n",
    "# =====================================================\n",
    "\n",
    "def compute_labels(ER):\n",
    "    return ER.pct_change(22).shift(-22)\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 4. Build TCN-compatible dataset: [samples, window, features]\n",
    "# =====================================================\n",
    "\n",
    "def build_tcn_dataset(features, labels, window=30):\n",
    "\n",
    "    X_list, y_list = [], []\n",
    "\n",
    "    for c in features.columns:\n",
    "        feat_c = features[c].dropna()\n",
    "        lab_c  = labels[c].dropna()\n",
    "\n",
    "        idx = feat_c.index.intersection(lab_c.index)\n",
    "\n",
    "        feat_c = feat_c.loc[idx]\n",
    "        lab_c  = lab_c.loc[idx]\n",
    "\n",
    "        for i in range(window, len(idx)):\n",
    "            X_list.append(feat_c.iloc[i-window:i].values)\n",
    "            y_list.append(lab_c.iloc[i])\n",
    "\n",
    "    X = np.array(X_list)\n",
    "    y = np.array(y_list)\n",
    "\n",
    "    # reshape: [samples, window, 1] → TCN expects channels last\n",
    "    return X.reshape(len(X), window, 1), y\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 5. Build & train the TCN\n",
    "# =====================================================\n",
    "\n",
    "def build_tcn_model(window):\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(window, 1)),\n",
    "        layers.Conv1D(filters=32, kernel_size=3, dilation_rate=1, activation='relu'),\n",
    "        layers.Conv1D(filters=32, kernel_size=3, dilation_rate=2, activation='relu'),\n",
    "        layers.Conv1D(filters=32, kernel_size=3, dilation_rate=4, activation='relu'),\n",
    "        layers.GlobalAveragePooling1D(),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(1)   # predict future return\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 6. Momentum baseline signal\n",
    "# =====================================================\n",
    "\n",
    "def compute_base_momentum(ER, lookback=4):\n",
    "    return np.log(ER).diff().rolling(lookback).sum()\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 7. Hybrid TCN-enhanced Momentum Strategy\n",
    "# =====================================================\n",
    "\n",
    "def tcn_enhanced_momentum(df, lookback=4, hold_period=22, pct=0.3, window=30):\n",
    "\n",
    "    BID, ER, OFFER = split_bid_offer(df)\n",
    "\n",
    "    # features + labels\n",
    "    feats = build_features(ER)\n",
    "    labels = compute_labels(ER)\n",
    "\n",
    "    # dataset\n",
    "    X, y = build_tcn_dataset(feats, labels, window)\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X.reshape(len(X), -1)).reshape(len(X), window, 1)\n",
    "\n",
    "    # train/val split\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, shuffle=False, test_size=0.2)\n",
    "\n",
    "    # train TCN\n",
    "    model = build_tcn_model(window)\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
    "              epochs=20, batch_size=32, verbose=1)\n",
    "\n",
    "    # predict future returns (TCN score)\n",
    "    tcn_pred = model.predict(X, verbose=0).flatten()\n",
    "\n",
    "    # convert TCN predictions back to a time series aligned to ER\n",
    "    idx = feats.index[window:]\n",
    "    tcn_series = pd.Series(tcn_pred, index=idx)\n",
    "\n",
    "    # base momentum signal\n",
    "    base_mom = compute_base_momentum(ER, lookback)\n",
    "\n",
    "    # merge both signals\n",
    "    hybrid = 0.5 * base_mom.mean(axis=1) + 0.5 * tcn_series\n",
    "\n",
    "    # build positions from hybrid\n",
    "    signals = pd.DataFrame(0, index=ER.index, columns=ER.columns)\n",
    "    rebalance_dates = ER.index[lookback::hold_period]\n",
    "\n",
    "    for t in rebalance_dates:\n",
    "        if t not in hybrid.index: continue\n",
    "\n",
    "        today = hybrid.loc[t]\n",
    "        ranks = today.rank(pct=True)\n",
    "\n",
    "        long_assets  = ranks[ranks > 1 - pct].index\n",
    "        short_assets = ranks[ranks < pct].index\n",
    "\n",
    "        signals.loc[t, long_assets] = 1\n",
    "        signals.loc[t, short_assets] = -1\n",
    "\n",
    "    # hold\n",
    "    signals = signals.replace(0, np.nan).ffill().fillna(0)\n",
    "\n",
    "    # compute returns\n",
    "    long_ret  = np.log(BID)   - np.log(OFFER.shift(1))\n",
    "    short_ret = np.log(OFFER) - np.log(BID.shift(1))\n",
    "\n",
    "    executed = (\n",
    "        (signals.shift(1) == 1)  * long_ret +\n",
    "        (signals.shift(1) == -1) * short_ret\n",
    "    )\n",
    "\n",
    "    strat_ret = executed.mean(axis=1)\n",
    "\n",
    "    return strat_ret, signals, hybrid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a3f7f2-0523-498e-95c1-5d81d340ea9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_ret, sig, enh_sig = tcn_enhanced_momentum(\n",
    "    xusd_df,\n",
    "    lookback=5,\n",
    "    hold_period=22,\n",
    "    pct=0.3\n",
    ")\n",
    "\n",
    "stats = evaluate_strategy(strat_ret)\n",
    "print(stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939453de-be95-48c2-bc1e-ba05820fc6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr = \"AUSTRALIAN\"\n",
    "plot_prices(ER, currency = curr)\n",
    "plot_signals(ER, sig, currency = curr)\n",
    "plot_pnl(strat_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb6c72e-c999-41fa-aa60-39be1d431d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(regimes)\n",
    "plt.title(\"TCN regime filter\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
