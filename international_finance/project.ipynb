{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "253f7c06-4efe-4614-86f2-0966cc597924",
   "metadata": {},
   "source": [
    "# **International Finance**\n",
    "Thomas de Portzamparc - 7/12/2025 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0b41fd-0d3e-4125-adc4-3759f17f35d9",
   "metadata": {},
   "source": [
    "# **Module Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b7726f-4db2-4c38-b3a0-7e54886591f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from scipy.stats import skew, kurtosis\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b697a20a-a0dc-4080-9622-30d199883918",
   "metadata": {},
   "source": [
    "# **Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644824d3-d461-4b62-89a4-7325a04b05de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_forward = pd.read_excel(\"fwd_rates.xlsx\", header = 0, skiprows = [2], sheet_name = None, index_col = 0)\n",
    "df_forward = pd.concat(dict_forward.values(), axis = 1)\n",
    "df_forward = df_forward[1:]\n",
    "dict_spot = pd.read_excel(\"spot_rates.xls\", header = [0, 1], sheet_name = None, index_col = 0)\n",
    "df_spot = pd.concat(dict_spot.values(), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b63a02-18db-4582-8ee7-bcc79ed3c046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we will get the dollar exchange rate and remove the other unused columns to manipulate the dataframe quicker\n",
    "usd_columns_spot = [col for col in df_spot if \" US\" in col[0] or \"US \" in col [0]] \n",
    "usd_columns_fwd = [col for col in df_forward if \" US\" in col or \"US \" in col]\n",
    "# A lot of XUSD spot columns are missing, we may need to retreive them buy using other currency pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15761fe0-427f-4f87-a749-a301b8b91b29",
   "metadata": {},
   "source": [
    "# **Data Pre - Processing**\n",
    "Here we will run some pre - treatment prior to executing strategies for both spot and forward dataframes\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a67d5e-bda0-4884-a4f6-a959afcdeb3f",
   "metadata": {},
   "source": [
    "## Spot dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a43d05b-5e8c-426d-9d1e-b87674d7eb1e",
   "metadata": {},
   "source": [
    "### Computing of the XUSD spot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba562d9c-9cd6-4f06-8ac5-3dc6f7d78da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# Build metadata (Cur1 / Cur2 / Type)\n",
    "# =========================================================\n",
    "# Extract the currency structure and associated quote type for each column.\n",
    "# Titles follow the pattern: \"<CUR1> TO <CUR2> - <QUOTE TYPE>\".\n",
    "# We standardize the quote nature into BID, OFFER, or ER (exchange rate mid).\n",
    "\n",
    "records = []\n",
    "\n",
    "for (title, code) in df_spot.columns:\n",
    "    # Identify base and quote currencies from the \"CUR1 TO CUR2\" portion\n",
    "    left, right = title.split(\"TO\")\n",
    "    cur1 = left.strip().split()[0].upper()\n",
    "    cur2 = right.strip().split()[0].upper()\n",
    "    \n",
    "    # Extract the descriptive quote label from the suffix (e.g. \"BID SPOT\")\n",
    "    raw_nature = title.split(\"-\")[-1].strip().upper()\n",
    "\n",
    "    # Convert the descriptive label to a standardized quote type\n",
    "    if \"BID\" in raw_nature:\n",
    "        price_type = \"BID\"\n",
    "    elif \"OFFER\" in raw_nature:\n",
    "        price_type = \"OFFER\"\n",
    "    elif \"EXCHANGE\" in raw_nature:\n",
    "        price_type = \"ER\"\n",
    "    else:\n",
    "        price_type = \"OTHER\"\n",
    "\n",
    "    records.append({\n",
    "        \"Title\": title,\n",
    "        \"Code\": code,\n",
    "        \"Cur1\": cur1,\n",
    "        \"Cur2\": cur2,\n",
    "        \"RawNature\": raw_nature,\n",
    "        \"Type\": price_type\n",
    "    })\n",
    "\n",
    "meta = pd.DataFrame(records, index=df_spot.columns)\n",
    "\n",
    "# Ensure consistent MultiIndex formatting across df_spot and metadata\n",
    "df_spot.columns = pd.MultiIndex.from_tuples([(str(a), str(b)) for a, b in df_spot.columns])\n",
    "meta.index       = pd.MultiIndex.from_tuples([(str(a), str(b)) for a, b in meta.index])\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Helpers\n",
    "# =========================================================\n",
    "\n",
    "def get_leg(cur1, cur2, typ):\n",
    "    \"\"\"\n",
    "    Select the time series corresponding to a specific currency pair (cur1 → cur2)\n",
    "    and quote type (BID, OFFER, ER). Returns None if the requested leg is missing.\n",
    "    \"\"\"\n",
    "    mask = (meta[\"Cur1\"] == cur1) & (meta[\"Cur2\"] == cur2) & (meta[\"Type\"] == typ)\n",
    "    idx = meta.index[mask]\n",
    "    if len(idx) == 0:\n",
    "        return None\n",
    "    return df_spot[idx[0]]\n",
    "\n",
    "\n",
    "def invert_bid_ask(bid, ask):\n",
    "    \"\"\"\n",
    "    Convert an X/USD bid-ask pair into the corresponding USD/X pair.\n",
    "    The inverted bid equals 1/ask and the inverted ask equals 1/bid.\n",
    "    \"\"\"\n",
    "    return 1/ask, 1/bid\n",
    "\n",
    "# Some quotes are missing we will thus input the missing values using the quote present in the dataframe \n",
    "\n",
    "\n",
    "def complete_quotes(bid, offer, mid):\n",
    "    if bid is None and offer is None and mid is None:\n",
    "        return None, None, None\n",
    "\n",
    "    # Convert to series\n",
    "    b = bid.copy() if bid is not None else None\n",
    "    o = offer.copy() if offer is not None else None\n",
    "    m = mid.copy() if mid is not None else None\n",
    "\n",
    "    # Ensure all exist\n",
    "    if b is None:\n",
    "        b = pd.Series(index=o.index if o is not None else m.index, dtype=float)\n",
    "    if o is None:\n",
    "        o = pd.Series(index=b.index if b is not None else m.index, dtype=float)\n",
    "    if m is None:\n",
    "        m = pd.Series(index=b.index if b is not None else o.index, dtype=float)\n",
    "\n",
    "    # 1. Fill mid when possible\n",
    "    mask_mid = m.isna() & b.notna() & o.notna()\n",
    "    m.loc[mask_mid] = (b.loc[mask_mid] + o.loc[mask_mid]) / 2\n",
    "\n",
    "    # 2. Fill bid when possible\n",
    "    mask_bid = b.isna() & m.notna() & o.notna()\n",
    "    b.loc[mask_bid] = 2 * m.loc[mask_bid] - o.loc[mask_bid]\n",
    "\n",
    "    # 3. Fill offer when possible\n",
    "    mask_offer = o.isna() & m.notna() & b.notna()\n",
    "    o.loc[mask_offer] = 2 * m.loc[mask_offer] - b.loc[mask_offer]\n",
    "\n",
    "    # 4. Last resort: if both bid & offer missing but mid exists\n",
    "    mask_both = b.isna() & o.isna() & m.notna()\n",
    "    b.loc[mask_both] = m.loc[mask_both]\n",
    "    o.loc[mask_both] = m.loc[mask_both]\n",
    "\n",
    "    return b, o, m\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Build USDX = X per USD\n",
    "# =========================================================\n",
    "# Construct quotes expressing the value of 1 USD in each foreign currency.\n",
    "# Direct USD→X quotes are used when available; otherwise, cross rates are\n",
    "# reconstructed using pivot currencies.\n",
    "\n",
    "usdx = pd.DataFrame(index=df_spot.index)\n",
    "\n",
    "# List all currencies appearing in Cur1 or Cur2, excluding USD\n",
    "currencies = set(meta[\"Cur1\"].unique()) | set(meta[\"Cur2\"].unique())\n",
    "currencies.discard(\"US\")\n",
    "\n",
    "# Start with direct USD→UK and USD→EURO pairs\n",
    "for tgt in [\"UK\", \"EURO\"]:\n",
    "    bid_X_USD   = get_leg(\"US\", tgt, \"BID\")\n",
    "    offer_X_USD = get_leg(\"US\", tgt, \"OFFER\")\n",
    "    mid_X_USD   = get_leg(\"US\", tgt, \"ER\")\n",
    "\n",
    "    # Fill missing values if necessary\n",
    "    bid_X_USD, offer_X_USD, mid_X_USD = complete_quotes(bid_X_USD, offer_X_USD, mid_X_USD)\n",
    "\n",
    "    if bid_X_USD is not None and offer_X_USD is not None:\n",
    "        # Convert X/USD quotes into USD→X using bid/ask inversion\n",
    "        bid_USD_X, offer_USD_X = invert_bid_ask(bid_X_USD, offer_X_USD)\n",
    "        mid_USD_X = 1/mid_X_USD\n",
    "\n",
    "        usdx[f\"{tgt}_BID\"]   = bid_USD_X\n",
    "        usdx[f\"{tgt}_OFFER\"] = offer_USD_X\n",
    "        usdx[f\"{tgt}_ER\"]    = mid_USD_X\n",
    "\n",
    "\n",
    "# Compute cross USD→X rates via pivot currencies when no direct quote exists\n",
    "pivots = [\"UK\", \"EURO\"]\n",
    "\n",
    "for cur in sorted(currencies):\n",
    "    if cur in [\"UK\", \"EURO\"]:\n",
    "        continue\n",
    "\n",
    "    for pivot in pivots:\n",
    "\n",
    "        # Retrieve X→pivot legs\n",
    "        bid_X_P   = get_leg(cur,  pivot, \"BID\")\n",
    "        offer_X_P = get_leg(cur,  pivot, \"OFFER\")\n",
    "        mid_X_P   = get_leg(cur,  pivot, \"ER\")\n",
    "\n",
    "        # Retrieve USD→pivot legs\n",
    "        bid_US_P   = get_leg(\"US\", pivot, \"BID\")\n",
    "        offer_US_P = get_leg(\"US\", pivot, \"OFFER\")\n",
    "        mid_US_P   = get_leg(\"US\", pivot, \"ER\")\n",
    "\n",
    "        # Complete missing values before using them\n",
    "        bid_X_P, offer_X_P, mid_X_P = complete_quotes(bid_X_P, offer_X_P, mid_X_P)\n",
    "        bid_US_P, offer_US_P, mid_US_P = complete_quotes(bid_US_P, offer_US_P, mid_US_P)\n",
    "        # Skip if still incomplete (very unlikely after correction)\n",
    "        if bid_X_P is None or offer_X_P is None or bid_US_P is None or offer_US_P is None:\n",
    "            continue\n",
    "\n",
    "        # Compute X per USD via the pivot:\n",
    "        # Sequence: USD→pivot (using ask), then pivot→X (using bid)\n",
    "        bid_USD_X   = bid_X_P   / offer_US_P\n",
    "        offer_USD_X = offer_X_P / bid_US_P\n",
    "        mid_USD_X   = mid_X_P / mid_US_P\n",
    "\n",
    "        usdx[f\"{cur}_BID\"]   = bid_USD_X\n",
    "        usdx[f\"{cur}_OFFER\"] = offer_USD_X\n",
    "        usdx[f\"{cur}_ER\"]    = mid_USD_X\n",
    "\n",
    "        break\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Convert USDX → XUSD (final quoting convention)\n",
    "# =========================================================\n",
    "# Invert each USD→X quote to obtain the final XUSD convention (USD per unit of X).\n",
    "# Bid and ask are swapped upon inversion.\n",
    "\n",
    "xusd_df = pd.DataFrame(index=usdx.index)\n",
    "\n",
    "for col in usdx.columns:\n",
    "    cur, typ = col.split(\"_\")\n",
    "\n",
    "    if typ == \"BID\":\n",
    "        xusd_df[f\"{cur}_OFFER\"] = 1 / usdx[col]\n",
    "\n",
    "    elif typ == \"OFFER\":\n",
    "        xusd_df[f\"{cur}_BID\"]   = 1 / usdx[col]\n",
    "\n",
    "    else:  # ER (mid)\n",
    "        xusd_df[f\"{cur}_ER\"]    = 1 / usdx[col]\n",
    "\n",
    "xusd_df = xusd_df.sort_index(axis=1)\n",
    "xusd_df.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa7c0d4-5e2e-444a-ae49-85812d48ba61",
   "metadata": {},
   "source": [
    "### Coherence of the spot obtained \n",
    "The first thing to do here is to verify the coherence of our computing, to do this we have several ressources, chatgpt and other AI tool may help us quickly review our code but to check the coherence of our data we can look at some spots on Yfinance or do it empirically as we've done below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c25078-25f1-4509-a107-e95840644fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnary containing the index of the comparison dataframe and the yfinance ticker to extract market data\n",
    "fx_map = {\n",
    "    \"UK\": \"GBPUSD=X\",\n",
    "    \"EURO\": \"EURUSD=X\",\n",
    "    \"PHILIPPINE\": \"PHPUSD=X\",\n",
    "    \"CANADIAN\": \"CADUSD=X\",\n",
    "    \"NORWEGIAN\": \"NOKUSD=X\",\n",
    "    \"NEW\": \"NZDUSD=X\",\n",
    "    \"CZECH\": \"CZKUSD=X\",\n",
    "    \"HUNGARIAN\": \"HUFUSD=X\",\n",
    "    \"POLISH\": \"PLNUSD=X\",\n",
    "    \"SINGAPORE\": \"SGDUSD=X\",\n",
    "    \"RUSSIAN\": \"RUBUSD=X\",\n",
    "    \"INDIAN\": \"INRUSD=X\",\n",
    "    \"SOUTH\": \"ZARUSD=X\",\n",
    "    \"INDONESIAN\": \"IDRUSD=X\",\n",
    "    \"BULGARIAN\": \"BGNUSD=X\",\n",
    "    \"ISRAELI\": \"ILSUSD=X\",\n",
    "    \"JAPANESE\": \"JPYUSD=X\",\n",
    "    \"BRAZILIAN\": \"BRLUSD=X\",\n",
    "    \"SWEDISH\": \"SEKUSD=X\",\n",
    "    \"THAI\": \"THBUSD=X\",\n",
    "    \"AUSTRALIAN\": \"AUDUSD=X\",\n",
    "    \"SWISS\": \"CHFUSD=X\",\n",
    "    \"MEXICAN\": \"MXNUSD=X\",\n",
    "    \"CHILEAN\": \"CLPUSD=X\",\n",
    "}\n",
    "\n",
    "target_date = \"2024-10-23\"\n",
    "results = {}\n",
    "\n",
    "for name, ticker in fx_map.items():\n",
    "    try:\n",
    "        data = yf.download(\n",
    "            ticker,\n",
    "            start=\"2024-10-23\",\n",
    "            end=\"2024-10-24\",\n",
    "            progress=False,\n",
    "            auto_adjust=False\n",
    "        )\n",
    "        \n",
    "        # If no data → record NaN\n",
    "        if data.empty:\n",
    "            results[name+\"_ER\"] = float(\"nan\")\n",
    "            continue\n",
    "        \n",
    "        # Look for the exact date\n",
    "        date_match = data.loc[data.index.strftime(\"%Y-%m-%d\") == target_date]\n",
    "        \n",
    "        if len(date_match) == 0:\n",
    "            results[name+\"_ER\"] = float(\"nan\")\n",
    "        else:\n",
    "            results[name+\"_ER\"] = date_match[\"Close\"].iloc[0]\n",
    "    \n",
    "    except Exception:\n",
    "        results[name] = float(\"nan\")\n",
    "\n",
    "clean_results = {k: float(v.iloc[0])for k, v in results.items()}\n",
    "df_check = pd.DataFrame.from_dict(clean_results,orient=\"index\", columns=[\"USD per X\"]) # dataframe \n",
    "\n",
    "\n",
    "# DATA comparison \n",
    "row_model = xusd_df.loc[target_date]\n",
    "row_model.name = \"USD_per_X_professor_data\"\n",
    "df_model = row_model.to_frame(name=\"USD_per_X_model\")\n",
    "comparison = df_model.join(df_check, how=\"inner\")\n",
    "comparison[\"abs_diff\"] = comparison[\"USD_per_X_model\"] - comparison[\"USD per X\"]\n",
    "comparison[\"rel_diff(%)\"] = comparison[\"abs_diff\"] / comparison[\"USD per X\"] * 100\n",
    "\n",
    "print(comparison.sort_values(\"rel_diff(%)\").head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6564f1-2dbf-485f-9e40-97e8d5cfee94",
   "metadata": {},
   "source": [
    "Once the verification is done, we can pursue our calculus without worrying about wether our currency pairs are quoted in the wrong direction. First and foremost we will thus start by computing some log returns -> we pick this because it has the nice property that the returns are additive and because the subject encourage us to go this way "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50205344-4ea8-4595-b20d-008d41158e4a",
   "metadata": {},
   "source": [
    "## Forward dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47372082-5e9a-4b0d-8004-8ed66add2b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Utility: ensure all columns are 1D numeric arrays\n",
    "# ============================================================\n",
    "\n",
    "def force_1d(df):\n",
    "    \"\"\"\n",
    "    Ensures all columns are flat 1D arrays and numeric.\n",
    "    Handles nested arrays, 2D structures, and string-based numerics.\n",
    "    \"\"\"\n",
    "    df2 = df.copy()\n",
    "    df2 = df2.sort_index()\n",
    "    for c in df2.columns:\n",
    "        col = df2[c]\n",
    "\n",
    "        # Flatten nested arrays if needed\n",
    "        if any(isinstance(x, np.ndarray) for x in col):\n",
    "            df2[c] = col.apply(lambda x: x.flatten()[0] if isinstance(x, np.ndarray) else x)\n",
    "\n",
    "        arr = df2[c].to_numpy()\n",
    "        if hasattr(arr, \"ndim\") and arr.ndim == 2:\n",
    "            df2[c] = arr[:, 0]\n",
    "\n",
    "        # Convert to numeric where possible\n",
    "        try:\n",
    "            df2[c] = pd.to_numeric(df2[c], errors=\"coerce\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    return df2\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Currency normalization\n",
    "# ============================================================\n",
    "\n",
    "CURRENCY_MAP = {\n",
    "    \"AUD\":\"AUSTRALIAN\",\"AUSTRALIAN\":\"AUSTRALIAN\",\n",
    "    \"EUR\":\"EURO\",\"EURO\":\"EURO\",\n",
    "    \"GBP\":\"UK\",\"UK\":\"UK\",\n",
    "    \"NZD\":\"NEW\",\"NEW\":\"NEW\",\n",
    "\n",
    "    \"BRL\":\"BRAZILIAN\",\"BRAZILIAN\":\"BRAZILIAN\",\n",
    "    \"CAD\":\"CANADIAN\",\"CANADIAN\":\"CANADIAN\",\n",
    "    \"HRK\":\"CROATIAN\",\"CROATIAN\":\"CROATIAN\",\n",
    "    \"CZK\":\"CZECH\",\"CZECH\":\"CZECH\",\n",
    "    \"HUF\":\"HUNGARIAN\",\"HUNGARIAN\":\"HUNGARIAN\",\n",
    "    \"INR\":\"INDIAN\",\"INDIAN\":\"INDIAN\",\n",
    "    \"IDR\":\"INDONESIAN\",\"INDONESIAN\":\"INDONESIAN\",\n",
    "    \"ILS\":\"ISRAELI\",\"ISRAELI\":\"ISRAELI\",\n",
    "    \"JPY\":\"JAPANESE\",\"JAPANESE\":\"JAPANESE\",\n",
    "    \"MXN\":\"MEXICAN\",\"MEXICAN\":\"MEXICAN\",\n",
    "    \"NOK\":\"NORWEGIAN\",\"NORWEGIAN\":\"NORWEGIAN\",\n",
    "    \"PHP\":\"PHILIPPINE\",\"PHILIPPINE\":\"PHILIPPINE\",\n",
    "    \"PLN\":\"POLISH\",\"POLISH\":\"POLISH\",\n",
    "    \"RUB\":\"RUSSIAN\",\"RUSSIAN\":\"RUSSIAN\",\n",
    "    \"SGD\":\"SINGAPORE\",\"SINGAPORE\":\"SINGAPORE\",\n",
    "    \"ZAR\":\"SOUTH\",\"SOUTH\":\"SOUTH\",\n",
    "    \"SEK\":\"SWEDISH\",\"SWEDISH\":\"SWEDISH\",\n",
    "    \"CHF\":\"SWISS\",\"SWISS\":\"SWISS\",\n",
    "    \"THB\":\"THAI\",\"THAI\":\"THAI\",\n",
    "\n",
    "    \"BULG\":\"BULGARIAN\",\"BULGARIAN\":\"BULGARIAN\",\n",
    "    \"CHILEAN\":\"CHILEAN\"\n",
    "}\n",
    "\n",
    "def clean_cur(raw):\n",
    "    \"\"\"\n",
    "    Normalizes currency labels and symbols into canonical identifiers.\n",
    "    \"\"\"\n",
    "    raw = re.sub(r\"[^A-Z]\", \"\", raw.upper())\n",
    "    return CURRENCY_MAP.get(raw, raw)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Metadata extractors\n",
    "# ============================================================\n",
    "\n",
    "def extract_source(title):\n",
    "    \"\"\"\n",
    "    Extracts the vendor/source tag from a column label.\n",
    "    Example: \"(WMR)\" → \"WMR\".\n",
    "    \"\"\"\n",
    "    parts = re.findall(r\"\\((.*?)\\)\", str(title).upper())\n",
    "    return parts[-1].strip() if parts else \"UNK\"\n",
    "\n",
    "\n",
    "def classify_type(title):\n",
    "    \"\"\"\n",
    "    Identifies whether a quote is BID, OFFER, or ER (mid).\n",
    "    Robust against vendor naming inconsistencies.\n",
    "    \"\"\"\n",
    "    t = title.upper()\n",
    "    if \"EXCH\" in t or \"EXCHANGE RATE\" in t:\n",
    "        return \"ER\"\n",
    "    if \"BID\" in t:\n",
    "        return \"BID\"\n",
    "    if \"OFFER\" in t or \"OFFERED\" in t:\n",
    "        return \"OFFER\"\n",
    "    return \"ER\"\n",
    "\n",
    "\n",
    "def unique_name(base, container):\n",
    "    \"\"\"\n",
    "    Ensures unique column names after merging multiple sources.\n",
    "    \"\"\"\n",
    "    if base not in container:\n",
    "        return base\n",
    "    i = 2\n",
    "    while f\"{base}_{i}\" in container:\n",
    "        i += 1\n",
    "    return f\"{base}_{i}\"\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Forward curve construction with pivot logic (UK / EURO)\n",
    "# ============================================================\n",
    "\n",
    "def build_forward_clean(df):\n",
    "    \"\"\"\n",
    "    Cleans raw forward FX data and produces standardized USD-denominated\n",
    "    forward curves for all currencies. Handles direct USD pairs, synthetic\n",
    "    X/USD via a pivot (EUR or GBP), and reconstructs bid/offer/mid spreads.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "    df.index = pd.to_datetime(df.index).normalize()\n",
    "\n",
    "    # -------------------------------\n",
    "    # 1. Parse raw columns\n",
    "    # -------------------------------\n",
    "\n",
    "    records = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        t = col.upper()\n",
    "        if \"TO\" not in t:\n",
    "            continue\n",
    "\n",
    "        left, right = t.split(\"TO\", 1)\n",
    "        cur1 = clean_cur(left.split()[0])\n",
    "        cur2 = clean_cur(right.split()[0])\n",
    "\n",
    "        src = extract_source(col)\n",
    "        typ = classify_type(col)\n",
    "\n",
    "        if \"1M\" in t:\n",
    "            tenor = \"1M\"\n",
    "        elif \"1W\" in t or \"SW\" in t:\n",
    "            tenor = \"1W\"\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        arr = df[col].to_numpy()\n",
    "        if arr.ndim > 1:\n",
    "            arr = arr[:, 0]\n",
    "\n",
    "        records.append({\n",
    "            \"cur1\": cur1,\n",
    "            \"cur2\": cur2,\n",
    "            \"tenor\": tenor,\n",
    "            \"typ\": typ,\n",
    "            \"src\": src,\n",
    "            \"values\": arr\n",
    "        })\n",
    "\n",
    "    # -------------------------------\n",
    "    # 2. Separate USD and cross pairs\n",
    "    # -------------------------------\n",
    "\n",
    "    direct = {\"1M\": [], \"1W\": []}\n",
    "    cross  = {\"1M\": [], \"1W\": []}\n",
    "\n",
    "    for r in records:\n",
    "        if \"USD\" in (r[\"cur1\"], r[\"cur2\"]) or \"US\" in (r[\"cur1\"], r[\"cur2\"]):\n",
    "            direct[r[\"tenor\"]].append(r)\n",
    "        else:\n",
    "            cross[r[\"tenor\"]].append(r)\n",
    "\n",
    "    out_1M, out_1W = {}, {}\n",
    "\n",
    "    def add(container, cur, typ, src, v):\n",
    "        base = f\"{cur}_{typ}_{src}\"\n",
    "        container[unique_name(base, container)] = v\n",
    "\n",
    "    # -------------------------------\n",
    "    # 3. Normalize direct USD pairs\n",
    "    # -------------------------------\n",
    "\n",
    "    for tenor, container in [(\"1M\", out_1M), (\"1W\", out_1W)]:\n",
    "        for r in direct[tenor]:\n",
    "            c1, c2 = r[\"cur1\"], r[\"cur2\"]\n",
    "            typ, src, v = r[\"typ\"], r[\"src\"], r[\"values\"]\n",
    "\n",
    "            # Case USD → X\n",
    "            if c1 in (\"USD\",\"US\") and c2 not in (\"USD\",\"US\"):\n",
    "                add(container, c2, typ, src, v)\n",
    "\n",
    "            # Case X → USD (invert)\n",
    "            elif c2 in (\"USD\",\"US\") and c1 not in (\"USD\",\"US\"):\n",
    "                if typ == \"BID\":\n",
    "                    # bid(X→USD) becomes OFFER(USD→X)\n",
    "                             # inversion of numeric quote\n",
    "                    typ = \"OFFER\"         # flip side  \n",
    "                elif typ == \"OFFER\":\n",
    "                    # offer(X→USD) becomes BID(USD→X)\n",
    "                    typ = \"BID\"\n",
    "                inv = 1.0 / v\n",
    "                add(container, c1, typ, src, inv)\n",
    "\n",
    "\n",
    "    # -------------------------------\n",
    "    # 4. Extract pivot→USD (mid, bid, offer)\n",
    "    # -------------------------------\n",
    "\n",
    "    pivots = {\"UK\", \"EURO\"}\n",
    "    pivot_USD = {\"1M\": {}, \"1W\": {}}\n",
    "\n",
    "    for tenor in [\"1M\", \"1W\"]:\n",
    "        tmp = {}\n",
    "\n",
    "        for r in direct[tenor]:\n",
    "            c1, c2, typ, src, v = r[\"cur1\"], r[\"cur2\"], r[\"typ\"], r[\"src\"], r[\"values\"]\n",
    "\n",
    "            pivot = None\n",
    "            val = None\n",
    "\n",
    "            # USD → P\n",
    "            if c1 in (\"USD\",\"US\") and c2 in pivots:\n",
    "                pivot, val = c2, v\n",
    "\n",
    "            # P → USD\n",
    "            # Case X → USD (needs full bid/offer inversion)\n",
    "            elif c2 in (\"USD\",\"US\") and c1 not in (\"USD\",\"US\"):\n",
    "                if typ == \"BID\":\n",
    "                    # bid(X→USD) becomes OFFER(USD→X)\n",
    "                             # inversion of numeric quote\n",
    "                    typ = \"OFFER\"         # flip side  \n",
    "                elif typ == \"OFFER\":\n",
    "                    # offer(X→USD) becomes BID(USD→X)\n",
    "                    typ = \"BID\"\n",
    "                inv = 1.0 / v\n",
    "                add(container, c1, typ, src, inv)\n",
    "\n",
    "\n",
    "            if pivot is None:\n",
    "                continue\n",
    "\n",
    "            key = (pivot, src)\n",
    "            tmp.setdefault(key, {\"BID\":None, \"OFFER\":None, \"ER\":None})\n",
    "            tmp[key][typ] = val\n",
    "\n",
    "        # Build mid if necessary\n",
    "        for key, d in tmp.items():\n",
    "            if d[\"ER\"] is None:\n",
    "                if d[\"BID\"] is not None and d[\"OFFER\"] is not None:\n",
    "                    d[\"ER\"] = (d[\"BID\"] + d[\"OFFER\"]) / 2\n",
    "                else:\n",
    "                    continue\n",
    "            pivot_USD[tenor][key] = d\n",
    "\n",
    "    # -------------------------------\n",
    "    # 5. Synthetic X/USD via pivot\n",
    "    # -------------------------------\n",
    "\n",
    "    priority = {\"WMR\":1, \"WM\":1, \"LSEG DS\":2, \"TR\":3, \"REFINITIV\":4, \"UNK\":9}\n",
    "\n",
    "    def best_source(keys):\n",
    "        return sorted(keys, key=lambda k: priority.get(k[1], 5))[0]\n",
    "    \n",
    "    for tenor, container in [(\"1M\", out_1M), (\"1W\", out_1W)]:\n",
    "    \n",
    "        for r in cross[tenor]:\n",
    "            X, P, typ, src, vXP = r[\"cur1\"], r[\"cur2\"], r[\"typ\"], r[\"src\"], r[\"values\"]\n",
    "    \n",
    "            # On ne construit le cross que sur la ligne mid\n",
    "            if typ != \"ER\" or P not in pivots:\n",
    "                continue\n",
    "    \n",
    "            # On récupère le meilleur pivot→USD (P par USD)\n",
    "            candidates = {k: d for k, d in pivot_USD[tenor].items() if k[0] == P}\n",
    "            if not candidates:\n",
    "                continue\n",
    "    \n",
    "            k_best = best_source(list(candidates.keys()))\n",
    "            P_info = candidates[k_best]\n",
    "    \n",
    "            mid_PUSD   = P_info[\"ER\"]      # P par USD\n",
    "            bid_PUSD   = P_info[\"BID\"]     # P par USD\n",
    "            offer_PUSD = P_info[\"OFFER\"]   # P par USD\n",
    "    \n",
    "            # mid XUSD = (P/USD) / (P/X)\n",
    "            mid_XUSD = mid_PUSD / vXP\n",
    "            add(container, X, \"ER\", src, mid_XUSD)\n",
    "    \n",
    "            # on récupère aussi bid/offer de X→P dans la même source\n",
    "            sib_bid, sib_offer = None, None\n",
    "            for s in cross[tenor]:\n",
    "                if s[\"cur1\"] == X and s[\"cur2\"] == P and s[\"src\"] == src:\n",
    "                    if s[\"typ\"] == \"BID\":\n",
    "                        sib_bid = s[\"values\"]      # P par X\n",
    "                    elif s[\"typ\"] == \"OFFER\":\n",
    "                        sib_offer = s[\"values\"]   # P par X\n",
    "    \n",
    "            if (\n",
    "                sib_bid   is not None and\n",
    "                sib_offer is not None and\n",
    "                bid_PUSD   is not None and\n",
    "                offer_PUSD is not None\n",
    "            ):\n",
    "                # BID_XUSD   = bid_PUSD   / offer_XP\n",
    "                # OFFER_XUSD = offer_PUSD / bid_XP\n",
    "                bid_XUSD   = bid_PUSD   / sib_offer\n",
    "                offer_XUSD = offer_PUSD / sib_bid\n",
    "    \n",
    "                add(container, X, \"BID\",   src, bid_XUSD)\n",
    "                add(container, X, \"OFFER\", src, offer_XUSD)\n",
    "    \n",
    "\n",
    "    # -------------------------------\n",
    "    # 6. Final dataframes\n",
    "    # -------------------------------\n",
    "\n",
    "    fwd_1M = pd.DataFrame(out_1M, index=df.index).sort_index(axis=1)\n",
    "    fwd_1W = pd.DataFrame(out_1W, index=df.index).sort_index(axis=1)\n",
    "\n",
    "    return fwd_1M, fwd_1W\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Duplicate fusion and reconstruction\n",
    "# ============================================================\n",
    "\n",
    "SOURCE_PRIORITY = [\"LSEG DS\", \"LSEG\", \"BBI\", \"TR\", \"WMR\", \"UNK\"]\n",
    "\n",
    "def source_rank(src):\n",
    "    src = src.upper()\n",
    "    for i, tag in enumerate(SOURCE_PRIORITY):\n",
    "        if tag in src:\n",
    "            return i\n",
    "    return len(SOURCE_PRIORITY)\n",
    "\n",
    "\n",
    "def complete_quotes(b, o, m):\n",
    "    \"\"\"\n",
    "    Reconstructs a consistent bid/offer/mid triplet.\n",
    "    Ensures:\n",
    "        bid <= mid <= offer\n",
    "        Deltas are minimized while preserving available values.\n",
    "    \"\"\"\n",
    "    b = b.copy() if b is not None else None\n",
    "    o = o.copy() if o is not None else None\n",
    "    m = m.copy() if m is not None else None\n",
    "\n",
    "    # Mid reconstruction\n",
    "    if m is None:\n",
    "        m = (b + o) / 2 if (b is not None and o is not None) else None\n",
    "\n",
    "    # Bid reconstruction\n",
    "    if b is None and o is not None and m is not None:\n",
    "        b = 2*m - o\n",
    "\n",
    "    # Offer reconstruction\n",
    "    if o is None and b is not None and m is not None:\n",
    "        o = 2*m - b\n",
    "\n",
    "    # Arbitrage fix\n",
    "    if b is not None and o is not None:\n",
    "        mask = b > o\n",
    "        if mask.any():\n",
    "            mid_fix = (b + o) / 2\n",
    "            b[mask] = mid_fix[mask]\n",
    "            o[mask] = mid_fix[mask]\n",
    "\n",
    "    if m is not None and b is not None:\n",
    "        m = m.clip(lower=b)\n",
    "    if m is not None and o is not None:\n",
    "        m = m.clip(upper=o)\n",
    "\n",
    "    return b, o, m\n",
    "\n",
    "\n",
    "def fuse_duplicates(df):\n",
    "    \"\"\"\n",
    "    Merges multiple vendor sources for the same currency forward.\n",
    "    Selects best source by ranking, fills gaps, and reconstructs\n",
    "    arbitrage-consistent bid/offer/mid triplets.\n",
    "    \"\"\"\n",
    "    final = {}\n",
    "    groups = {}\n",
    "\n",
    "    # Group by currency / type\n",
    "    for col in df.columns:\n",
    "        if \"_\" not in col:\n",
    "            continue\n",
    "        parts = col.split(\"_\")\n",
    "        if len(parts) < 3:\n",
    "            continue\n",
    "        cur, typ = parts[0], parts[1]\n",
    "        src = \"_\".join(parts[2:])\n",
    "        groups.setdefault(cur, {}).setdefault(typ, []).append((col, src))\n",
    "\n",
    "    for cur, type_dict in groups.items():\n",
    "\n",
    "        def merged(type_name):\n",
    "            if type_name not in type_dict:\n",
    "                return None\n",
    "            cols = sorted(type_dict[type_name], key=lambda x: source_rank(x[1]))\n",
    "            out = df[cols[0][0]].copy()\n",
    "            for col_name, _ in cols[1:]:\n",
    "                out = out.fillna(df[col_name])\n",
    "            return out\n",
    "\n",
    "        b = merged(\"BID\")\n",
    "        o = merged(\"OFFER\")\n",
    "        m = merged(\"ER\")\n",
    "\n",
    "        b2, o2, m2 = complete_quotes(b, o, m)\n",
    "\n",
    "        final[f\"{cur}_BID\"]   = b2\n",
    "        final[f\"{cur}_OFFER\"] = o2\n",
    "        final[f\"{cur}_ER\"]    = m2\n",
    "\n",
    "    return pd.DataFrame(final, index=df.index).sort_index(axis=1)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Pipeline\n",
    "# ============================================================\n",
    "\n",
    "df_forward = force_1d(df_forward)\n",
    "forward_1M, forward_1W = build_forward_clean(df_forward)\n",
    "\n",
    "forward_1M = fuse_duplicates(forward_1M)\n",
    "forward_1W = fuse_duplicates(forward_1W)\n",
    "print(forward_1W.columns == forward_1M.columns)\n",
    "forward_1W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e10699-3d57-4174-b512-03d43af8b1dd",
   "metadata": {},
   "source": [
    "### Coherence of the forward obtained \n",
    "The first thing to do here is to verify the coherence of our computing, to do this we have several ressources, chatgpt and other AI tool may help us quickly review our code but to check the coherence of our data we can look at some spots on Yfinance or do it empirically as we've done below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8591786c-25fd-4fab-8f83-063728643f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnary containing the index of the comparison dataframe and the yfinance ticker to extract market data\n",
    "fx_map = {\n",
    "    \"UK\": \"GBPUSD=X\",\n",
    "    \"EURO\": \"EURUSD=X\",\n",
    "    \"PHILIPPINE\": \"PHPUSD=X\",\n",
    "    \"CANADIAN\": \"CADUSD=X\",\n",
    "    \"NORWEGIAN\": \"NOKUSD=X\",\n",
    "    \"NEW\": \"NZDUSD=X\",\n",
    "    \"CZECH\": \"CZKUSD=X\",\n",
    "    \"HUNGARIAN\": \"HUFUSD=X\",\n",
    "    \"POLISH\": \"PLNUSD=X\",\n",
    "    \"SINGAPORE\": \"SGDUSD=X\",\n",
    "    \"RUSSIAN\": \"RUBUSD=X\",\n",
    "    \"INDIAN\": \"INRUSD=X\",\n",
    "    \"SOUTH\": \"ZARUSD=X\",\n",
    "    \"INDONESIAN\": \"IDRUSD=X\",\n",
    "    \"BULGARIAN\": \"BGNUSD=X\",\n",
    "    \"ISRAELI\": \"ILSUSD=X\",\n",
    "    \"JAPANESE\": \"JPYUSD=X\",\n",
    "    \"BRAZILIAN\": \"BRLUSD=X\",\n",
    "    \"SWEDISH\": \"SEKUSD=X\",\n",
    "    \"THAI\": \"THBUSD=X\",\n",
    "    \"AUSTRALIAN\": \"AUDUSD=X\",\n",
    "    \"SWISS\": \"CHFUSD=X\",\n",
    "    \"MEXICAN\": \"MXNUSD=X\",\n",
    "    \"CHILEAN\": \"CLPUSD=X\",\n",
    "}\n",
    "\n",
    "target_date = \"2024-10-01\"\n",
    "results = {}\n",
    "\n",
    "for name, ticker in fx_map.items():\n",
    "    try:\n",
    "        data = yf.download(\n",
    "            ticker,\n",
    "            start=\"2024-10-01\",\n",
    "            end=\"2024-10-02\",\n",
    "            progress=False,\n",
    "            auto_adjust=False\n",
    "        )\n",
    "        \n",
    "        # If no data → record NaN\n",
    "        if data.empty:\n",
    "            results[name+\"_ER\"] = float(\"nan\")\n",
    "            continue\n",
    "        \n",
    "        # Look for the exact date\n",
    "        date_match = data.loc[data.index.strftime(\"%Y-%m-%d\") == target_date]\n",
    "        \n",
    "        if len(date_match) == 0:\n",
    "            results[name+\"_ER\"] = float(\"nan\")\n",
    "        else:\n",
    "            results[name+\"_ER\"] = date_match[\"Close\"].iloc[0]\n",
    "    \n",
    "    except Exception:\n",
    "        results[name] = float(\"nan\")\n",
    "\n",
    "clean_results = {k: float(v.iloc[0])for k, v in results.items()}\n",
    "df_check = pd.DataFrame.from_dict(clean_results,orient=\"index\", columns=[\"USD per X\"]) # dataframe \n",
    "\n",
    "\n",
    "# DATA comparison \n",
    "row_model = forward_1M.loc[target_date]\n",
    "row_model.name = \"USD_per_X_professor_data\"\n",
    "df_model = row_model.to_frame(name=\"USD_per_X_model\")\n",
    "comparison = df_model.join(df_check, how=\"inner\")\n",
    "comparison[\"abs_diff\"] = comparison[\"USD_per_X_model\"] - comparison[\"USD per X\"]\n",
    "comparison[\"rel_diff(%)\"] = comparison[\"abs_diff\"] / comparison[\"USD per X\"] * 100\n",
    "print(\"1M:\")\n",
    "print(comparison.sort_values(\"rel_diff(%)\"))\n",
    "print(\"\\n\")\n",
    "\n",
    "# DATA comparison \n",
    "row_model = forward_1W.loc[target_date]\n",
    "row_model.name = \"USD_per_X_professor_data\"\n",
    "df_model = row_model.to_frame(name=\"USD_per_X_model\")\n",
    "comparison = df_model.join(df_check, how=\"inner\")\n",
    "comparison[\"abs_diff\"] = comparison[\"USD_per_X_model\"] - comparison[\"USD per X\"]\n",
    "comparison[\"rel_diff(%)\"] = comparison[\"abs_diff\"] / comparison[\"USD per X\"] * 100\n",
    "print(\"1W:\")\n",
    "print(comparison.sort_values(\"rel_diff(%)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dc04ea-bc00-49a0-bb35-2bc833b2baff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we plot the missing values to check the coherence of the results -> It seems coherent \n",
    "forward_1M[[\"CHILEAN_ER\", \"BULGARIAN_ER\", \"SINGAPORE_ER\", \"CANADIAN_ER\"]].plot()\n",
    "plt.show()\n",
    "forward_1W[[\"CHILEAN_ER\", \"BULGARIAN_ER\"]].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f05149-88ba-4615-ac2f-683e0efed73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_columns(df):\n",
    "    names = sorted({col.split(\"_\")[0] for col in df.columns})\n",
    "    for name in names:\n",
    "        bid = df[name + \"_BID\"]\n",
    "        er = df[name + \"_ER\"]\n",
    "        offer = df[name + \"_OFFER\"]\n",
    "        \n",
    "        same_bid_er = bid.isna().equals(er.isna())\n",
    "        same_bid_offer = bid.isna().equals(offer.isna())\n",
    "        same_offer_er = offer.isna().equals(er.isna())\n",
    "        num_not_nan = bid.notna().sum()\n",
    "        if same_bid_er and same_bid_offer and same_offer_er: \n",
    "            continue \n",
    "        else: \n",
    "            print(f\"=== {name} ===\")\n",
    "            print(\"BID vs ER NaN pattern identical :\", same_bid_er)\n",
    "            print(\"BID vs OFFER NaN pattern identical :\", same_bid_offer)\n",
    "            print(\"ER vs OFFER NaN pattern identical :\", same_offer_er)\n",
    "            return None \n",
    "        if  num_not_nan == 0: \n",
    "            print(f\"=== {name} ===\")\n",
    "            print(\"0 not Nan values there is maybe an issue\") \n",
    "            break \n",
    "            return None \n",
    "    print(\"dataframe OK\") \n",
    "            \n",
    "test_columns(xusd_df)        \n",
    "test_columns(forward_1W)\n",
    "test_columns(forward_1M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd67fc6-e970-4d9c-9af4-03817f86a9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_quotes(df):\n",
    "    \"\"\"\n",
    "    verify bid <= er <= offer\n",
    "    \"\"\"\n",
    "    cols = df.columns\n",
    "    currencies = sorted({c.split(\"_\")[0] for c in cols if \"_BID\" in c})\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for cur in currencies:\n",
    "        bid_col = f\"{cur}_BID\"\n",
    "        er_col  = f\"{cur}_ER\"\n",
    "        off_col = f\"{cur}_OFFER\"\n",
    "\n",
    "        if not ({bid_col, er_col, off_col} <= set(cols)):\n",
    "            continue\n",
    "\n",
    "        bid = df[bid_col]\n",
    "        er  = df[er_col]\n",
    "        off = df[off_col]\n",
    "\n",
    "        # filtre les lignes sans NaN\n",
    "        valid_mask = (~bid.isna()) & (~er.isna()) & (~off.isna())\n",
    "\n",
    "        if valid_mask.sum() == 0:  \n",
    "            results[cur] = {\n",
    "                \"valid\": True,\n",
    "                \"violations\": 0,\n",
    "                \"rows\": []\n",
    "            }\n",
    "            continue\n",
    "\n",
    "        bid_clean = bid[valid_mask]\n",
    "        er_clean  = er[valid_mask]\n",
    "        off_clean = off[valid_mask]\n",
    "\n",
    "        cond1 = bid_clean <= er_clean\n",
    "        cond2 = er_clean <= off_clean\n",
    "\n",
    "        ok = cond1 & cond2\n",
    "        bad_rows = bid_clean.index[~ok]\n",
    "\n",
    "        results[cur] = {\n",
    "            \"valid\": len(bad_rows) == 0,\n",
    "            \"violations\": len(bad_rows),\n",
    "            \"rows\": list(bad_rows)\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "res = check_quotes(xusd_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b330893d-0316-4469-b6d4-6decb6841346",
   "metadata": {},
   "source": [
    "# **Economic Rationale Behind the Fixed Portfolio Construction**\n",
    "\n",
    "To obtain meaningful and interpretable results, currencies were not assigned randomly to portfolios. Instead, we grouped them according to **economic similarity, geographical proximity, market development, and common macro-financial drivers**. This approach is widely used in the empirical FX literature, as currencies tend to exhibit strong co-movements when they share similar economic fundamentals, exposure to global risk factors, or monetary and trade linkages.\n",
    "\n",
    "The five portfolios therefore reflect **coherent currency blocs**:\n",
    "\n",
    "1. **Developed Europe (EUR, GBP, CHF, SEK, NOK)**\n",
    "   These currencies belong to highly integrated and liquid markets with similar monetary regimes and strong cross-correlations. They typically behave as low-volatility safe-haven or funding currencies, making them a natural benchmark group in FX momentum tests.\n",
    "\n",
    "2. **Commodity-Linked Majors (AUD, NZD, CAD, ZAR, CLP)**\n",
    "   These currencies are strongly exposed to global commodity cycles and international trade dynamics. Their returns tend to co-move with risk sentiment and global demand, which makes momentum effects more pronounced or more volatile within this group.\n",
    "\n",
    "3. **Emerging Europe (CZK, PLN, HUF, HRK, BGN)**\n",
    "   Central and Eastern European currencies share similar macroeconomic structures, EU economic linkages, and exposure to regional capital flows. Treating them as a unified block allows us to analyse momentum in a medium-volatility, partially integrated market segment.\n",
    "\n",
    "4. **Emerging Asia (INR, IDR, PHP, THB, SGD)**\n",
    "   Asian currencies are influenced by regional trade patterns, high growth rates, and varying degrees of managed exchange rate regimes. Grouping them together highlights how momentum behaves in markets where monetary authorities often intervene.\n",
    "\n",
    "5. **Americas & High-Risk EM (BRL, MXN, RUB, ILS, JPY)**\n",
    "   This portfolio includes currencies with higher idiosyncratic volatility, geopolitical risk, or structural risk premia. They often display strong directional moves and are useful for isolating momentum performance in high-risk environments.\n",
    "\n",
    "This fixed allocation provides **three key benefits**:\n",
    "\n",
    "* It generates **economically interpretable differences** across portfolios, allowing us to analyse whether momentum behaves differently in developed vs. emerging markets, commodity-linked vs. safe-haven currencies, or high-risk vs. low-risk regimes.\n",
    "* It ensures **stable composition over time**, avoiding confusion between the effects of portfolio rebalancing and actual strategy performance.\n",
    "* It aligns with **empirical FX research**, where currencies are often grouped by region or market characteristics to isolate structural return patterns.\n",
    "\n",
    "Overall, structuring the portfolios economically rather than randomly creates a more robust and meaningful framework for analysing momentum strategies in the FX market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4842628d-3700-4fe3-9b84-3b59679e975a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_economic_portfolios(df):\n",
    "    \"\"\"\n",
    "    Build fixed economic FX portfolios.\n",
    "    Input:\n",
    "        df = any FX dataframe where columns follow the pattern CURRENCY or CURRENCY_xxx\n",
    "             (ex: EURO, EURO_ER, EURO_BID ...)\n",
    "    Output:\n",
    "        A dictionary { \"P1\": df_subset, ..., \"P5\": df_subset }\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the 5 economic portfolios\n",
    "    portfolios = {\n",
    "        \"P1\": [\"UK\", \"EURO\", \"SWISS\", \"SWEDISH\", \"NORWEGIAN\"],             # Developed Europe\n",
    "        \"P2\": [\"AUSTRALIAN\", \"NEW\", \"CANADIAN\", \"SOUTH\", \"CHILEAN\"],      # Commodity-linked majors\n",
    "        \"P3\": [\"CZECH\", \"POLISH\", \"HUNGARIAN\", \"CROATIAN\", \"BULGARIAN\"],  # Emerging Europe\n",
    "        \"P4\": [\"INDIAN\", \"INDONESIAN\", \"PHILIPPINE\", \"THAI\", \"SINGAPORE\"],# Emerging Asia\n",
    "        \"P5\": [\"BRAZILIAN\", \"MEXICAN\", \"RUSSIAN\", \"ISRAELI\", \"JAPANESE\"]  # Americas + High-risk EM\n",
    "    }\n",
    "\n",
    "    out = {}\n",
    "    for pname, currency_list in portfolios.items():\n",
    "        name = pname +' : '\n",
    "        # Select all columns in df that start with the currency name\n",
    "        cols = []\n",
    "        \n",
    "        for cur in currency_list:\n",
    "            matching = [c for c in df.columns if c.startswith(cur)]\n",
    "            cols.extend(matching)\n",
    "        \n",
    "        name += \"|\".join(currency_list)\n",
    "        # Build the portfolio dataframe (only relevant columns)\n",
    "        out[pname] = df[cols].copy()\n",
    "\n",
    "    return out\n",
    "\n",
    "portfolios = get_economic_portfolios(xusd_df)\n",
    "portfolios_forward_1W = get_economic_portfolios(forward_1W)\n",
    "portfolios_forward_1M = get_economic_portfolios(forward_1M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d81400-ac47-46c4-a838-95ac519dc129",
   "metadata": {},
   "source": [
    "# **Trading strategies** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e783f96f-3ea4-457f-9eb9-ae8ae54db207",
   "metadata": {},
   "source": [
    "## Momentum strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde70aad-1e7e-4642-a01f-287e14310507",
   "metadata": {},
   "source": [
    "The momentum strategy implemented here is a direct translation of the assignment instructions into a systematic trading framework. It adheres to the classical structure of cross-sectional momentum in currency markets: a short lookback window used to generate directional signals, combined with a fixed monthly holding period to capture persistent trends. Its design is intentionally simple, yet it preserves market realism through the use of bid–ask spreads in execution and the separation of bid, mid, and offer data.\n",
    "\n",
    "The signal relies on four-day cumulative log returns computed from mid-market spot prices, which provides a very short-term measure of relative performance across currencies. At each monthly rebalancing date, currencies are sorted by recent momentum, and the top and bottom quantiles form the long and short portfolios, respectively. The position is then held for twenty-two trading days. This structure enforces disciplined, calendar-based rebalancing and reflects the literature on short-horizon momentum in FX markets.\n",
    "\n",
    "A key strength of the implementation is the explicit modelling of transaction costs through bid–ask spreads: long positions enter and exit via offer-to-bid pricing, whereas shorts transact via bid-to-offer. This prevents the strategy from overstating profitability and brings the backtest closer to executable returns. The code also ensures that signals are lagged by one day to avoid look-ahead bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf33f353-95af-4e7c-b3c1-14c85573e234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 1. Split BID / ER / OFFER\n",
    "# =====================================================\n",
    "\n",
    "def split_bid_offer(df):\n",
    "    bid_cols   = [c for c in df.columns if c.endswith(\"_BID\")]\n",
    "    er_cols    = [c for c in df.columns if c.endswith(\"_ER\")]\n",
    "    offer_cols = [c for c in df.columns if c.endswith(\"_OFFER\")]\n",
    "\n",
    "    BID   = df[bid_cols].copy()\n",
    "    ER    = df[er_cols].copy()\n",
    "    OFFER = df[offer_cols].copy()\n",
    "\n",
    "    BID.columns   = [c.replace(\"_BID\", \"\") for c in bid_cols]\n",
    "    ER.columns    = [c.replace(\"_ER\", \"\") for c in er_cols]\n",
    "    OFFER.columns = [c.replace(\"_OFFER\", \"\") for c in offer_cols]\n",
    "\n",
    "    return BID, ER, OFFER\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 2. Momentum signal + signals (common for both versions)\n",
    "#    4-day lookback, 1-month holding (approx 22 jours)\n",
    "# =====================================================\n",
    "\n",
    "def compute_signals(ER, lookback=4, hold_period=22, pct=0.3):\n",
    "\n",
    "    log_ret_spot = np.log(ER).diff()\n",
    "    mom_signal = log_ret_spot.rolling(lookback).sum()\n",
    "\n",
    "    dates = ER.index\n",
    "    assets = ER.columns\n",
    "    signals = pd.DataFrame(0, index=dates, columns=assets)\n",
    "\n",
    "    # rebal tous les hold_period jours, après lookback\n",
    "    rebalance_dates = dates[lookback::hold_period]\n",
    "\n",
    "    for t in rebalance_dates:\n",
    "        today = mom_signal.loc[t].dropna()\n",
    "        if len(today) == 0:\n",
    "            continue\n",
    "\n",
    "        n = len(today)\n",
    "        k = int(np.floor(n * pct))\n",
    "\n",
    "        winners = today.nlargest(k).index\n",
    "        losers  = today.nsmallest(k).index\n",
    "\n",
    "        signals.loc[t, winners] = 1\n",
    "        signals.loc[t, losers]  = -1\n",
    "\n",
    "    # on tient les positions entre deux rebalancings\n",
    "    signals = signals.replace(0, np.nan).ffill().fillna(0)\n",
    "\n",
    "    return signals, mom_signal, log_ret_spot\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 3. Momentum using only mid (ER)\n",
    "#    Mark-to-market au mid, pas de coûts de transaction\n",
    "# =====================================================\n",
    "\n",
    "def momentum_ER_only(ER, signals):\n",
    "\n",
    "    log_ret = np.log(ER).diff()\n",
    "    # daily portfolio return = moyenne des positions (décalées) * log-returns\n",
    "    r = (signals.shift(1) * log_ret).mean(axis=1)\n",
    "    return r.fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 4. Momentum using BID/OFFER execution rules\n",
    "#    Mark-to-market au mid + coûts seulement aux changements de position\n",
    "# =====================================================\n",
    "\n",
    "def momentum_bidask(BID, OFFER, signals):\n",
    "\n",
    "    # mid-prices and daily mid log-returns\n",
    "    MID = (BID + OFFER) / 2\n",
    "    log_mid = np.log(MID)\n",
    "    daily_mid_ret = log_mid.diff()\n",
    "\n",
    "    # base daily PnL: comme la version mid-only, mais avec MID\n",
    "    base_ret = (signals.shift(1) * daily_mid_ret).mean(axis=1)\n",
    "\n",
    "    # positions today vs yesterday\n",
    "    pos_prev = signals.shift(1).fillna(0)\n",
    "    pos_curr = signals\n",
    "\n",
    "    log_bid   = np.log(BID)\n",
    "    log_offer = np.log(OFFER)\n",
    "\n",
    "    # transaction cost per asset / day selon type de trade\n",
    "    # long open  : mid - offer  (on paie le spread en entrant long)\n",
    "    # long close : bid - mid\n",
    "    # short open : bid - mid\n",
    "    # short close: mid - offer\n",
    "\n",
    "    tc_long_open  = log_mid - log_offer\n",
    "    tc_long_close = log_bid - log_mid\n",
    "    tc_short_open = log_bid - log_mid\n",
    "    tc_short_close= log_mid - log_offer\n",
    "\n",
    "    # masks de changement de position\n",
    "    long_open_mask   = (pos_prev == 0) & (pos_curr == 1)\n",
    "    long_close_mask  = (pos_prev == 1) & (pos_curr == 0)\n",
    "    short_open_mask  = (pos_prev == 0) & (pos_curr == -1)\n",
    "    short_close_mask = (pos_prev == -1) & (pos_curr == 0)\n",
    "\n",
    "    # flips: 1 -> -1 (close long + open short) et -1 -> 1 (close short + open long)\n",
    "    flip_long_to_short = (pos_prev == 1) & (pos_curr == -1)\n",
    "    flip_short_to_long = (pos_prev == -1) & (pos_curr == 1)\n",
    "\n",
    "    long_close_mask  = long_close_mask  | flip_long_to_short\n",
    "    short_open_mask  = short_open_mask  | flip_long_to_short\n",
    "    short_close_mask = short_close_mask | flip_short_to_long\n",
    "    long_open_mask   = long_open_mask   | flip_short_to_long\n",
    "\n",
    "    # transaction cost matrix\n",
    "    tc_matrix = (\n",
    "        long_open_mask   * tc_long_open  +\n",
    "        long_close_mask  * tc_long_close +\n",
    "        short_open_mask  * tc_short_open +\n",
    "        short_close_mask * tc_short_close\n",
    "    )\n",
    "\n",
    "    # nombre d'actifs tradés par jour\n",
    "    traded_mask  = long_open_mask | long_close_mask | short_open_mask | short_close_mask\n",
    "    traded_count = traded_mask.sum(axis=1).replace(0, np.nan)\n",
    "\n",
    "    # coût de transaction au niveau portefeuille = moyenne sur les actifs tradés\n",
    "    tc_port = tc_matrix.sum(axis=1) / traded_count\n",
    "    tc_port = tc_port.fillna(0)\n",
    "\n",
    "    # total daily return = mid-based MTM + transaction cost adjustments\n",
    "    r = base_ret + tc_port\n",
    "\n",
    "    return r.fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 5. Evaluation\n",
    "# =====================================================\n",
    "\n",
    "def evaluate_strategy(r,freq = 'D'):\n",
    "\n",
    "    r = r.fillna(0)\n",
    "\n",
    "    perf = (1 + r).cumprod()\n",
    "    if freq == 'D':\n",
    "        div = 252 \n",
    "    elif freq == 'M':\n",
    "        div = 12  \n",
    "    elif freq == 'W':\n",
    "        div = 52\n",
    "    ann_ret = (1 + r.mean())**div - 1\n",
    "    ann_vol = r.std() * np.sqrt(div)\n",
    "    sharpe  = ann_ret / ann_vol if ann_vol != 0 else np.nan\n",
    "\n",
    "    running_max = perf.cummax()\n",
    "    max_dd = ((perf - running_max) / running_max).min()\n",
    "\n",
    "    return pd.Series({\n",
    "        \"Annualized Return\": ann_ret,\n",
    "        \"Annualized Volatility\": ann_vol,\n",
    "        \"Sharpe Ratio\": sharpe,\n",
    "        \"Max Drawdown\": max_dd,\n",
    "        \"Skewness (daily)\": skew(r.dropna()),\n",
    "        \"Kurtosis (daily)\": kurtosis(r.dropna(), fisher=False)\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 6. WRAPPER : run BOTH versions for each portfolio\n",
    "# =====================================================\n",
    "\n",
    "def run_portfolio_strategies(portfolios, lookback=4, hold_period=22, pct=0.3, print_data = True):\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for name, df_port in portfolios.items():\n",
    "\n",
    "        BID, ER, OFFER = split_bid_offer(df_port)\n",
    "\n",
    "        signals, momentum, log_ret_spot = compute_signals(\n",
    "            ER, lookback=lookback, hold_period=hold_period, pct=pct\n",
    "        )\n",
    "\n",
    "        # Strategy A: mid-only\n",
    "        ret_mid   = momentum_ER_only(ER, signals)\n",
    "        stats_mid = evaluate_strategy(ret_mid, freq='D')\n",
    "\n",
    "        # Strategy B: real execution using bid/offer with TC at rebal only\n",
    "        ret_ba   = momentum_bidask(BID, OFFER, signals)\n",
    "        stats_ba = evaluate_strategy(ret_ba, freq='D')\n",
    "        \n",
    "        results[name] = {\n",
    "            \"ER_only\": {\n",
    "                \"returns\": ret_mid,\n",
    "                \"stats\": stats_mid\n",
    "            },\n",
    "            \"BidAsk\": {\n",
    "                \"returns\": ret_ba,\n",
    "                \"stats\": stats_ba\n",
    "            },\n",
    "            \"signals\": signals,\n",
    "            \"momentum\": momentum,\n",
    "            \"log_returns\": log_ret_spot\n",
    "        }\n",
    "        if print_data :\n",
    "            print(\"\\n==============================\")\n",
    "            print(f\"Portfolio: {name}\")\n",
    "            print(\"=== ER-only ===\")\n",
    "            print(stats_mid)\n",
    "            print(\"=== Bid/Ask ===\")\n",
    "            print(stats_ba)\n",
    "\n",
    "    return results\n",
    "\n",
    "results=run_portfolio_strategies(portfolios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5b2874-70e1-41e2-a2e8-23c3c4cb0414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1) Plot ALL transactions of a portfolio\n",
    "# ============================================================\n",
    "\n",
    "def plot_portfolio_transactions(portfolio_data, portfolios, portfolio_name):\n",
    "\n",
    "    df = portfolios[portfolio_name]\n",
    "    BID, ER, OFFER = split_bid_offer(df)\n",
    "\n",
    "    signals = portfolio_data[portfolio_name][\"signals\"]\n",
    "\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.suptitle(f\"Transactions – {portfolio_name}\", fontsize=14)\n",
    "\n",
    "    for i, cur in enumerate(ER.columns):\n",
    "        price = ER[cur]\n",
    "        s = signals[cur]\n",
    "\n",
    "        # raw buy/sell signals\n",
    "        buy_idx  = s[s == 1].index\n",
    "        sell_idx = s[s == -1].index\n",
    "\n",
    "        # CRUCIAL FIX:\n",
    "        # keep only dates actually present in price.index\n",
    "        buy_idx  = buy_idx.intersection(price.index)\n",
    "        sell_idx = sell_idx.intersection(price.index)\n",
    "\n",
    "        plt.subplot(len(ER.columns), 1, i + 1)\n",
    "\n",
    "        plt.plot(price.index, price, color=\"black\", linewidth=1.2)\n",
    "        plt.scatter(buy_idx,  price.loc[buy_idx],  color=\"green\", marker=\"^\", s=40)\n",
    "        plt.scatter(sell_idx, price.loc[sell_idx], color=\"red\", marker=\"v\", s=40)\n",
    "\n",
    "        plt.title(cur, fontsize=10)\n",
    "        plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2) Compare portfolio PnL (ER-only vs Bid/Ask execution)\n",
    "# ============================================================\n",
    "\n",
    "def plot_portfolio_pnl_comparison(portfolio_data, portfolio_name):\n",
    "    \"\"\"\n",
    "    Plots cumulative PnL for ER-only and Bid/Ask executed strategies.\n",
    "    \"\"\"\n",
    "    ret_mid = portfolio_data[portfolio_name][\"ER_only\"][\"returns\"].fillna(0)\n",
    "    ret_ba  = portfolio_data[portfolio_name][\"BidAsk\"][\"returns\"].fillna(0)\n",
    "\n",
    "    pnl_mid = (1 + ret_mid).cumprod()\n",
    "    pnl_ba  = (1 + ret_ba).cumprod()\n",
    "\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.plot(pnl_mid, linewidth=2, label=\"Mid-price strategy (ER-only)\")\n",
    "    plt.plot(pnl_ba, linewidth=2, label=\"Executed strategy (Bid/Ask)\")\n",
    "\n",
    "    plt.title(f\"Cumulative Performance – {portfolio_name}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Cumulative Return\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3) Inspect one specific currency inside a portfolio\n",
    "# ============================================================\n",
    "\n",
    "def plot_currency_details(portfolio_data, portfolios, portfolio_name, currency):\n",
    "    \"\"\"\n",
    "    Plots:\n",
    "      - ER price series\n",
    "      - Buy/Sell signals\n",
    "      - Executed transaction PnL (Bid/Ask)\n",
    "    \"\"\"\n",
    "\n",
    "    df = portfolios[portfolio_name]\n",
    "    BID, ER, OFFER = split_bid_offer(df)\n",
    "\n",
    "    if currency not in ER.columns:\n",
    "        print(f\"{currency} not found in {portfolio_name}.\")\n",
    "        return\n",
    "\n",
    "    price = ER[currency]\n",
    "    sig   = portfolio_data[portfolio_name][\"signals\"][currency]\n",
    "\n",
    "    # executed transaction returns\n",
    "    long_ret  = np.log(BID[currency])   - np.log(OFFER[currency].shift(1))\n",
    "    short_ret = np.log(OFFER[currency]) - np.log(BID[currency].shift(1))\n",
    "    exec_ret  = ((sig.shift(1) == 1) * long_ret +\n",
    "                 (sig.shift(1) == -1) * short_ret).fillna(0)\n",
    "\n",
    "    pnl_exec = (1 + exec_ret).cumprod()\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(16, 8))\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(price, color=\"black\", linewidth=1.5, label=\"ER price\")\n",
    "\n",
    "    buy_idx  = sig[sig == 1].index\n",
    "    sell_idx = sig[sig == -1].index\n",
    "\n",
    "    plt.scatter(buy_idx, price.loc[buy_idx], color=\"green\", marker=\"^\", s=60, label=\"Buy\")\n",
    "    plt.scatter(sell_idx, price.loc[sell_idx], color=\"red\", marker=\"v\", s=60, label=\"Sell\")\n",
    "\n",
    "    plt.title(f\"{portfolio_name} – Price & Signals ({currency})\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"ER\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(pnl_exec, linewidth=2, color=\"blue\")\n",
    "    plt.title(f\"Executed Transaction PnL – {currency}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Cumulative Return\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4) Full portfolio summary (table + plots)\n",
    "# ============================================================\n",
    "\n",
    "def summarize_portfolio(portfolio_data, portfolios, portfolio_name):\n",
    "    \"\"\"\n",
    "    Displays:\n",
    "      - Portfolio composition\n",
    "      - Summary statistics (ER-only vs Bid/Ask)\n",
    "      - PnL comparison\n",
    "      - Detailed transaction plots\n",
    "    \"\"\"\n",
    "    print(f\"\\n====== Portfolio {portfolio_name} – Composition ======\")\n",
    "    print(portfolios[portfolio_name].columns.tolist())\n",
    "\n",
    "    print(f\"\\n====== Performance Statistics – {portfolio_name} ======\")\n",
    "    stats_mid   = portfolio_data[portfolio_name][\"ER_only\"][\"stats\"]\n",
    "    stats_bidask = portfolio_data[portfolio_name][\"BidAsk\"][\"stats\"]\n",
    "\n",
    "    display(pd.DataFrame({\n",
    "        \"ER-only\": stats_mid,\n",
    "        \"Bid/Ask Executed\": stats_bidask\n",
    "    }))\n",
    "\n",
    "    plot_portfolio_pnl_comparison(portfolio_data, portfolio_name)\n",
    "    plot_portfolio_transactions(portfolio_data, portfolios, portfolio_name)\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5) Plot cumulative PnL of ALL portfolios (ER-only & Bid/Ask)\n",
    "# ============================================================\n",
    "\n",
    "def plot_all_portfolios_pnl(portfolio_data, portfolios_keys=None):\n",
    "    \"\"\"\n",
    "    Plots cumulative PnL for all portfolios (both ER-only and Bid/Ask).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    portfolio_data : dict\n",
    "        Output of run_portfolio_strategies()\n",
    "    portfolios_keys : list or None\n",
    "        List of portfolio names to plot (e.g., [\"P1\", \"P2\", ...]).\n",
    "        If None, all available portfolios are plotted.\n",
    "    \"\"\"\n",
    "\n",
    "    if portfolios_keys is None:\n",
    "        portfolios_keys = sorted(list(portfolio_data.keys()))\n",
    "\n",
    "    plt.figure(figsize=(16, 8))\n",
    "\n",
    "    colors = [\"blue\", \"green\", \"red\", \"purple\", \"orange\"]\n",
    "    linestyles = [\"-\", \"--\"]  # ER-only solid, Bid/Ask dashed\n",
    "\n",
    "    for i, p in enumerate(portfolios_keys):\n",
    "        data = portfolio_data[p]\n",
    "\n",
    "        # retrieve returns\n",
    "        ret_mid = data[\"ER_only\"][\"returns\"].fillna(0)\n",
    "        ret_ba  = data[\"BidAsk\"][\"returns\"].fillna(0)\n",
    "\n",
    "        pnl_mid = (1 + ret_mid).cumprod()\n",
    "        pnl_ba  = (1 + ret_ba).cumprod()\n",
    "\n",
    "        plt.plot(\n",
    "            pnl_mid, color=colors[i % len(colors)], linestyle=linestyles[0],\n",
    "            linewidth=1.8, label=f\"{p} – Mid\"\n",
    "        )\n",
    "\n",
    "        plt.plot(\n",
    "            pnl_ba, color=colors[i % len(colors)], linestyle=linestyles[1],\n",
    "            linewidth=1.8, label=f\"{p} – Bid/Ask\"\n",
    "        )\n",
    "\n",
    "    plt.title(\"Portfolio PnL Comparison (ER-only vs Bid/Ask Execution)\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Cumulative Return\")\n",
    "    plt.grid(True)\n",
    "    plt.legend(ncol=2)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9053ec7-43ba-4327-9a5d-23beafaafac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_data=run_portfolio_strategies(portfolios, print_data = False)\n",
    "summarize_portfolio(portfolio_data, portfolios, \"P5\")\n",
    "plot_all_portfolios_pnl(portfolio_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e861a09d-b01a-41c4-b09a-32c6995926ee",
   "metadata": {},
   "source": [
    "### **Performance Commentary**\n",
    "\n",
    "Across all five economic FX portfolios, the strategy delivers **weak to negative performance**, with the **Bid/Ask-executed version consistently underperforming** the mid-only version. This pattern is fully consistent with a very short-term momentum signal applied to FX markets.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Key Observations**\n",
    "\n",
    "#### **1. The 4-day momentum signal is too noisy**\n",
    "\n",
    "Short-horizon FX returns are dominated by noise and mean-reversion.\n",
    "A 4-day signal has little persistence and reverses frequently, producing:\n",
    "\n",
    "* low predictive power\n",
    "* unstable exposures\n",
    "* frequent flips\n",
    "* high effective turnover\n",
    "\n",
    "This explains why mid-only Sharpe ratios are close to zero or negative across portfolios.\n",
    "\n",
    "\n",
    "#### **2. Transaction costs degrade performance sharply**\n",
    "\n",
    "Bid/Ask execution turns marginal mid-only results into **significant losses**.\n",
    "Emerging markets (P3–P5) and thinly traded currencies carry wider spreads, amplifying the drag.\n",
    "\n",
    "In all portfolios, Sharpe ratios drop by **0.2 to 0.4 points** when costs are applied.\n",
    "\n",
    "#### **3. Drawdowns and fat tails**\n",
    "\n",
    "Max drawdowns are large relative to volatility, and kurtosis is exceptionally high in several portfolios, indicating that returns are dominated by rare, large shocks.\n",
    "Short-term momentum performs poorly in such environments.\n",
    "\n",
    "\n",
    "#### **Portfolio-Specific Notes**\n",
    "\n",
    "* **P1 (Developed Europe)**: structurally mean-reverting FX; momentum signal fails.\n",
    "* **P2 (Commodity FX)**: the only mildly positive mid-only performance, reflecting stronger trending behavior. Costs still erase the edge.\n",
    "* **P3–P5 (EM FX)**: noisy price action + higher spreads → consistently negative results.\n",
    "\n",
    "\n",
    "#### **Overall Assessment**\n",
    "\n",
    "The strategy, as currently specified (4-day lookback, 22-day holding), is **not suited** to FX markets.\n",
    "It captures little genuine momentum, and execution costs dominate the PnL.\n",
    "Results match well-known empirical findings: **FX momentum only becomes robust at longer horizons (1–3 months)** and with proper volatility scaling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95309f39-d3f9-4857-a1df-8b611214c12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\"lookback\": 4, \"hold\": 22, \"pct\": 0.2},\n",
    "    {\"lookback\": 10, \"hold\": 22, \"pct\": 0.4},\n",
    "]\n",
    "# allow to test other setup -> we can maybe tune some values using optuna for bayesian optimisation of those parameters\n",
    "\n",
    "subsamples = {\n",
    "    \"1999-2007\": (\"1999-01-01\", \"2007-12-31\"), # (pre-crisis)\n",
    "    \"2008-2012\": (\"2008-01-01\", \"2012-12-31\"), # (Financial Crisis + Euro Crisis)\n",
    "    \"2013-2019\": (\"2013-01-01\", \"2019-12-31\"), # (QE, Low Volatility)\n",
    "    \"2020-2024\": (\"2020-01-01\", \"2024-12-31\"), # (COVID, Inflation, QT)\n",
    "}\n",
    "\n",
    "\n",
    "results_sub = {}\n",
    "\n",
    "for sub_name, (start, end) in subsamples.items():\n",
    "    print(sub_name) \n",
    "    df_sub = xusd_df.loc[start:end]\n",
    "    portfolios_sub = get_economic_portfolios(df_sub)\n",
    "    if len(df_sub) < 200:\n",
    "        continue\n",
    "\n",
    "    for p in param_grid:\n",
    "        lb = p[\"lookback\"]\n",
    "        hd = p[\"hold\"]\n",
    "        pct = p[\"pct\"]\n",
    "        portfolio_data = run_portfolio_strategies(portfolios_sub,lookback=lb, hold_period=hd, pct=pct)\n",
    "        #summarize_portfolio(portfolio_data, portfolios, \"P1\") #change the key to visualize the portfolio you wish to comment on \n",
    "        #plot_all_portfolios_pnl(portfolio_data)\n",
    "\n",
    "        key = f\"{sub_name} | LB={lb}, HP={hd}, PCT={pct}\"\n",
    "        results_sub[key] = portfolio_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707b6b43-17d6-42b7-bfd1-8092a8a901e9",
   "metadata": {},
   "source": [
    "### **Regime Performance Analysis of the FX Momentum Strategy**\n",
    "\n",
    "**Across 1999–2007, 2008–2012, 2013–2019, 2020–2024**\n",
    "\n",
    "The results reveal a clear regime dependence driven by volatility regimes, liquidity conditions, and structural characteristics of each economic portfolio.\n",
    "\n",
    "### **1. 1999–2007 – Pre-Crisis, Low-to-Moderate Volatility**\n",
    "\n",
    "#### Key observations\n",
    "\n",
    "- All portfolios except P5 deliver **negative Sharpe ratios** in ER-only form.\n",
    "- EM Americas (P5) is the only segment with a **positive Sharpe (~0.35)**.\n",
    "- Developed FX (P1) and Commodity FX (P2) are mildly negative in ER-only form but drop sharply under Bid/Ask execution.\n",
    "- Bid/Ask costs consistently **halve or destroy Sharpe** across all portfolios.\n",
    "\n",
    "#### Interpretation\n",
    "\n",
    "Momentum signals over short horizons struggle in stable pre-crisis FX markets where cross-currency trends are weak and mean-reversion dominates. P5 benefits from structural trends in BRL/MXN/RUB during the global EM carry boom.\n",
    "\n",
    "#### Execution impact\n",
    "\n",
    "Bid/Ask spreads increase drawdowns by **30–50%** and push most Sharpe ratios close to -0.5 to -0.8.\n",
    "This suggests the signal is not strong enough to overcome transaction costs in this regime.\n",
    "\n",
    "### **2. 2008–2012 – Crisis + Eurozone Turmoil (High Volatility)**\n",
    "\n",
    "#### Key observations\n",
    "\n",
    "- P2 (commodity FX) behaves exceptionally well in ER-only form: **Sharpe ~0.9**.\n",
    "- P5 (Americas + high-beta EM) also performs strongly: **Sharpe 0.55**.\n",
    "- Developed FX (P1) and Asia (P4) remain weak.\n",
    "- Bid/Ask execution reduces performance but **does not destroy profitability** for the strongest portfolios (P2, P5).\n",
    "\n",
    "#### Interpretation\n",
    "\n",
    "Crisis regimes create **large directional dislocations** that momentum can exploit.\n",
    "Commodity currencies produce robust trends driven by global deleveraging, oil, and risk cycles.\n",
    "\n",
    "#### Execution impact\n",
    "\n",
    "Bid/Ask erodes Sharpe but does not flip the signal negative for P2/P5, meaning the **signal strength exceeds transaction cost drag** in high-vol regimes.\n",
    "\n",
    "### **3. 2013–2019 – QE, Compression of Risk Premia, Low Volatility**\n",
    "\n",
    "#### Key observations\n",
    "\n",
    "- This is the **worst regime for the strategy** across all portfolios.\n",
    "- Nearly all portfolios exhibit **negative Sharpe ratios**, both ER-only and Bid/Ask.\n",
    "- Momentum signals revert frequently in range-bound currency markets with limited directional risk.\n",
    "- Bid/Ask execution amplifies losses significantly (Sharpe often < -0.8).\n",
    "\n",
    "#### Interpretation\n",
    "\n",
    "Post-crisis monetary regimes eliminated FX trends:\n",
    "ultra-low rates, synchronized QE, and suppressed cross-currency volatility.\n",
    "Momentum cannot extract signal when **macro dispersion collapses**.\n",
    "\n",
    "#### Execution impact\n",
    "\n",
    "Bid/Ask spreads consistently worsen Sharpe by **30–50%**, occasionally doubling drawdowns.\n",
    "The strategy becomes **non-viable** in this environment.\n",
    "\n",
    "### **4. 2020–2024 – COVID, Inflation Shock, Monetary Divergence**\n",
    "\n",
    "#### Key observations\n",
    "\n",
    "- Performance is mixed but materially better than during QE.\n",
    "- P3 (EM Europe) and P5 (Americas/Asia EM) deliver **positive ER-only Sharpe**, though modest (~0.25–0.32).\n",
    "- Developed markets (P1, P2) remain negative.\n",
    "- EM portfolios again show greater trend persistence post-COVID.\n",
    "\n",
    "#### Interpretation\n",
    "\n",
    "The return of inflation, divergent central bank reactions, and volatility spikes reintroduced directional signals in EM FX, while G10 FX was dominated by policy reversals and noisy short-lived moves.\n",
    "\n",
    "#### Execution impact\n",
    "\n",
    "As spreads widened during COVID, Bid/Ask drag becomes large enough to erase nearly all profitability—even in the stronger EM portfolios.\n",
    "\n",
    "\n",
    "### **Cross-Regime Synthesis (Most Important Part)**\n",
    "\n",
    "#### **1. The strategy is highly regime-dependent**\n",
    "\n",
    "Momentum succeeds in periods with:\n",
    "- strong macro trends,\n",
    "- high dispersion between economies,\n",
    "- persistent directional moves (2008–2012, post-2020 selectively).\n",
    "\n",
    "Fails in mean-reverting or low-vol regimes (2013–2019).\n",
    "\n",
    "#### **2. EM portfolios (P3–P5) carry most of the alpha**\n",
    "\n",
    "Because EM FX tends to trend structurally around risk cycles, carry unwinds, and policy shocks.\n",
    "\n",
    "#### **3. Developed markets (P1–P2) struggle except during crises**\n",
    "\n",
    "G10 FX is heavily mean-reverting under QE and exhibits limited trend strength.\n",
    "\n",
    "#### **4. Bid/Ask execution systematically degrades returns**\n",
    "\n",
    "Across all regimes:\n",
    "- Sharpe reduction of **30–80%**,\n",
    "- Drawdowns increase by **20–50%**,\n",
    "- Returns frequently fall below zero.\n",
    "\n",
    "Momentum signals are too weak to overcome transaction costs in most environments.\n",
    "\n",
    "#### **5. Best performing segments per regime**\n",
    "\n",
    "| Regime    | Best Portfolio(s) | Explanation                        |\n",
    "| --------- | ----------------- | ---------------------------------- |\n",
    "| 1999–2007 | P5                | EM structural trends               |\n",
    "| 2008–2012 | P2, P5            | Crisis-driven directional moves    |\n",
    "| 2013–2019 | None              | QE suppression of volatility       |\n",
    "| 2020–2024 | P3, P5            | Macro divergence and EM volatility |\n",
    "\n",
    "---\n",
    "\n",
    "### **Overall Conclusion**\n",
    "\n",
    "The strategy shows clear **economic sensitivity**:\n",
    "\n",
    "- Works only in regimes with **persistent macro shocks** and **high dispersion**.\n",
    "- EM portfolios reliably outperform G10 baskets.\n",
    "- Transaction costs render the strategy **borderline untradable in low-volatility regimes** and significantly weaken it even when raw momentum is strong.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dc5fed-ece2-4c09-b5a4-60d8f91efa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 1. Split spot dataframe into BID / MID(ER) / OFFER\n",
    "# =====================================================\n",
    "\n",
    "def split_bid_offer(df):\n",
    "    bid_cols   = [c for c in df.columns if c.endswith(\"_BID\")]\n",
    "    er_cols    = [c for c in df.columns if c.endswith(\"_ER\")]\n",
    "    offer_cols = [c for c in df.columns if c.endswith(\"_OFFER\")]\n",
    "\n",
    "    BID   = df[bid_cols].copy()\n",
    "    ER    = df[er_cols].copy()\n",
    "    OFFER = df[offer_cols].copy()\n",
    "\n",
    "    BID.columns   = [c.replace(\"_BID\", \"\") for c in bid_cols]\n",
    "    ER.columns    = [c.replace(\"_ER\", \"\") for c in er_cols]\n",
    "    OFFER.columns = [c.replace(\"_OFFER\", \"\") for c in offer_cols]\n",
    "\n",
    "    return BID, ER, OFFER\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 2. Harmonize forward dataframe into BID / MID / OFFER\n",
    "# =====================================================\n",
    "\n",
    "def harmonize_forward(df_forward):\n",
    "\n",
    "    currencies = sorted(set(c.split(\"_\")[0] for c in df_forward.columns))\n",
    "\n",
    "    F_bid   = pd.DataFrame(index=df_forward.index)\n",
    "    F_mid   = pd.DataFrame(index=df_forward.index)\n",
    "    F_offer = pd.DataFrame(index=df_forward.index)\n",
    "\n",
    "    for cur in currencies:\n",
    "        if f\"{cur}_BID\" in df_forward.columns:\n",
    "            F_bid[cur] = df_forward[f\"{cur}_BID\"]\n",
    "        if f\"{cur}_ER\" in df_forward.columns:\n",
    "            F_mid[cur] = df_forward[f\"{cur}_ER\"]\n",
    "        if f\"{cur}_OFFER\" in df_forward.columns:\n",
    "            F_offer[cur] = df_forward[f\"{cur}_OFFER\"]\n",
    "\n",
    "    return F_bid, F_mid, F_offer\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 3. Normalize weights (market-neutral)\n",
    "# =====================================================\n",
    "\n",
    "def clean_weights(signals):\n",
    "    w = signals.copy()\n",
    "    denom = w.abs().sum(axis=1)\n",
    "    return (w.div(denom, axis=0)).fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 4. PPP Strategy: log(F/S) with daily-expanded forwards\n",
    "# =====================================================\n",
    "\n",
    "def ppp_strategy(df_spot, df_forward, hold_period=22, pct=0.3):\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # Split spot into BID / ER / OFFER\n",
    "    # -----------------------------------------\n",
    "    BID, ER, OFFER = split_bid_offer(df_spot)\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # Extract raw forward curves\n",
    "    # -----------------------------------------\n",
    "    F_bid_raw, F_mid_raw, F_offer_raw = harmonize_forward(df_forward)\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # Expand forwards to daily frequency (critical)\n",
    "    # -----------------------------------------\n",
    "    F_bid   = F_bid_raw.reindex(df_spot.index).ffill()\n",
    "    F_mid   = F_mid_raw.reindex(df_spot.index).ffill()\n",
    "    F_offer = F_offer_raw.reindex(df_spot.index).ffill()\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # Common tradable universe\n",
    "    # -----------------------------------------\n",
    "    common = sorted(list(set(ER.columns) & set(F_mid.columns)))\n",
    "\n",
    "    BID   = BID[common]\n",
    "    ER    = ER[common]\n",
    "    OFFER = OFFER[common]\n",
    "    F_mid = F_mid[common]\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # PPP / carry mispricing signal = log(F/S)\n",
    "    # -----------------------------------------\n",
    "    value_signal = np.log(F_mid) - np.log(ER)\n",
    "\n",
    "    dates = value_signal.index\n",
    "    assets = value_signal.columns\n",
    "\n",
    "    signals = pd.DataFrame(0, index=dates, columns=assets)\n",
    "    rebalance_dates = dates[::hold_period]\n",
    "\n",
    "    for t in rebalance_dates:\n",
    "        today = value_signal.loc[t].dropna()\n",
    "        if today.empty:\n",
    "            continue\n",
    "\n",
    "        n = len(today)\n",
    "        k = int(np.floor(n * pct))\n",
    "\n",
    "        long_assets  = today.nlargest(k).index\n",
    "        short_assets = today.nsmallest(k).index\n",
    "\n",
    "        signals.loc[t, long_assets]  = 1\n",
    "        signals.loc[t, short_assets] = -1\n",
    "\n",
    "    # Hold between rebalancing dates\n",
    "    signals = signals.replace(0, np.nan).ffill().fillna(0)\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # Convert to market-neutral weights\n",
    "    # -----------------------------------------\n",
    "    weights = clean_weights(signals.shift(1))\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # Mid-only theoretical PnL\n",
    "    # -----------------------------------------\n",
    "    logret = np.log(ER).diff()\n",
    "    ret_mid = (weights * logret).sum(axis=1).fillna(0)\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # Executed PnL with Bid-Ask Costs\n",
    "    # -----------------------------------------\n",
    "    MID = (BID + OFFER) / 2\n",
    "    log_mid = np.log(MID)\n",
    "    daily_mid_ret = log_mid.diff()\n",
    "\n",
    "    pnl_mid = (weights * daily_mid_ret).sum(axis=1)\n",
    "\n",
    "    pos_prev = signals.shift(1)\n",
    "    pos_curr = signals\n",
    "\n",
    "    log_bid = np.log(BID)\n",
    "    log_offer = np.log(OFFER)\n",
    "\n",
    "    long_open_cost  = log_mid - log_offer\n",
    "    long_close_cost = log_bid - log_mid\n",
    "    short_open_cost = log_bid - log_mid\n",
    "    short_close_cost = log_mid - log_offer\n",
    "\n",
    "    long_open  = (pos_prev == 0) & (pos_curr == 1)\n",
    "    long_close = (pos_prev == 1) & (pos_curr == 0)\n",
    "\n",
    "    short_open  = (pos_prev == 0) & (pos_curr == -1)\n",
    "    short_close = (pos_prev == -1) & (pos_curr == 0)\n",
    "\n",
    "    flip_long_to_short = (pos_prev == 1) & (pos_curr == -1)\n",
    "    flip_short_to_long = (pos_prev == -1) & (pos_curr == 1)\n",
    "\n",
    "    long_close |= flip_long_to_short\n",
    "    short_open |= flip_long_to_short\n",
    "\n",
    "    short_close |= flip_short_to_long\n",
    "    long_open   |= flip_short_to_long\n",
    "\n",
    "    tc_matrix = (\n",
    "        long_open  * long_open_cost +\n",
    "        long_close * long_close_cost +\n",
    "        short_open * short_open_cost +\n",
    "        short_close * short_close_cost\n",
    "    )\n",
    "\n",
    "    traded_mask = long_open | long_close | short_open | short_close\n",
    "    trade_count = traded_mask.sum(axis=1).replace(0, np.nan)\n",
    "\n",
    "    tc_port = (tc_matrix.sum(axis=1) / trade_count).fillna(0)\n",
    "\n",
    "    ret_ba = pnl_mid + tc_port\n",
    "\n",
    "    return ret_mid, ret_ba, signals, value_signal, logret\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 5. Portfolio wrapper\n",
    "# =====================================================\n",
    "\n",
    "def run_ppp_portfolio_strategies(portfolios_spot, portfolios_forward, hold_period=22, pct=0.2, print_data=True):\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for name in portfolios_spot.keys():\n",
    "\n",
    "        df_spot    = portfolios_spot[name]\n",
    "        df_forward = portfolios_forward[name]\n",
    "\n",
    "        ret_mid, ret_ba, signals_ppp, value_ppp, logret_ppp = ppp_strategy(\n",
    "            df_spot,\n",
    "            df_forward,\n",
    "            hold_period=hold_period,\n",
    "            pct=pct\n",
    "        )\n",
    "\n",
    "        stats_mid = evaluate_strategy(ret_mid, freq='D')\n",
    "        stats_ba  = evaluate_strategy(ret_ba, freq='D')\n",
    "\n",
    "        results[name] = {\n",
    "            \"ER_only\": {\"returns\": ret_mid, \"stats\": stats_mid},\n",
    "            \"BidAsk\":  {\"returns\": ret_ba,  \"stats\": stats_ba},\n",
    "            \"signals\": signals_ppp,\n",
    "            \"value_signal\": value_ppp,\n",
    "            \"log_returns\": logret_ppp\n",
    "        }\n",
    "\n",
    "        if print_data:\n",
    "            print(\"\\n==============================\")\n",
    "            print(f\"PPP Portfolio: {name}\")\n",
    "            print(\"=== PPP Mid-only ===\")\n",
    "            print(stats_mid)\n",
    "            print(\"=== PPP Bid/Ask Execution ===\")\n",
    "            print(stats_ba)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "# ================= RUN =================\n",
    "\n",
    "print(\"1M\")\n",
    "results_ppp_1M = run_ppp_portfolio_strategies(\n",
    "    portfolios_spot=portfolios,\n",
    "    portfolios_forward=portfolios_forward_1M,\n",
    "    hold_period=22\n",
    ")\n",
    "\n",
    "print(\"1W\")\n",
    "results_ppp_1W = run_ppp_portfolio_strategies(\n",
    "    portfolios_spot=portfolios,\n",
    "    portfolios_forward=portfolios_forward_1W,\n",
    "    hold_period=7\n",
    ")\n",
    "\n",
    "summarize_portfolio(results_ppp_1M, portfolios, \"P1\")\n",
    "plot_all_portfolios_pnl(results_ppp_1M)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd30007-8728-441d-824d-7a379f758fd7",
   "metadata": {},
   "source": [
    "### **1. Overall Takeaway**\n",
    "\n",
    "The PPP signal **works only marginally at the 1-month horizon** and becomes **non-viable at the 1-week horizon**.\n",
    "Forward–spot mispricing is too weak in your currency universe, and transaction costs eliminate almost all excess returns.\n",
    "\n",
    "\n",
    "#### **2. PPP (1M) – Interpretation**\n",
    "\n",
    "**Mid-only performance**\n",
    "\n",
    "* Returns are low across most portfolios.\n",
    "* Only P2 shows a meaningful Sharpe (≈0.38), suggesting some PPP/carry information in Scandinavian FX.\n",
    "* Volatility remains low, consistent with a market-neutral FX strategy.\n",
    "\n",
    "**Bid/Ask execution**\n",
    "\n",
    "* Performance turns **negative for all portfolios except P2**.\n",
    "* Sharpe ratios collapse.\n",
    "* Drawdowns deepen significantly.\n",
    "* High kurtosis (10–29) indicates exposure to tail events and announcement-driven jumps.\n",
    "\n",
    "**Conclusion (1M):**\n",
    "The PPP signal is present but too weak relative to spreads. In a small universe with low rate dispersion, the forward curve doesn’t provide enough systematic premium.\n",
    "\n",
    "\n",
    "#### **3. PPP (1W) – Interpretation**\n",
    "\n",
    "**Mid-only performance**\n",
    "\n",
    "* Weak or negative returns for most portfolios.\n",
    "* The signal behaves more like noise than a persistent valuation/carry factor.\n",
    "\n",
    "**Bid/Ask execution**\n",
    "\n",
    "* All portfolios become **strongly negative**.\n",
    "* Sharpe ratios between –0.28 and –0.72.\n",
    "* Drawdowns extremely large (up to –57%).\n",
    "* Some portfolios show extreme kurtosis (>100), reflecting sensitivity to fast FX corrections.\n",
    "\n",
    "**Conclusion (1W):**\n",
    "Weekly PPP is **not economically meaningful** and **not tradable**. Short-horizon forward/spot mispricing is dominated by microstructure noise and transaction costs.\n",
    "\n",
    "#### **4. Economic Interpretation**\n",
    "\n",
    "* Your universe (GBP, EUR, CHF, SEK, NOK) has **limited forward rate dispersion** → weak carry/PPP signal.\n",
    "* Forward curves at 1W or 1M do not generate strong cross-sectional spreads.\n",
    "* Transaction costs fully absorb the small theoretical premium.\n",
    "\n",
    "#### **5. Final Summary**\n",
    "\n",
    "* **PPP 1M:** weak but detectable signal; not profitable after costs.\n",
    "* **PPP 1W:** no signal; structurally untradable.\n",
    "* **Main issue:** low cross-sectional rate differentials + high turnover relative to spreads.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3ec20b-105c-40da-aac2-c7c4bb58e93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_ppp_execution_calendar(results_ppp, portfolios_forward, portfolio_name):\n",
    "    \"\"\"\n",
    "    Visualise:\n",
    "    - PPP rebalance dates\n",
    "    - Trade execution dates (where bid/offer execution was possible)\n",
    "    - Forward portfolio content\n",
    "    \"\"\"\n",
    "\n",
    "    data = results_ppp[portfolio_name]\n",
    "    ret_ba = data[\"BidAsk\"][\"returns\"]\n",
    "    signals = data[\"signals\"]\n",
    "\n",
    "    # Rebalance dates = where signals change (first differences)\n",
    "    rebalance_dates = signals.diff().abs().sum(axis=1)\n",
    "    rebalance_dates = rebalance_dates[rebalance_dates > 0].index\n",
    "\n",
    "    # Execution dates = where ret_ba != 0\n",
    "    pos_prev = signals.shift(1).fillna(0)\n",
    "    pos_curr = signals\n",
    "    \n",
    "    trade_mask = (pos_prev != pos_curr).any(axis=1)\n",
    "    exec_dates = trade_mask[trade_mask].index\n",
    "    \n",
    "\n",
    "    # Forward portfolio composition\n",
    "    fwd_cols = portfolios_forward[portfolio_name].columns\n",
    "    forward_assets = sorted(set(c.split(\"_\")[0] for c in fwd_cols))\n",
    "\n",
    "    plt.figure(figsize=(15, 4))\n",
    "\n",
    "    plt.scatter(rebalance_dates, [1]*len(rebalance_dates),\n",
    "                color=\"blue\", s=50, label=\"PPP Rebalance dates\")\n",
    "\n",
    "    plt.scatter(exec_dates, [0]*len(exec_dates),\n",
    "                color=\"red\", s=30, label=\"Executed trades (Bid/Offer)\")\n",
    "\n",
    "    plt.yticks([0,1], [\"Executed trades\", \"Rebalance trigger\"])\n",
    "    plt.grid(True, alpha=0.4)\n",
    "    plt.title(f\"PPP Execution Calendar – Portfolio {portfolio_name}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.legend(loc=\"upper left\")\n",
    "\n",
    "    print(\"\\nForward currencies used in this portfolio:\")\n",
    "    print(forward_assets)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_ppp_execution_calendar(results_ppp_1W, portfolios_forward_1W, \"P5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a29177-a48b-4c30-8a5c-b06fdb4ca406",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\"pct\": 0.2},\n",
    "]\n",
    "subsamples = {\n",
    "    \"1999-2007\": (\"1999-01-01\", \"2007-12-31\"), # (pre-crisis)\n",
    "    \"2008-2012\": (\"2008-01-01\", \"2012-12-31\"), # (Financial Crisis + Euro Crisis)\n",
    "    \"2013-2019\": (\"2013-01-01\", \"2019-12-31\"), # (QE, Low Volatility)\n",
    "    \"2020-2024\": (\"2020-01-01\", \"2024-12-31\"), # (COVID, Inflation, QT)\n",
    "}\n",
    "\n",
    "\n",
    "results_sub1W = {}\n",
    "results_sub1M = {}\n",
    "for sub_name, (start, end) in subsamples.items():\n",
    "    xusd_df_sub = xusd_df.loc[start:end]\n",
    "    forward_1M_sub = forward_1M.loc[start:end]\n",
    "    forward_1W_sub = forward_1W.loc[start:end]\n",
    "\n",
    "\n",
    "    portfolios_sub = get_economic_portfolios(xusd_df_sub)\n",
    "    portfolios_forward_1W_sub = get_economic_portfolios(forward_1W_sub)\n",
    "    portfolios_forward_1M_sub = get_economic_portfolios(forward_1M_sub)\n",
    "    if len(df_sub) < 200:\n",
    "        continue\n",
    "\n",
    "    for p in param_grid:\n",
    "        pct = p[\"pct\"]\n",
    "\n",
    "        results_ppp_1M = run_ppp_portfolio_strategies(\n",
    "            portfolios_spot=portfolios_sub,\n",
    "            portfolios_forward=portfolios_forward_1M_sub, hold_period=22, pct=pct\n",
    "        )\n",
    "        \n",
    "        results_ppp_1W = run_ppp_portfolio_strategies(\n",
    "            portfolios_spot=portfolios_sub,\n",
    "            portfolios_forward=portfolios_forward_1W_sub, hold_period=7, pct=pct\n",
    "        )\n",
    "        summarize_portfolio(results_ppp_1W, portfolios_sub, \"P5\")\n",
    "        summarize_portfolio(results_ppp_1M, portfolios_sub, \"P5\")\n",
    "        plot_all_portfolios_pnl(results_ppp_1M)\n",
    "\n",
    "\n",
    "        key = f\"{sub_name} | HP={hd}, PCT={pct}\"\n",
    "        results_sub1M[key] = results_ppp_1W\n",
    "        results_sub1W[key] = results_ppp_1M\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e9b434-d100-4a54-a06d-1548ba9ed33e",
   "metadata": {},
   "source": [
    "#### **1. Stability of the PPP signal across regimes**\n",
    "\n",
    "Across all subsamples, the PPP factor behaves **weakly and inconsistently**, with substantial regime dependence.\n",
    "Only a few windows show meaningful Sharpe ratios, and most of the performance deteriorates once realistic execution costs are included.\n",
    "\n",
    "The **economic conclusion** is clear:\n",
    "PPP mispricing is slow-moving and weakly predictive, and its explanatory power collapses when markets are stressed or when currencies are heavily policy-driven.\n",
    "\n",
    "#### **2. 1999–2007 (pre-crisis)**\n",
    "\n",
    "* Mid-only performance is mixed. Some portfolios (P2, P4) reach respectable Sharpe ratios driven by carry-like structure in EM and commodity currencies.\n",
    "* Bid/ask execution materially reduces performance but doesn’t fully eliminate it in the strongest portfolios.\n",
    "* Drawdowns remain shallow, suggesting a stable macro environment where slow PPP deviations persist.\n",
    "\n",
    "**Interpretation:**\n",
    "PPP has some predictive power in a stable macro regime with differentiated interest rates and fewer shocks.\n",
    "\n",
    "\n",
    "#### **3. 2008–2012 (financial crisis + euro crisis)**\n",
    "\n",
    "* The signal weakens sharply; most portfolios produce low or negative Sharpe ratios even before transaction costs.\n",
    "* Bid/ask execution amplifies losses, turning almost all portfolios untradable.\n",
    "* Volatility spikes and kurtosis increases, reflecting disorderly FX repricing and regime discontinuities.\n",
    "\n",
    "**Interpretation:**\n",
    "Crisis periods destroy PPP-style arbitrage because FX is driven by liquidity, risk aversion and capital flows rather than valuation differentials.\n",
    "\n",
    "#### **4. 2013–2019 (QE, low-vol regime)**\n",
    "\n",
    "* PPP performance improves slightly; some portfolios (notably P5 in your EM bloc) produce stable mid-only returns.\n",
    "* Execution costs, however, again absorb a material portion of the premium.\n",
    "* High kurtosis shows that returns remain exposed to occasional macro jumps despite QE stability.\n",
    "\n",
    "**Interpretation:**\n",
    "PPP works better in calm markets, but the signal remains too small relative to spreads to generate robust trading returns.\n",
    "\n",
    "#### **5. 2020–2024 (COVID, inflation, QT)**\n",
    "\n",
    "* The signal almost collapses.\n",
    "* Mid-only returns fluctuate around zero; bid/ask versions are deeply negative.\n",
    "* Volatility and tail risk increase sharply (skewness and kurtosis rise), stressing the fragility of valuation-based signals during macro dislocations.\n",
    "\n",
    "**Interpretation:**\n",
    "Extreme macro shocks dominate FX pricing; PPP deviations adjust too slowly and become irrelevant for trading horizons.\n",
    "\n",
    "#### **6. Portfolio P5 (EM + JPY bloc) – Detailed insight**\n",
    "\n",
    "Consistently across windows:\n",
    "\n",
    "* **Mid-only returns oscillate between weakly positive and negative.**\n",
    "* **Bid/ask execution almost always turns the strategy negative.**\n",
    "* High kurtosis (8–28) indicates large tail sensitivity.\n",
    "* Deep drawdowns reflect violent EM and JPY adjustments during risk-off regimes.\n",
    "\n",
    "**Conclusion for P5:**\n",
    "PPP is not a reliable driver of EMFX returns and cannot overcome structural spreads or regime breaks.\n",
    "\n",
    "#### **7. Final synthesis**\n",
    "\n",
    "* **PPP is not a tradable standalone signal** across any macro regime in your dataset.\n",
    "* When it works (e.g., pre-2007, QE years), the premium is modest and fragile.\n",
    "* During crises (2008–12, 2020–24), it becomes strongly negative.\n",
    "* Execution costs systematically eliminate any exploitable edge.\n",
    "\n",
    "**Overall:**\n",
    "The PPP factor is economically intuitive but empirically weak. Its timescale (multi-year convergence) is incompatible with high-frequency portfolio rotation, and transaction costs fully dominate the signal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d10a8f7-353f-4665-9103-f0582ad0ee3a",
   "metadata": {},
   "source": [
    "# Enhanced Momentum Strategy for FX Markets (Literature-Based)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96079f9b-37a2-4535-9371-a6cf337b4ae6",
   "metadata": {},
   "source": [
    "Momentum strategies, originally documented by Jegadeesh & Titman (1993, 2001), have proven persistent across equities (Fama & French, 2012), global asset classes (Asness et al., 2013), and foreign exchange markets (Menkhoff et al., 2012).\n",
    "However, research after the Global Financial Crisis showed that momentum is **fragile**, especially during market rebounds, and that naïve implementations can experience severe drawdowns (Daniel & Moskowitz, 2016).\n",
    "\n",
    "To adapt the classical FX momentum strategy without over-engineering the model, we implement **three simple improvements** directly motivated by the academic literature.q\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Volatility Scaling (Barroso & Santa-Clara, 2015)**\n",
    "\n",
    "Momentum behaves poorly when its volatility spikes, particularly during crisis periods.\n",
    "A straightforward improvement is to **reduce exposure when recent strategy volatility is high**.\n",
    "\n",
    "**Implementation (very simple):**\n",
    "\n",
    "```\n",
    "vol_t   = rolling 60-day volatility of the strategy\n",
    "scale_t = target_vol / vol_t\n",
    "signal  = scale_t * raw_signal\n",
    "```\n",
    "\n",
    "**Why this matters:**\n",
    "FX markets exhibit volatility clustering. This adjustment prevents the strategy from taking large positions in unstable periods (e.g., 2008, 2020), thereby reducing drawdowns and improving Sharpe ratios.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Market-Condition Filter (Daniel & Moskowitz, 2016)**\n",
    "\n",
    "Momentum tends to crash in **sharp market reversals**. A full crash-robust model would be heavy, but a simple filter works well:\n",
    "\n",
    "```\n",
    "market_momentum = average 1-month return across all currencies\n",
    "\n",
    "if market_momentum < 0:\n",
    "    signals are reduced (for example by 50%)\n",
    "else:\n",
    "    full exposure\n",
    "```\n",
    "\n",
    "**Intuition:**\n",
    "When FX markets collectively reverse after stress, momentum spreads compress violently.\n",
    "This lightweight filter avoids trading aggressively in these regimes without requiring complex modelling.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Combine Cross-Sectional and Time-Series Momentum (Moskowitz, Ooi & Pedersen, 2012)**\n",
    "\n",
    "Cross-sectional momentum (ranking currencies against each other) can be noisy.\n",
    "Adding a **simple time-series component** stabilises signals and improves persistence.\n",
    "\n",
    "**Implementation:**\n",
    "\n",
    "```\n",
    "ts_signal     = sign(50-day cumulative return of each currency)\n",
    "final_signal  = 0.5 * cross_sectional + 0.5 * ts_signal\n",
    "```\n",
    "\n",
    "**Benefit:**\n",
    "If a currency is a “relative winner” but not trending upward, the signal is moderated.\n",
    "If both components agree, the position is reinforced.\n",
    "This reduces false positive trades and improves robustness across regimes.\n",
    "\n",
    "---\n",
    "\n",
    "# **Summary**\n",
    "\n",
    "With only three compact enhancements, the FX momentum strategy becomes:\n",
    "\n",
    "* **More stable** (volatility scaling)\n",
    "* **Less exposed to crashes** (market-condition filter)\n",
    "* **More robust and persistent** (hybrid momentum signal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c662e648-9324-4f83-af97-9c921de34c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 1. Split BID / ER / OFFER\n",
    "# =====================================================\n",
    "\n",
    "def split_bid_offer(df):\n",
    "    bid_cols   = [c for c in df.columns if c.endswith(\"_BID\")]\n",
    "    er_cols    = [c for c in df.columns if c.endswith(\"_ER\")]\n",
    "    offer_cols = [c for c in df.columns if c.endswith(\"_OFFER\")]\n",
    "\n",
    "    BID   = df[bid_cols].copy()\n",
    "    ER    = df[er_cols].copy()\n",
    "    OFFER = df[offer_cols].copy()\n",
    "\n",
    "    BID.columns   = [c.replace(\"_BID\", \"\") for c in bid_cols]\n",
    "    ER.columns    = [c.replace(\"_ER\", \"\") for c in er_cols]\n",
    "    OFFER.columns = [c.replace(\"_OFFER\", \"\") for c in offer_cols]\n",
    "\n",
    "    return BID, ER, OFFER\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 2. Basic momentum building blocks\n",
    "# =====================================================\n",
    "\n",
    "def compute_log_returns(ER):\n",
    "    return np.log(ER).diff()\n",
    "\n",
    "def compute_cross_sectional_momentum(log_ret, lookback):\n",
    "    return log_ret.rolling(lookback).sum()\n",
    "\n",
    "def compute_time_series_momentum(ER, ts_window):\n",
    "    return np.sign(ER.pct_change(ts_window))\n",
    "\n",
    "def combine_momentum(cs, ts):\n",
    "    return 0.5 * cs + 0.5 * ts\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 3. Market filter\n",
    "# =====================================================\n",
    "\n",
    "def compute_market_momentum(momentum):\n",
    "    return momentum.mean(axis=1)\n",
    "\n",
    "def market_regime_multiplier(market_mom, threshold):\n",
    "    return 1 - 0.5 * (market_mom < threshold).astype(float)\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 4. Signal construction\n",
    "# =====================================================\n",
    "\n",
    "def select_assets(momentum_vector, pct):\n",
    "    momentum_vector = momentum_vector.dropna()\n",
    "    if momentum_vector.empty:\n",
    "        return [], []\n",
    "\n",
    "    n = len(momentum_vector)\n",
    "    k = int(np.floor(n * pct))\n",
    "\n",
    "    winners = list(momentum_vector.nlargest(k).index)\n",
    "    losers  = list(momentum_vector.nsmallest(k).index)\n",
    "\n",
    "    return winners, losers\n",
    "\n",
    "\n",
    "def build_signal_matrix(momentum, dates, assets, hold_period, pct):\n",
    "    signals = pd.DataFrame(0, index=dates, columns=assets)\n",
    "    rebalance_dates = dates[::hold_period]\n",
    "\n",
    "    for t in rebalance_dates:\n",
    "        winners, losers = select_assets(momentum.loc[t], pct)\n",
    "        signals.loc[t, winners] = 1\n",
    "        signals.loc[t, losers]  = -1\n",
    "\n",
    "    return signals.replace(0, np.nan).ffill().fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 5. Volatility scaling\n",
    "# =====================================================\n",
    "\n",
    "def compute_volatility_scaler(r, window=60, target_vol=0.10):\n",
    "    vol = r.rolling(window).std()\n",
    "    scale = (target_vol / vol).clip(upper=3)\n",
    "    return scale\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 6A. Mid-only execution (MTM daily)\n",
    "# =====================================================\n",
    "\n",
    "def compute_mid_execution(ER, signals):\n",
    "    log_ret = np.log(ER).diff()\n",
    "    return (signals.shift(1) * log_ret).mean(axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 6B. Correct bid/ask execution with monthly holding\n",
    "# =====================================================\n",
    "\n",
    "def compute_bidask_execution(BID, OFFER, ER, signals, hold_period=22):\n",
    "\n",
    "    dates = ER.index\n",
    "    assets = ER.columns\n",
    "\n",
    "    daily_mid_ret = np.log(ER).diff()\n",
    "    portfolio_ret = pd.Series(0.0, index=dates)\n",
    "\n",
    "    # Detect true rebalance dates (signal changes)\n",
    "    rebal_dates = signals.diff().abs().sum(axis=1)\n",
    "    rebal_dates = rebal_dates[rebal_dates > 0].index\n",
    "    rebal_dates = rebal_dates.sort_values()\n",
    "\n",
    "    for i in range(len(rebal_dates)-1):\n",
    "\n",
    "        t_entry = rebal_dates[i]\n",
    "        t_exit  = rebal_dates[i+1]\n",
    "\n",
    "        pos = signals.loc[t_entry]\n",
    "        active = pos[pos != 0].index\n",
    "\n",
    "        if len(active) == 0:\n",
    "            continue\n",
    "\n",
    "        # --- 1. Daily MTM using mid ---------------------\n",
    "        mtm = (signals.loc[t_entry] * daily_mid_ret)[active]\n",
    "\n",
    "        # Convert timestamps to index positions\n",
    "        entry_idx = daily_mid_ret.index.get_loc(t_entry) + 1\n",
    "        exit_idx  = daily_mid_ret.index.get_loc(t_exit)\n",
    "\n",
    "        if entry_idx <= exit_idx:\n",
    "            mtm_period = mtm.iloc[entry_idx : exit_idx + 1]\n",
    "            portfolio_ret.iloc[entry_idx : exit_idx + 1] = mtm_period.mean(axis=1)\n",
    "\n",
    "        # --- 2. Entry transaction cost -------------------\n",
    "        entry_cost = 0\n",
    "        for cur in active:\n",
    "            if pos[cur] == 1:   # long\n",
    "                entry_cost += np.log(OFFER.loc[t_entry, cur]) - np.log(ER.loc[t_entry, cur])\n",
    "            else:               # short\n",
    "                entry_cost += np.log(ER.loc[t_entry, cur]) - np.log(BID.loc[t_entry, cur])\n",
    "\n",
    "        # --- 3. Exit transaction cost --------------------\n",
    "        exit_cost = 0\n",
    "        for cur in active:\n",
    "            if pos[cur] == 1:\n",
    "                exit_cost += np.log(ER.loc[t_exit, cur]) - np.log(BID.loc[t_exit, cur])\n",
    "            else:\n",
    "                exit_cost += np.log(OFFER.loc[t_exit, cur]) - np.log(ER.loc[t_exit, cur])\n",
    "\n",
    "        # Record total period PnL on exit date\n",
    "        portfolio_ret.loc[t_exit] += (-entry_cost - exit_cost)\n",
    "\n",
    "    return portfolio_ret\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 7. Compute hybrid momentum signals\n",
    "# =====================================================\n",
    "\n",
    "def compute_signals(ER, lookback=4, hold_period=22, pct=0.3,\n",
    "                    ts_window=50, market_threshold=0):\n",
    "\n",
    "    log_ret = compute_log_returns(ER)\n",
    "    cs = compute_cross_sectional_momentum(log_ret, lookback)\n",
    "    ts = compute_time_series_momentum(ER, ts_window)\n",
    "\n",
    "    hybrid = combine_momentum(cs, ts)\n",
    "\n",
    "    market_mom = compute_market_momentum(hybrid)\n",
    "    regime = market_regime_multiplier(market_mom, market_threshold)\n",
    "\n",
    "    hybrid_filtered = hybrid.mul(regime, axis=0)\n",
    "\n",
    "    signals = build_signal_matrix(\n",
    "        hybrid_filtered,\n",
    "        ER.index,\n",
    "        ER.columns,\n",
    "        hold_period,\n",
    "        pct\n",
    "    )\n",
    "\n",
    "    return signals, hybrid_filtered, log_ret\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 8. Momentum using mid-only\n",
    "# =====================================================\n",
    "\n",
    "def momentum_ER_only(ER, signals, vol_window=60, target_vol=0.10):\n",
    "    raw = compute_mid_execution(ER, signals)\n",
    "    scale = compute_volatility_scaler(raw, vol_window, target_vol)\n",
    "    return raw * scale\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 9. Momentum using corrected bid/offer execution\n",
    "# =====================================================\n",
    "\n",
    "def momentum_bidask(BID, OFFER, ER, signals, hold_period=22,\n",
    "                    vol_window=60, target_vol=0.10):\n",
    "\n",
    "    raw = compute_bidask_execution(BID, OFFER, ER, signals, hold_period)\n",
    "    scale = compute_volatility_scaler(raw, vol_window, target_vol)\n",
    "    return raw * scale\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 10. Wrapper\n",
    "# =====================================================\n",
    "\n",
    "def run_portfolio_strategies_improved(portfolios, lookback=4, hold_period=22, pct=0.3, print_data = True):\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for name, df_port in portfolios.items():\n",
    "\n",
    "        BID, ER, OFFER = split_bid_offer(df_port)\n",
    "\n",
    "        signals, momentum, log_ret_spot = compute_signals(\n",
    "            ER,\n",
    "            lookback=lookback,\n",
    "            hold_period=hold_period,\n",
    "            pct=pct\n",
    "        )\n",
    "\n",
    "        ret_mid = momentum_ER_only(ER, signals)\n",
    "        stats_mid = evaluate_strategy(ret_mid, freq='D')\n",
    "\n",
    "        ret_ba = momentum_bidask(BID, OFFER, ER, signals, hold_period)\n",
    "        stats_ba = evaluate_strategy(ret_ba, freq='D')\n",
    "\n",
    "        results[name] = {\n",
    "            \"ER_only\": {\n",
    "                \"returns\": ret_mid,\n",
    "                \"stats\": stats_mid\n",
    "            },\n",
    "            \"BidAsk\": {\n",
    "                \"returns\": ret_ba,\n",
    "                \"stats\": stats_ba\n",
    "            },\n",
    "            \"signals\": signals,\n",
    "            \"momentum\": momentum,\n",
    "            \"log_returns\": log_ret_spot\n",
    "        }\n",
    "        if print_data: \n",
    "            print(\"\\n==============================\")\n",
    "            print(f\"Portfolio: {name}\")\n",
    "            print(\"=== ER-only ===\")\n",
    "            print(stats_mid)\n",
    "            print(\"=== Bid/Ask ===\")\n",
    "            print(stats_ba)\n",
    "\n",
    "    return results\n",
    "\n",
    "portfolio_run_momentum_strat_biblio= run_portfolio_strategies_improved(portfolios)\n",
    "\n",
    "summarize_portfolio(portfolio_run_momentum_strat_biblio, portfolios, \"P1\")\n",
    "plot_all_portfolios_pnl(portfolio_run_momentum_strat_biblio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1f283f-3bee-4cc8-8796-64cbab7bba81",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\"lookback\": 4, \"hold\": 22, \"pct\": 0.2},\n",
    "    {\"lookback\": 10, \"hold\": 22, \"pct\": 0.4},\n",
    "]\n",
    "# allow to test other setup -> we can maybe tune some values using optuna for bayesian optimisation of those parameters\n",
    "\n",
    "subsamples = {\n",
    "    \"1999-2007\": (\"1999-01-01\", \"2007-12-31\"), # (pre-crisis)\n",
    "    \"2008-2012\": (\"2008-01-01\", \"2012-12-31\"), # (Financial Crisis + Euro Crisis)\n",
    "    \"2013-2019\": (\"2013-01-01\", \"2019-12-31\"), # (QE, Low Volatility)\n",
    "    \"2020-2024\": (\"2020-01-01\", \"2024-12-31\"), # (COVID, Inflation, QT)\n",
    "}\n",
    "\n",
    "\n",
    "results_sub = {}\n",
    "\n",
    "for sub_name, (start, end) in subsamples.items():\n",
    "    print(sub_name) \n",
    "    df_sub = xusd_df.loc[start:end]\n",
    "    portfolios_sub = get_economic_portfolios(df_sub)\n",
    "    if len(df_sub) < 200:\n",
    "        continue\n",
    "\n",
    "    for p in param_grid:\n",
    "        lb = p[\"lookback\"]\n",
    "        hd = p[\"hold\"]\n",
    "        pct = p[\"pct\"]\n",
    "        portfolio_data = run_portfolio_strategies_improved(portfolios,lookback=lb, hold_period=hd, pct=pct, print_data = False)\n",
    "        summarize_portfolio(portfolio_data, portfolios, \"P1\") #change the key to visualize the portfolio you wish to comment on \n",
    "        plot_all_portfolios_pnl(portfolio_data)\n",
    "\n",
    "        key = f\"{sub_name} | LB={lb}, HP={hd}, PCT={pct}\"\n",
    "        results_sub[key] = portfolio_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3d31e5-ec57-4114-98ba-423ce54686cc",
   "metadata": {},
   "source": [
    "Despite integrating state-of-the-art enhancements such as volatility scaling (Barroso & Santa-Clara, 2015), crash-robust conditioning (Daniel & Moskowitz, 2016) and hybrid trend specifications (Moskowitz et al., 2012), the FX momentum strategy does not exhibit any economically meaningful improvement. This is fully consistent with the empirical literature, which shows that momentum is structurally weak in FX spot markets, highly regime-dependent, and largely dominated by bid–ask frictions and global volatility conditions. In short, the strategy fails not because of implementation errors, but because FX momentum is not a robust standalone factor over long horizons."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
